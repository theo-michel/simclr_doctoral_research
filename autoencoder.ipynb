{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\python310\\lib\\site-packages (0.12.16)\n",
      "Requirement already satisfied: six>=1.13.0 in c:\\python310\\lib\\site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: PyYAML in c:\\python310\\lib\\site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: setproctitle in c:\\python310\\lib\\site-packages (from wandb) (1.2.3)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in c:\\python310\\lib\\site-packages (from wandb) (3.19.4)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in c:\\python310\\lib\\site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\python310\\lib\\site-packages (from wandb) (1.5.11)\n",
      "Requirement already satisfied: pathtools in c:\\python310\\lib\\site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in c:\\python310\\lib\\site-packages (from wandb) (3.1.27)\n",
      "Requirement already satisfied: setuptools in c:\\python310\\lib\\site-packages (from wandb) (58.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\python310\\lib\\site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in c:\\python310\\lib\\site-packages (from wandb) (1.0.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\python310\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in c:\\python310\\lib\\site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\python310\\lib\\site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\python310\\lib\\site-packages (from wandb) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from Click!=8.0.0,>=7.0->wandb) (0.4.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\python310\\lib\\site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\python310\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\python310\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: graphviz in c:\\python310\\lib\\site-packages (0.20)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchviz in c:\\python310\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: graphviz in c:\\python310\\lib\\site-packages (from torchviz) (0.20)\n",
      "Requirement already satisfied: torch in c:\\python310\\lib\\site-packages (from torchviz) (1.11.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in c:\\python310\\lib\\site-packages (from torch->torchviz) (4.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install wandb\n",
    "%pip install graphviz\n",
    "%pip install torchviz\n",
    "import wandb\n",
    "wandb.login()#doesnt detect WANDB_NOTEBOOK_NAME on windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1futr09k) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▇█▇▇▇▂▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00956</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">neat-glitter-4</strong>: <a href=\"https://wandb.ai/simclr-doctoral-research/test-project/runs/1futr09k\" target=\"_blank\">https://wandb.ai/simclr-doctoral-research/test-project/runs/1futr09k</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220508_202234-1futr09k\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1futr09k). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\theob\\simclr_doctoral_research-1\\wandb\\run-20220508_205554-57ifoqfu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/simclr-doctoral-research/test-project/runs/57ifoqfu\" target=\"_blank\">firm-smoke-5</a></strong> to <a href=\"https://wandb.ai/simclr-doctoral-research/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/simclr-doctoral-research/test-project/runs/57ifoqfu?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1c8c5df7c10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"test-project\", entity=\"simclr-doctoral-research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 10,\n",
    "  \"batch_size\": 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')\n",
    "\n",
    "\n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "dataset_train = MNIST('./data', transform=img_transform, download=True,train = True)\n",
    "dataset_test = MNIST('./data', transform=img_transform, download=True,train = False)\n",
    "\n",
    "dataloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 128))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256,28 * 28), \n",
    "            nn.Tanh())\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/10], loss:0.0380\n",
      "epoch [2/10], loss:0.0293\n",
      "epoch [3/10], loss:0.0254\n",
      "epoch [4/10], loss:0.0207\n",
      "epoch [5/10], loss:0.0179\n",
      "epoch [6/10], loss:0.0160\n",
      "epoch [7/10], loss:0.0145\n",
      "epoch [8/10], loss:0.0155\n",
      "epoch [9/10], loss:0.0141\n",
      "epoch [10/10], loss:0.0138\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img).to(device)\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        loss = criterion(output, img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.item()))\n",
    "    if epoch % 10 == 0:\n",
    "        pic = to_img(output.cpu().data)\n",
    "        save_image(pic, './mlp_img/image_{}.png'.format(epoch))\n",
    "    wandb.log({\"loss\": loss})\n",
    "\n",
    "    wandb.watch(model)\n",
    "    #print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.data[0]))\n",
    "\n",
    "pic = to_img(output.cpu().data)\n",
    "save_image(pic, './mlp_img/image_final.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011972813867032528\n",
      "0.013827801682054996\n",
      "0.01233371440321207\n",
      "0.01306719146668911\n",
      "0.012613274157047272\n",
      "0.014141821302473545\n",
      "0.01355400588363409\n",
      "0.013729814440011978\n",
      "0.012866649776697159\n",
      "0.012710191309452057\n",
      "0.011761903762817383\n",
      "0.014803962782025337\n",
      "0.013759760186076164\n",
      "0.011927159503102303\n",
      "0.012271540239453316\n",
      "0.013205592520534992\n",
      "0.014295821078121662\n",
      "0.012852337211370468\n",
      "0.014401019550859928\n",
      "0.013996053487062454\n",
      "0.012950664386153221\n",
      "0.012979492545127869\n",
      "0.012506290338933468\n",
      "0.013522597961127758\n",
      "0.013066948391497135\n",
      "0.013648418709635735\n",
      "0.013688760809600353\n",
      "0.011853915639221668\n",
      "0.013132873922586441\n",
      "0.013601476326584816\n",
      "0.01232051383703947\n",
      "0.013058393262326717\n",
      "0.012982528656721115\n",
      "0.013188609853386879\n",
      "0.013026068918406963\n",
      "0.012004712596535683\n",
      "0.013105807825922966\n",
      "0.012951243668794632\n",
      "0.012774603441357613\n",
      "0.013820839114487171\n",
      "0.013123128563165665\n",
      "0.013113797642290592\n",
      "0.011946074664592743\n",
      "0.013576759956777096\n",
      "0.01313229463994503\n",
      "0.013639523647725582\n",
      "0.01322807278484106\n",
      "0.012494525872170925\n",
      "0.012579048983752728\n",
      "0.012938314117491245\n",
      "0.013238629326224327\n",
      "0.012677817605435848\n",
      "0.013846601359546185\n",
      "0.01328223291784525\n",
      "0.012452244758605957\n",
      "0.012289962731301785\n",
      "0.012220978736877441\n",
      "0.013658126816153526\n",
      "0.01433171983808279\n",
      "0.012863696552813053\n",
      "0.013059725053608418\n",
      "0.01465437188744545\n",
      "0.012646135874092579\n",
      "0.012320971116423607\n",
      "0.011785059235990047\n",
      "0.013478001579642296\n",
      "0.011475038714706898\n",
      "0.01242821291089058\n",
      "0.013475696556270123\n",
      "0.01275675743818283\n",
      "0.012687799520790577\n",
      "0.013345400802791119\n",
      "0.01370470691472292\n",
      "0.013890995644032955\n",
      "0.012036423198878765\n",
      "0.01301303319633007\n",
      "0.012352220714092255\n",
      "0.011645205318927765\n",
      "0.012469514273107052\n"
     ]
    }
   ],
   "source": [
    "#test of the model\n",
    "test_data = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data in test_data:\n",
    "    img, _ = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    img = Variable(img).to(device)\n",
    "    output = model(img)\n",
    "    pic = to_img(output.cpu().data)\n",
    "    save_image(pic, './mlp_img/image_test.png')\n",
    "#accuracy of the autoencoder comparing input and output\n",
    "loss_sum = 0\n",
    "for data in test_data:\n",
    "    img, _ = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    img = Variable(img).to(device)\n",
    "    output = model(img)\n",
    "    loss = criterion(output, img)\n",
    "    loss_sum += loss.item()\n",
    "\n",
    "print(loss_sum/len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torchviz.png'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "y = model(img)\n",
    "make_dot(y, params=dict(list(model.named_parameters()))).render(\"torchviz\", format=\"png\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
