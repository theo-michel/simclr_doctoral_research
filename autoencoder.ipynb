{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wandb\n",
    "%pip install graphviz\n",
    "%pip install torchviz\n",
    "import wandb\n",
    "wandb.login()#doesnt detect WANDB_NOTEBOOK_NAME on windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"test-project\", entity=\"simclr-doctoral-research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 10,\n",
    "  \"batch_size\": 512\n",
    "}\n",
    "image_size = 32\n",
    "image_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST,CIFAR10\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')\n",
    "\n",
    "\n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), image_depth, image_size, image_size)\n",
    "    return x\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 512\n",
    "learning_rate = 1e-3\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# dataset_train = MNIST('./data', transform=img_transform, download=True,train = True)\n",
    "# dataset_test = MNIST('./data', transform=img_transform, download=True,train = False)\n",
    "dataset_train = CIFAR10('./data', transform=img_transform, download=True,train = True)\n",
    "dataset_test = CIFAR10('./data', transform=img_transform, download=True,train = False)\n",
    "\n",
    "dataloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(image_size * image_size*image_depth, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 128))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256,image_size * image_size*image_depth), \n",
    "            nn.Tanh())\n",
    "    def forward(self, x,only_encode=False):\n",
    "        if only_encode:\n",
    "            return self.encoder(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(str(device)+\" is being used\")\n",
    "auto_model = AutoEncoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(auto_model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img, _ = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img).to(device)\n",
    "        # ===================forward=====================\n",
    "        output = auto_model(img)\n",
    "        loss = criterion(output, img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.item()))\n",
    "    if epoch % 10 == 0:\n",
    "        pic = to_img(output.cpu().data)\n",
    "        save_image(pic, './mlp_img/image_{}.png'.format(epoch))\n",
    "    wandb.log({\"loss\": loss})\n",
    "\n",
    "    wandb.watch(auto_model)\n",
    "    #print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, num_epochs, loss.data[0]))\n",
    "\n",
    "pic = to_img(output.cpu().data)\n",
    "save_image(pic, './mlp_img/image_final.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test of the loss of the encoder on test data\n",
    "test_data = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data in test_data:\n",
    "    img, _ = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    img = Variable(img).to(device)\n",
    "    output = auto_model(img)\n",
    "    pic = to_img(output.cpu().data)\n",
    "    save_image(pic, './mlp_img/autencoder.png')\n",
    "#accuracy of the autoencoder comparing input and output\n",
    "loss_sum = 0\n",
    "for data in test_data:\n",
    "    img, _ = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    img = Variable(img).to(device)\n",
    "    output = auto_model(img)\n",
    "    loss = criterion(output, img)\n",
    "    loss_sum += loss.item()\n",
    "\n",
    "print(loss_sum/len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "y = auto_model(img)\n",
    "make_dot(y, params=dict(list(auto_model.named_parameters()))).render(\"torchviz\", format=\"png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the encoder is going to be frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze the encoder\n",
    "# print(model.state_dict())\n",
    "\n",
    "auto_model.encoder[0].weight.requires_grad = False\n",
    "auto_model.encoder[0].bias.requires_grad = False\n",
    "auto_model.encoder[2].weight.requires_grad = False\n",
    "auto_model.encoder[2].bias.requires_grad = False\n",
    "\n",
    "#show that it has been frozen\n",
    "for name, param in auto_model.named_parameters():\n",
    "    print(name, param.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save the encoder (optionnal)\n",
    "# os.makedirs('./saved_models', exist_ok=True)#the frost in not saved\n",
    "# torch.save(auto_model.state_dict(), './saved_models/autoencoder.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear_classifier import LinearClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #load the encoder (optionnal)\n",
    "# model.load_state_dict(torch.load('./saved_models/autoencoder.pth'))\n",
    "# #add a mlp to the encoder\n",
    "# model.add_module('linear_classifier', linear_classifier())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joined model\n",
    "class JoinedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JoinedModel, self).__init__()\n",
    "        self.encoder = auto_model.encoder\n",
    "        self.classifier = LinearClassifier()\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "joined_model = JoinedModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we make sure they are frozen (we should remove the one above )\n",
    "joined_model.encoder[0].weight.requires_grad = False\n",
    "joined_model.encoder[0].bias.requires_grad = False\n",
    "joined_model.encoder[2].weight.requires_grad = False\n",
    "joined_model.encoder[2].bias.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify weight are frozen\n",
    "\n",
    "for name, param in joined_model.named_parameters():\n",
    "    print(name, param.requires_grad)\n",
    "print(joined_model.parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function that calculates the accuracy of the model on the test set\n",
    "def test_accuracy(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.view(images.size(0), -1)\n",
    "            images = Variable(images).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the classifcation head of the model on the train data\n",
    "# model = model.to(device)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "test_accuracy_list = []\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, joined_model.parameters()), lr=learning_rate, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img).to(device)\n",
    "        label = Variable(label).to(device)\n",
    "        # ===================forward=====================\n",
    "        output = joined_model(img)#This should train the classifier\n",
    "        loss = criterion(output, label)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "            .format(epoch + 1, num_epochs, loss.item()))\n",
    "    wandb.log({\"loss\": loss})\n",
    "    wandb.watch(joined_model)\n",
    "    #calculate the accuracy of the model on the test set\n",
    "    test_accuracy_list.append(test_accuracy(joined_model, test_loader))\n",
    "    print(\"Test accuracy: {}\".format(test_accuracy_list[-1]))\n",
    "#plot the accuracy of the model over the epochs\n",
    "#epochs in axis x\n",
    "epochs = np.arange(1, num_epochs+1)\n",
    "#accuracy in axis y\n",
    "accuracy = test_accuracy_list\n",
    "plt.plot(epochs, accuracy, label='accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the loss one the test data\n",
    "loss_sum = 0\n",
    "\n",
    "for data in test_data:\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    img = Variable(img).to(device)\n",
    "    label = Variable(label).to(device)\n",
    "    output = joined_model(img)\n",
    "    loss = criterion(output, label)\n",
    "    loss_sum += loss.item()\n",
    "\n",
    "\n",
    "print(loss_sum/len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# from fastai.vision.all import show_image\n",
    "#show results of the model\n",
    "\n",
    "\n",
    "for data in test_data:\n",
    "    img, label = data\n",
    "    img = img.view(img.size(0), -1)\n",
    "    img = Variable(img).to(device)\n",
    "    #label = Variable(label).to(device)\n",
    "    output = joined_model(img)\n",
    "    pic = to_img(img.cpu().data)\n",
    "    # save_image(pic, './mlp_img/image_test.png')\n",
    "    #show predicted label for the image\n",
    "    #print(output.argmax(dim=1))\n",
    "    #show the true label for the image\n",
    "    #print(label)\n",
    "    #show the image\n",
    "    plt.imshow(np.transpose(img.view(img.size(0), image_depth, image_size, image_size).cpu().data[0], (1,2, 0)))\n",
    "    #show the label corresponding to the image\n",
    "    #print class name\n",
    "\n",
    "    plt.title(dataset_test.classes[label.cpu().data[0]]+\" predicted :\"+ dataset_test.classes[output.argmax(dim=1)[0]])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model:\n",
    "joined_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in test_data:\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        img = Variable(img).to(device)\n",
    "        label = Variable(label).to(device)\n",
    "        output = joined_model(img)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted == label).sum().item()\n",
    "    print(\"accuracy: \", correct/total)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the directoruy does not exist, create it\n",
    "if not os.path.exists('./saved_models'):\n",
    "    os.makedirs('./saved_models')\n",
    "#save the joined_model\n",
    "torch.save(joined_model.state_dict(), './saved_models/auto_encoder_saved_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
