{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function that calculates the accuracy of the model on the test set\n",
    "def test_accuracy(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=False, num_classes=10)\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet18, self).__init__()\n",
    "    \n",
    "        self.adapter= nn.Sequential( nn.Linear(512, 128), nn.ReLU() )\n",
    "   \n",
    "        self.conv1 = resnet18.conv1\n",
    "        self.bn1 = resnet18.bn1\n",
    "        self.relu = resnet18.relu\n",
    "        self.maxpool = resnet18.maxpool\n",
    "        self.layer1 = resnet18.layer1\n",
    "        self.layer2 = resnet18.layer2\n",
    "        self.layer3 = resnet18.layer3\n",
    "        self.layer4 = resnet18.layer4\n",
    "        self.avgpool = resnet18.avgpool\n",
    "        self.fc = nn.Sequential( nn.Linear(128, num_classes))\n",
    "        # print(self)\n",
    "\n",
    "    def forward(self, x, no_fc=False):\n",
    "        # See note [TorchScript super()]\n",
    "        # print(self)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.adapter(x)\n",
    "        if no_fc:\n",
    "            return x\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')\n",
    "\n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 32, 32)\n",
    "    return x\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 512\n",
    "learning_rate = 1e-3\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# dataset_train = MNIST('./data', transform=img_transform, download=True,train = True)\n",
    "# dataset_test = MNIST('./data', transform=img_transform, download=True,train = False)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32,padding=4),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "dataset_train = CIFAR10('./data', transform=train_transform, download=True,train = True)\n",
    "dataset_test = CIFAR10('./data', transform=test_transform, download=True,train = False)\n",
    "\n",
    "\n",
    "# dataloader\n",
    "train_loader = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "# dataloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "# in this cell, I want to train the model and save the weights\n",
    "\n",
    "# device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device=torch.device('cuda'if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "modelResnet=ResNet18(num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(modelResnet.parameters(), lr=learning_rate)\n",
    "test_accuracy_list_before_freeze = []\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        print(i)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = modelResnet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"Epoch: {}/{}\".format(epoch, num_epochs - 1))\n",
    "    #calculate the accuracy of the model on the test set\n",
    "    test_accuracy_list_before_freeze.append(test_accuracy(modelResnet, test_loader))\n",
    "    print(\"Test accuracy: {}\".format(test_accuracy_list_before_freeze[-1]))\n",
    "#plot the accuracy of the model over the epochs\n",
    "#epochs in axis x\n",
    "epochs = np.arange(1, num_epochs+1)\n",
    "#accuracy in axis y\n",
    "accuracy = test_accuracy_list_before_freeze\n",
    "plt.plot(epochs, accuracy, label='accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import torchvision.models as models\n",
    "#show what the model is made of we can compare it to the original resnet 18\n",
    "# resnet18 = models.resnet18()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "summary(modelResnet, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = modelResnet(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "    # save the model\n",
    "    torch.save(modelResnet.state_dict(), './resnet18.pth')\n",
    "    # save the image\n",
    "    img = images[0].cpu()\n",
    "    img = img.view(1, 3, 32, 32)\n",
    "    save_image(img, './mlp_img/image_{}.png'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from linear_classifier import LinearClassifier\n",
    "#joined model\n",
    "class JoinedModel(nn.Module):\n",
    "    def __init__(self,num_classes=10):\n",
    "        \n",
    "        super(JoinedModel, self).__init__()\n",
    "        #uses the resnets weights already trained\n",
    "        self.resnet = modelResnet\n",
    "        #classifier parts\n",
    "        self.classifier = LinearClassifier()\n",
    "    def forward(self, x):\n",
    "        x = self.resnet.forward(x,no_fc=True)\n",
    "        #classifier part\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "joined_model = JoinedModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "summary(joined_model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(joined_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze all weights \n",
    "for param in joined_model.parameters():\n",
    "    param.requires_grad = False\n",
    "#unfreeze the classifier\n",
    "joined_model.classifier.fc1.weight.requires_grad = True\n",
    "joined_model.classifier.fc1.bias.requires_grad = True\n",
    "joined_model.classifier.fc2.weight.requires_grad = True\n",
    "joined_model.classifier.fc2.bias.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify weight are frozen\n",
    "\n",
    "for name, param in joined_model.named_parameters():\n",
    "    print(name, param.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the joined model\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, joined_model.parameters()), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#a function that plots the accuracy of the model over the epochs\n",
    "# def plot_accuracy(model, train_loader, test_loader):\n",
    "#     # Plot the accuracy\n",
    "#     train_acc = []\n",
    "#     test_acc = []\n",
    "#     for epoch in range(num_epochs):\n",
    "#         print(\"Epoch: {}\".format(epoch))\n",
    "#         for i, (images, labels) in enumerate(train_loader):\n",
    "#             print(i)\n",
    "#             images = images.to(device)\n",
    "#             labels = labels.to(device)\n",
    "\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             print(\"Epoch: {}/{}\".format(epoch, num_epochs - 1))\n",
    "#         train_acc.append(test_accuracy(model, train_loader))\n",
    "#         test_acc.append(test_accuracy(model, test_loader))\n",
    "\n",
    "#     plt.plot(train_acc, label='train')\n",
    "#     plt.plot(test_acc, label='test')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_accuracy_list=[]\n",
    "#train the classification layer\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch: {}\".format(epoch))\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        print(i)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = joined_model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"Epoch: {}/{}\".format(epoch, num_epochs - 1))\n",
    "    #calculate the accuracy of the model on the test set\n",
    "    test_accuracy_list.append(test_accuracy(joined_model, test_loader))\n",
    "    print(\"Test accuracy: {}\".format(test_accuracy_list[-1]))\n",
    "#plot the accuracy of the model over the epochs\n",
    "#epochs in axis x\n",
    "epochs = np.arange(1, num_epochs+1)\n",
    "#accuracy in axis y\n",
    "accuracy = test_accuracy_list\n",
    "plt.plot(epochs, accuracy, label='accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the joined model \n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = joined_model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "    # save the model\n",
    "    torch.save(joined_model.state_dict(), './joined_model.pth')\n",
    "    # save the image\n",
    "    img = images[0].cpu()\n",
    "    img = img.view(1, 3, 32, 32)\n",
    "    save_image(img, './mlp_img_resnet/image_{}.png'.format(epoch))\n",
    "\n",
    "\n",
    "# make a graph of the accuracy vs epoch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the joined_model for resnet supervised encoder\n",
    "torch.save(joined_model.state_dict(), './saved_models/joined_model_resnet_supervised.pth')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
