{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import os\n",
    "import wandb\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.resnet = models.resnet18(pretrained=False, num_classes=num_classes)\n",
    "        self.adapter= nn.Sequential( nn.Linear(512, 128), nn.ReLU() )\n",
    "        self.resnet.fc = nn.Sequential( nn.Linear(128, num_classes))\n",
    "        self.conv1 = self.resnet.conv1\n",
    "        self.bn1 = self.resnet.bn1\n",
    "        self.relu = self.resnet.relu\n",
    "        self.maxpool = self.resnet.maxpool\n",
    "        self.layer1 = self.resnet.layer1\n",
    "        self.layer2 = self.resnet.layer2\n",
    "        self.layer3 = self.resnet.layer3\n",
    "        self.layer4 = self.resnet.layer4\n",
    "        self.avgpool = self.resnet.avgpool\n",
    "        self.fc = self.resnet.fc\n",
    "\n",
    "    def forward(self, x, no_fc=False):\n",
    "        # See note [TorchScript super()]\n",
    "        print(self)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.adapter(x)\n",
    "        \n",
    "        \n",
    "        if no_fc:\n",
    "            return x\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')\n",
    "\n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 512\n",
    "learning_rate = 1e-3\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "dataset_train = MNIST('./data', transform=img_transform, download=True,train = True)\n",
    "dataset_test = MNIST('./data', transform=img_transform, download=True,train = False)\n",
    "\n",
    "dataloader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a programm that trains the model on dataset_train and evaluates it on dataset_test\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNet18(10).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (img, label) in enumerate(dataloader):\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        output = model(img)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, len(dataloader), loss.item()))\n",
    "\n",
    "    # Save the model checkpoints\n",
    "    torch.save(model.state_dict(), './resnet.ckpt')\n",
    "\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test dataset\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for img, label in dataloader:\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        output = model(img)\n",
    "        test_loss += criterion(output, label).item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(dataloader.dataset)\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "        .format(test_loss, correct, len(dataloader.dataset),\n",
    "                100. * correct / len(dataloader.dataset)))\n",
    "\n",
    "# Save the model checkpoints\n",
    "torch.save(model.state_dict(), './resnet.ckpt')\n",
    "\n",
    "# Evaluate the model using the test dataset\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for img, label in dataloader:\n",
    "        img = img.to(device)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
