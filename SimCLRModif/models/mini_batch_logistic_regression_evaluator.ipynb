{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sthalles/SimCLR/blob/simclr-refactor/feature_eval/mini_batch_logistic_regression_evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YUemQib7ZE4D"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import yaml\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSgRE1CcLqdS",
        "outputId": "48a2ae15-f672-495b-8d43-9a23b85fa3b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in c:\\python310\\lib\\site-packages (4.4.0)\n",
            "Requirement already satisfied: filelock in c:\\python310\\lib\\site-packages (from gdown) (3.7.0)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\python310\\lib\\site-packages (from gdown) (4.10.0)\n",
            "Requirement already satisfied: requests[socks] in c:\\python310\\lib\\site-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: tqdm in c:\\python310\\lib\\site-packages (from gdown) (4.64.0)\n",
            "Requirement already satisfied: six in c:\\python310\\lib\\site-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\python310\\lib\\site-packages (from beautifulsoup4->gdown) (2.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests[socks]->gdown) (1.26.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\python310\\lib\\site-packages (from requests[socks]->gdown) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\python310\\lib\\site-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python310\\lib\\site-packages (from requests[socks]->gdown) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\python310\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm->gdown) (0.4.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "NOIJEui1ZziV"
      },
      "outputs": [],
      "source": [
        "def get_file_id_by_model(folder_name):\n",
        "  file_id = {'resnet18_100-epochs_stl10': '14_nH2FkyKbt61cieQDiSbBVNP8-gtwgF',\n",
        "             'resnet18_100-epochs_cifar10': '1lc2aoVtrAetGn0PnTkOyFzPCIucOJq7C',\n",
        "             'resnet50_50-epochs_stl10': '1ByTKAUsdm_X7tLcii6oAEl5qFRqRMZSu'}\n",
        "  return file_id.get(folder_name, \"Model not found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7YMxsvEZMrX",
        "outputId": "59475430-69d2-45a2-b61b-ae755d5d6e88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "resnet50_50-epochs_stl10 1ByTKAUsdm_X7tLcii6oAEl5qFRqRMZSu\n"
          ]
        }
      ],
      "source": [
        "folder_name = 'resnet50_50-epochs_stl10'\n",
        "file_id = get_file_id_by_model(folder_name)\n",
        "print(folder_name, file_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWZ8fet_YoJm",
        "outputId": "fbaeb858-221b-4d1b-dd90-001a6e713b75"
      },
      "outputs": [],
      "source": [
        "# download and extract model files\n",
        "# os.system('gdown https://drive.google.com/uc?id={}'.format(file_id))\n",
        "# os.system('unzip {}'.format(folder_name))\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "3_nypQVEv-hn"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDfbL3w_Z0Od",
        "outputId": "7532966e-1c4a-4641-c928-4cda14c53389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "BfIPl0G6_RrT"
      },
      "outputs": [],
      "source": [
        "def get_stl10_data_loaders(download, shuffle=False, batch_size=256):\n",
        "  train_dataset = datasets.STL10('./data', split='train', download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                            num_workers=3, drop_last=False, shuffle=shuffle)\n",
        "  \n",
        "  test_dataset = datasets.STL10('./data', split='test', download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
        "                            num_workers=3, drop_last=False, shuffle=shuffle)#changed num of workers\n",
        "  return train_loader, test_loader\n",
        "\n",
        "def get_cifar10_data_loaders(download, shuffle=False, batch_size=256):\n",
        "  train_dataset = datasets.CIFAR10('./data', train=True, download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                            num_workers=3, drop_last=False, shuffle=shuffle)\n",
        "  \n",
        "  test_dataset = datasets.CIFAR10('./data', train=False, download=download,\n",
        "                                  transform=transforms.ToTensor())\n",
        "\n",
        "  test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
        "                            num_workers=3, drop_last=False, shuffle=shuffle)\n",
        "  return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "6N8lYkbmDTaK"
      },
      "outputs": [],
      "source": [
        "# with open(os.path.join('./config.yml')) as file:\n",
        "#   config = yaml.load(file)\n",
        "\n",
        "class config_class:\n",
        "  arch = \"resnet18\"\n",
        "  dataset_name = \"cifar10\"\n",
        "  def __init__(self):\n",
        "    self.arch\n",
        "    self.dataset_name\n",
        "\n",
        "config = config_class()\n",
        "config.arch = \"resnet18\"\n",
        "config.dataset_name = \"cifar10\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "a18lPD-tIle6"
      },
      "outputs": [],
      "source": [
        "from resnet_simclr import ResNetSimCLR\n",
        "# from models.resnet_simclr import  resnet_simclr\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if config.arch == 'resnet18':\n",
        "  model = ResNetSimCLR(base_model='resnet18', out_dim=10).to(device)\n",
        "elif config.arch == 'resnet50':\n",
        "  model = torchvision.models.resnet50(pretrained=False, num_classes=10).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "4AIfgq41GuTT"
      },
      "outputs": [],
      "source": [
        "# checkpoint = torch.load('checkpoint_0040.pth.tar', map_location=device)\n",
        "# state_dict = checkpoint['state_dict']\n",
        "\n",
        "# for k in list(state_dict.keys()):\n",
        "\n",
        "#   if k.startswith('backbone.'):\n",
        "#     if k.startswith('backbone') and not k.startswith('backbone.fc'):\n",
        "#       # remove prefix\n",
        "#       state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n",
        "#   del state_dict[k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "VVjA83PPJYWl"
      },
      "outputs": [],
      "source": [
        "# log = model.load_state_dict(state_dict, strict=False)\n",
        "# assert log.missing_keys == ['fc.weight', 'fc.bias']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "149b9ce8fb68473a837a77431c12281a",
            "88cd3db2831e4c13a4a634709700d6b2",
            "a88c31d74f5c40a2b24bcff5a35d216c",
            "60c6150177694717a622936b830427b5",
            "dba019efadee4fdc8c799f309b9a7e70",
            "5901c2829a554c8ebbd5926610088041",
            "957362a11d174407979cf17012bf9208",
            "a4f82234388e4701a02a9f68a177193a"
          ]
        },
        "id": "_GC0a14uWRr6",
        "outputId": "4c2558db-921c-425e-f947-6cc746d8c749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Dataset: cifar10\n"
          ]
        }
      ],
      "source": [
        "if config.dataset_name == 'cifar10':\n",
        "  train_loader, test_loader = get_cifar10_data_loaders(download=True)\n",
        "elif config.dataset_name == 'stl10':\n",
        "  train_loader, test_loader = get_stl10_data_loaders(download=True)\n",
        "print(\"Dataset:\", config.dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "aPVh1S_eMRDU"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.0008)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "edr6RhP2PdVq"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
            "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
            "             ReLU-14             [-1, 64, 8, 8]               0\n",
            "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
            "             ReLU-17             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
            "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
            "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
            "             ReLU-21            [-1, 128, 4, 4]               0\n",
            "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
            "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
            "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
            "             ReLU-26            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
            "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
            "             ReLU-30            [-1, 128, 4, 4]               0\n",
            "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
            "             ReLU-33            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
            "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
            "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
            "             ReLU-37            [-1, 256, 2, 2]               0\n",
            "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
            "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
            "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
            "             ReLU-42            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
            "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
            "             ReLU-46            [-1, 256, 2, 2]               0\n",
            "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
            "             ReLU-49            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
            "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-53            [-1, 512, 1, 1]               0\n",
            "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
            "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-58            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
            "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-62            [-1, 512, 1, 1]               0\n",
            "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-65            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                  [-1, 128]          65,664\n",
            "           ResNet-69                  [-1, 128]               0\n",
            "           Linear-70                  [-1, 128]          16,512\n",
            "             ReLU-71                  [-1, 128]               0\n",
            "           Linear-72                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 11,259,978\n",
            "Trainable params: 11,259,978\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.29\n",
            "Params size (MB): 42.95\n",
            "Estimated Total Size (MB): 44.25\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#visualize the dataset\n",
        "\n",
        "import torch\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "import torchvision.models as models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "summary(model, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOder0dAMI7X",
        "outputId": "5f723b91-5a5e-43eb-ca01-a9b5ae2f1346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Started epoch 0\n",
            "Batch 0\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 1\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 2\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 3\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 4\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 5\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 6\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 7\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 8\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 9\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 10\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 11\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 12\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 13\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 14\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 15\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 16\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 17\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 18\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 19\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 20\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 21\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 22\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 23\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 24\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 25\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 26\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 27\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 28\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 29\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 30\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 31\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 32\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 33\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 34\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 35\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 36\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 37\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 38\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 39\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 40\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 41\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 42\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 43\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 44\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 45\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 46\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 47\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 48\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 49\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 50\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 51\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 52\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 53\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 54\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 55\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 56\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 57\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 58\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 59\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 60\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 61\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 62\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 63\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 64\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 65\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 66\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 67\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 68\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 69\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 70\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 71\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 72\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 73\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 74\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 75\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 76\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 77\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 78\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 79\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 80\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 81\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 82\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 83\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 84\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 85\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 86\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 87\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 88\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 89\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 90\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 91\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 92\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 93\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 94\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 95\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 96\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 97\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 98\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 99\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 100\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 101\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 102\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 103\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 104\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 105\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 106\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 107\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 108\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 109\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 110\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 111\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 112\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 113\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 114\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 115\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 116\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 117\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 118\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 119\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 120\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 121\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 122\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 123\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 124\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 125\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 126\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 127\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 128\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 129\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 130\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 131\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 132\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 133\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 134\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 135\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 136\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 137\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 138\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 139\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 140\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 141\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 142\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 143\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 144\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 145\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 146\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 147\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 148\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 149\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 150\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 151\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 152\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 153\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 154\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 155\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 156\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 157\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 158\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 159\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 160\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 161\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 162\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 163\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 164\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 165\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 166\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 167\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 168\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 169\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 170\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 171\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 172\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 173\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 174\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 175\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 176\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 177\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 178\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 179\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 180\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 181\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 182\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 183\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 184\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 185\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 186\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 187\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 188\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 189\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 190\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 191\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 192\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 193\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 194\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 195\n",
            "x_batch: torch.Size([80, 3, 32, 32])\n",
            "y_batch: torch.Size([80])\n",
            "Epoch 0\tTop1 Train accuracy 48.18319320678711\tTop1 Test accuracy: 57.15418243408203\tTop5 test acc: 95.52619934082031\n",
            "Started epoch 1\n",
            "Batch 0\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 1\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 2\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 3\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 4\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 5\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 6\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 7\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 8\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 9\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 10\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 11\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 12\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 13\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 14\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 15\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 16\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 17\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 18\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 19\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 20\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 21\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 22\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 23\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 24\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 25\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 26\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 27\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 28\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 29\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 30\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 31\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 32\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 33\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 34\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 35\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 36\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 37\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 38\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 39\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 40\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 41\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 42\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 43\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 44\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 45\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 46\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 47\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 48\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 49\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 50\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 51\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 52\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 53\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 54\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 55\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 56\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 57\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 58\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 59\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 60\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 61\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 62\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 63\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 64\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 65\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 66\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 67\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 68\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 69\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 70\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 71\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 72\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 73\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 74\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 75\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 76\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 77\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 78\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 79\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 80\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 81\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 82\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 83\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 84\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 85\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 86\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 87\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 88\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 89\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 90\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 91\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 92\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 93\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 94\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 95\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 96\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 97\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 98\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 99\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 100\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 101\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 102\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 103\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 104\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 105\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 106\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 107\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 108\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 109\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 110\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 111\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 112\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 113\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 114\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 115\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 116\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 117\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 118\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 119\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 120\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 121\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 122\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 123\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 124\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 125\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 126\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 127\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 128\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 129\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 130\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 131\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 132\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 133\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 134\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 135\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 136\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 137\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 138\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 139\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 140\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 141\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 142\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 143\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 144\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 145\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 146\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 147\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 148\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 149\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 150\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 151\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 152\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 153\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 154\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 155\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 156\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 157\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 158\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 159\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 160\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 161\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 162\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 163\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 164\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 165\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 166\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 167\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 168\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 169\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 170\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 171\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 172\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 173\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 174\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 175\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 176\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 177\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 178\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 179\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 180\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 181\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 182\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 183\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 184\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 185\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 186\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 187\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 188\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 189\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 190\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 191\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 192\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 193\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 194\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 195\n",
            "x_batch: torch.Size([80, 3, 32, 32])\n",
            "y_batch: torch.Size([80])\n",
            "Epoch 1\tTop1 Train accuracy 63.398834228515625\tTop1 Test accuracy: 62.88660430908203\tTop5 test acc: 96.6773910522461\n",
            "Started epoch 2\n",
            "Batch 0\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 1\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 2\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 3\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 4\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 5\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 6\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 7\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 8\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 9\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 10\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 11\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 12\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 13\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 14\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 15\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 16\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 17\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 18\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 19\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 20\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 21\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 22\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 23\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 24\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 25\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 26\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 27\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 28\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 29\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 30\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 31\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 32\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 33\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 34\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 35\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 36\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 37\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 38\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n",
            "Batch 39\n",
            "x_batch: torch.Size([256, 3, 32, 32])\n",
            "y_batch: torch.Size([256])\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\theob\\simclr_doctoral_research-1\\SimCLRModif\\models\\mini_batch_logistic_regression_evaluator.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/theob/simclr_doctoral_research-1/SimCLRModif/models/mini_batch_logistic_regression_evaluator.ipynb#ch0000017?line=3'>4</a>\u001b[0m top1_train_accuracy \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/theob/simclr_doctoral_research-1/SimCLRModif/models/mini_batch_logistic_regression_evaluator.ipynb#ch0000017?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m counter, (x_batch, y_batch) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/theob/simclr_doctoral_research-1/SimCLRModif/models/mini_batch_logistic_regression_evaluator.ipynb#ch0000017?line=5'>6</a>\u001b[0m   x_batch \u001b[39m=\u001b[39m x_batch\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/theob/simclr_doctoral_research-1/SimCLRModif/models/mini_batch_logistic_regression_evaluator.ipynb#ch0000017?line=6'>7</a>\u001b[0m   y_batch \u001b[39m=\u001b[39m y_batch\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/theob/simclr_doctoral_research-1/SimCLRModif/models/mini_batch_logistic_regression_evaluator.ipynb#ch0000017?line=7'>8</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBatch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(counter))\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "  print(\"Started epoch {}\".format(epoch))\n",
        "  top1_train_accuracy = 0\n",
        "  for counter, (x_batch, y_batch) in enumerate(train_loader):\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    print(\"Batch {}\".format(counter))\n",
        "    print(\"x_batch:\", x_batch.shape)\n",
        "    print(\"y_batch:\", y_batch.shape)\n",
        "    \n",
        "\n",
        "    logits = model(x_batch)\n",
        "    loss = criterion(logits, y_batch)\n",
        "    top1 = accuracy(logits, y_batch, topk=(1,))\n",
        "    top1_train_accuracy += top1[0]\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  top1_train_accuracy /= (counter + 1)\n",
        "  top1_accuracy = 0\n",
        "  top5_accuracy = 0\n",
        "  for counter, (x_batch, y_batch) in enumerate(test_loader):\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "\n",
        "    logits = model(x_batch)\n",
        "  \n",
        "    top1, top5 = accuracy(logits, y_batch, topk=(1,5))\n",
        "    top1_accuracy += top1[0]\n",
        "    top5_accuracy += top5[0]\n",
        "  \n",
        "  top1_accuracy /= (counter + 1)\n",
        "  top5_accuracy /= (counter + 1)\n",
        "  print(f\"Epoch {epoch}\\tTop1 Train accuracy {top1_train_accuracy.item()}\\tTop1 Test accuracy: {top1_accuracy.item()}\\tTop5 test acc: {top5_accuracy.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
            "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
            "             ReLU-14             [-1, 64, 8, 8]               0\n",
            "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
            "             ReLU-17             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
            "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
            "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
            "             ReLU-21            [-1, 128, 4, 4]               0\n",
            "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
            "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
            "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
            "             ReLU-26            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
            "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
            "             ReLU-30            [-1, 128, 4, 4]               0\n",
            "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
            "             ReLU-33            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
            "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
            "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
            "             ReLU-37            [-1, 256, 2, 2]               0\n",
            "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
            "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
            "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
            "             ReLU-42            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
            "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
            "             ReLU-46            [-1, 256, 2, 2]               0\n",
            "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
            "             ReLU-49            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
            "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-53            [-1, 512, 1, 1]               0\n",
            "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
            "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-58            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
            "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-62            [-1, 512, 1, 1]               0\n",
            "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-65            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                  [-1, 128]          65,664\n",
            "           ResNet-69                  [-1, 128]               0\n",
            "           Linear-70                  [-1, 128]          16,512\n",
            "             ReLU-71                  [-1, 128]               0\n",
            "           Linear-72                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 11,259,978\n",
            "Trainable params: 11,259,978\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.29\n",
            "Params size (MB): 42.95\n",
            "Estimated Total Size (MB): 44.25\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#visualize the dataset\n",
        "\n",
        "import torch\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "import torchvision.models as models\n",
        "#show what the model is made of we can compare it to the original resnet 18\n",
        "# resnet18 = models.resnet18()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "summary(model, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torchviz import make_dot\n",
        "# y = model(img)\n",
        "# make_dot(y, params=dict(list(auto_model.named_parameters()))).render(\"torchviz\", format=\"png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#compute model loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#copy and pasted because didn't manage to import it\n",
        "from torch import nn\n",
        "\n",
        "class LinearClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(128, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#joined model \n",
        "class JoinedModel(nn.Module):\n",
        "    def __init__(self,num_classes=10):\n",
        "        \n",
        "        super(JoinedModel, self).__init__()\n",
        "        #uses the resnets weights already trained\n",
        "        self.simCLR = model\n",
        "        #classifier parts\n",
        "        self.classifier = LinearClassifier()\n",
        "    def forward(self, x):\n",
        "        x = self.simCLR.forward(x,no_projection_head=True)\n",
        "        #classifier part\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "joined_model = JoinedModel().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtYqHZirMNZk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
            "              ReLU-7             [-1, 64, 8, 8]               0\n",
            "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
            "             ReLU-10             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-11             [-1, 64, 8, 8]               0\n",
            "           Conv2d-12             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-13             [-1, 64, 8, 8]             128\n",
            "             ReLU-14             [-1, 64, 8, 8]               0\n",
            "           Conv2d-15             [-1, 64, 8, 8]          36,864\n",
            "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
            "             ReLU-17             [-1, 64, 8, 8]               0\n",
            "       BasicBlock-18             [-1, 64, 8, 8]               0\n",
            "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
            "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
            "             ReLU-21            [-1, 128, 4, 4]               0\n",
            "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
            "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
            "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
            "             ReLU-26            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
            "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
            "             ReLU-30            [-1, 128, 4, 4]               0\n",
            "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
            "             ReLU-33            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
            "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
            "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
            "             ReLU-37            [-1, 256, 2, 2]               0\n",
            "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
            "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
            "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
            "             ReLU-42            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
            "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
            "             ReLU-46            [-1, 256, 2, 2]               0\n",
            "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
            "             ReLU-49            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
            "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-53            [-1, 512, 1, 1]               0\n",
            "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
            "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-58            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
            "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-62            [-1, 512, 1, 1]               0\n",
            "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-65            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                  [-1, 128]          65,664\n",
            "           ResNet-69                  [-1, 128]               0\n",
            "           Linear-70                  [-1, 128]          16,512\n",
            "             ReLU-71                  [-1, 128]               0\n",
            "           Linear-72                   [-1, 10]           1,290\n",
            " LinearClassifier-73                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 11,259,978\n",
            "Trainable params: 11,259,978\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 1.29\n",
            "Params size (MB): 42.95\n",
            "Estimated Total Size (MB): 44.25\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#verify the model shape\n",
        "summary(joined_model, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#freeze all weights \n",
        "for param in joined_model.parameters():\n",
        "    param.requires_grad = False\n",
        "#unfreeze the classifier\n",
        "joined_model.classifier.fc1.weight.requires_grad = True\n",
        "joined_model.classifier.fc1.bias.requires_grad = True\n",
        "joined_model.classifier.fc2.weight.requires_grad = True\n",
        "joined_model.classifier.fc2.bias.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "simCLR.backbone.conv1.weight False\n",
            "simCLR.backbone.bn1.weight False\n",
            "simCLR.backbone.bn1.bias False\n",
            "simCLR.backbone.layer1.0.conv1.weight False\n",
            "simCLR.backbone.layer1.0.bn1.weight False\n",
            "simCLR.backbone.layer1.0.bn1.bias False\n",
            "simCLR.backbone.layer1.0.conv2.weight False\n",
            "simCLR.backbone.layer1.0.bn2.weight False\n",
            "simCLR.backbone.layer1.0.bn2.bias False\n",
            "simCLR.backbone.layer1.1.conv1.weight False\n",
            "simCLR.backbone.layer1.1.bn1.weight False\n",
            "simCLR.backbone.layer1.1.bn1.bias False\n",
            "simCLR.backbone.layer1.1.conv2.weight False\n",
            "simCLR.backbone.layer1.1.bn2.weight False\n",
            "simCLR.backbone.layer1.1.bn2.bias False\n",
            "simCLR.backbone.layer2.0.conv1.weight False\n",
            "simCLR.backbone.layer2.0.bn1.weight False\n",
            "simCLR.backbone.layer2.0.bn1.bias False\n",
            "simCLR.backbone.layer2.0.conv2.weight False\n",
            "simCLR.backbone.layer2.0.bn2.weight False\n",
            "simCLR.backbone.layer2.0.bn2.bias False\n",
            "simCLR.backbone.layer2.0.downsample.0.weight False\n",
            "simCLR.backbone.layer2.0.downsample.1.weight False\n",
            "simCLR.backbone.layer2.0.downsample.1.bias False\n",
            "simCLR.backbone.layer2.1.conv1.weight False\n",
            "simCLR.backbone.layer2.1.bn1.weight False\n",
            "simCLR.backbone.layer2.1.bn1.bias False\n",
            "simCLR.backbone.layer2.1.conv2.weight False\n",
            "simCLR.backbone.layer2.1.bn2.weight False\n",
            "simCLR.backbone.layer2.1.bn2.bias False\n",
            "simCLR.backbone.layer3.0.conv1.weight False\n",
            "simCLR.backbone.layer3.0.bn1.weight False\n",
            "simCLR.backbone.layer3.0.bn1.bias False\n",
            "simCLR.backbone.layer3.0.conv2.weight False\n",
            "simCLR.backbone.layer3.0.bn2.weight False\n",
            "simCLR.backbone.layer3.0.bn2.bias False\n",
            "simCLR.backbone.layer3.0.downsample.0.weight False\n",
            "simCLR.backbone.layer3.0.downsample.1.weight False\n",
            "simCLR.backbone.layer3.0.downsample.1.bias False\n",
            "simCLR.backbone.layer3.1.conv1.weight False\n",
            "simCLR.backbone.layer3.1.bn1.weight False\n",
            "simCLR.backbone.layer3.1.bn1.bias False\n",
            "simCLR.backbone.layer3.1.conv2.weight False\n",
            "simCLR.backbone.layer3.1.bn2.weight False\n",
            "simCLR.backbone.layer3.1.bn2.bias False\n",
            "simCLR.backbone.layer4.0.conv1.weight False\n",
            "simCLR.backbone.layer4.0.bn1.weight False\n",
            "simCLR.backbone.layer4.0.bn1.bias False\n",
            "simCLR.backbone.layer4.0.conv2.weight False\n",
            "simCLR.backbone.layer4.0.bn2.weight False\n",
            "simCLR.backbone.layer4.0.bn2.bias False\n",
            "simCLR.backbone.layer4.0.downsample.0.weight False\n",
            "simCLR.backbone.layer4.0.downsample.1.weight False\n",
            "simCLR.backbone.layer4.0.downsample.1.bias False\n",
            "simCLR.backbone.layer4.1.conv1.weight False\n",
            "simCLR.backbone.layer4.1.bn1.weight False\n",
            "simCLR.backbone.layer4.1.bn1.bias False\n",
            "simCLR.backbone.layer4.1.conv2.weight False\n",
            "simCLR.backbone.layer4.1.bn2.weight False\n",
            "simCLR.backbone.layer4.1.bn2.bias False\n",
            "simCLR.backbone.fc.0.weight False\n",
            "simCLR.backbone.fc.0.bias False\n",
            "simCLR.projection_head.0.weight False\n",
            "simCLR.projection_head.0.bias False\n",
            "simCLR.projection_head.2.weight False\n",
            "simCLR.projection_head.2.bias False\n",
            "classifier.fc1.weight True\n",
            "classifier.fc1.bias True\n",
            "classifier.fc2.weight True\n",
            "classifier.fc2.bias True\n"
          ]
        }
      ],
      "source": [
        "#verify weight are frozen\n",
        "\n",
        "for name, param in joined_model.named_parameters():\n",
        "    print(name, param.requires_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "#train the joined model\n",
        "learning_rate = 1e-3\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, joined_model.parameters()), lr=learning_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "0\n",
            "Loss: 0.5399525761604309\n",
            "Epoch: 0/9\n",
            "1\n",
            "Loss: 0.519212007522583\n",
            "Epoch: 0/9\n",
            "2\n",
            "Loss: 0.45982852578163147\n",
            "Epoch: 0/9\n",
            "3\n",
            "Loss: 0.545820415019989\n",
            "Epoch: 0/9\n",
            "4\n",
            "Loss: 0.6507019400596619\n",
            "Epoch: 0/9\n",
            "5\n",
            "Loss: 0.5678039789199829\n",
            "Epoch: 0/9\n",
            "6\n",
            "Loss: 0.5231722593307495\n",
            "Epoch: 0/9\n",
            "7\n",
            "Loss: 0.65208500623703\n",
            "Epoch: 0/9\n",
            "8\n",
            "Loss: 0.6153600811958313\n",
            "Epoch: 0/9\n",
            "9\n",
            "Loss: 0.5568593144416809\n",
            "Epoch: 0/9\n",
            "10\n",
            "Loss: 0.5739806294441223\n",
            "Epoch: 0/9\n",
            "11\n",
            "Loss: 0.712602972984314\n",
            "Epoch: 0/9\n",
            "12\n",
            "Loss: 0.6553792357444763\n",
            "Epoch: 0/9\n",
            "13\n",
            "Loss: 0.5993602871894836\n",
            "Epoch: 0/9\n",
            "14\n",
            "Loss: 0.6396824717521667\n",
            "Epoch: 0/9\n",
            "15\n",
            "Loss: 0.6791321039199829\n",
            "Epoch: 0/9\n",
            "16\n",
            "Loss: 0.704905092716217\n",
            "Epoch: 0/9\n",
            "17\n",
            "Loss: 0.7251819372177124\n",
            "Epoch: 0/9\n",
            "18\n",
            "Loss: 0.6250635981559753\n",
            "Epoch: 0/9\n",
            "19\n",
            "Loss: 0.6624881029129028\n",
            "Epoch: 0/9\n",
            "20\n",
            "Loss: 0.6796400547027588\n",
            "Epoch: 0/9\n",
            "21\n",
            "Loss: 0.6937943696975708\n",
            "Epoch: 0/9\n",
            "22\n",
            "Loss: 0.6520704030990601\n",
            "Epoch: 0/9\n",
            "23\n",
            "Loss: 0.6232017278671265\n",
            "Epoch: 0/9\n",
            "24\n",
            "Loss: 0.6794021129608154\n",
            "Epoch: 0/9\n",
            "25\n",
            "Loss: 0.7212855219841003\n",
            "Epoch: 0/9\n",
            "26\n",
            "Loss: 0.7125237584114075\n",
            "Epoch: 0/9\n",
            "27\n",
            "Loss: 0.6971930861473083\n",
            "Epoch: 0/9\n",
            "28\n",
            "Loss: 0.6217233538627625\n",
            "Epoch: 0/9\n",
            "29\n",
            "Loss: 0.7072402238845825\n",
            "Epoch: 0/9\n",
            "30\n",
            "Loss: 0.6379597187042236\n",
            "Epoch: 0/9\n",
            "31\n",
            "Loss: 0.6722524166107178\n",
            "Epoch: 0/9\n",
            "32\n",
            "Loss: 0.5780640244483948\n",
            "Epoch: 0/9\n",
            "33\n",
            "Loss: 0.7093188762664795\n",
            "Epoch: 0/9\n",
            "34\n",
            "Loss: 0.6631382703781128\n",
            "Epoch: 0/9\n",
            "35\n",
            "Loss: 0.6936171650886536\n",
            "Epoch: 0/9\n",
            "36\n",
            "Loss: 0.7741262316703796\n",
            "Epoch: 0/9\n",
            "37\n",
            "Loss: 0.6469821929931641\n",
            "Epoch: 0/9\n",
            "38\n",
            "Loss: 0.6509790420532227\n",
            "Epoch: 0/9\n",
            "39\n",
            "Loss: 0.7515932321548462\n",
            "Epoch: 0/9\n",
            "40\n",
            "Loss: 0.7390907406806946\n",
            "Epoch: 0/9\n",
            "41\n",
            "Loss: 0.6062992811203003\n",
            "Epoch: 0/9\n",
            "42\n",
            "Loss: 0.6871674060821533\n",
            "Epoch: 0/9\n",
            "43\n",
            "Loss: 0.8269345164299011\n",
            "Epoch: 0/9\n",
            "44\n",
            "Loss: 0.6518341302871704\n",
            "Epoch: 0/9\n",
            "45\n",
            "Loss: 0.6268110275268555\n",
            "Epoch: 0/9\n",
            "46\n",
            "Loss: 0.6569375395774841\n",
            "Epoch: 0/9\n",
            "47\n",
            "Loss: 0.7287387847900391\n",
            "Epoch: 0/9\n",
            "48\n",
            "Loss: 0.7359456419944763\n",
            "Epoch: 0/9\n",
            "49\n",
            "Loss: 0.665645956993103\n",
            "Epoch: 0/9\n",
            "50\n",
            "Loss: 0.7057380080223083\n",
            "Epoch: 0/9\n",
            "51\n",
            "Loss: 0.7616531848907471\n",
            "Epoch: 0/9\n",
            "52\n",
            "Loss: 0.7168780565261841\n",
            "Epoch: 0/9\n",
            "53\n",
            "Loss: 0.7753373384475708\n",
            "Epoch: 0/9\n",
            "54\n",
            "Loss: 0.7181347608566284\n",
            "Epoch: 0/9\n",
            "55\n",
            "Loss: 0.6906226873397827\n",
            "Epoch: 0/9\n",
            "56\n",
            "Loss: 0.7335733771324158\n",
            "Epoch: 0/9\n",
            "57\n",
            "Loss: 0.6561734080314636\n",
            "Epoch: 0/9\n",
            "58\n",
            "Loss: 0.6271330118179321\n",
            "Epoch: 0/9\n",
            "59\n",
            "Loss: 0.6591664552688599\n",
            "Epoch: 0/9\n",
            "60\n",
            "Loss: 0.650070071220398\n",
            "Epoch: 0/9\n",
            "61\n",
            "Loss: 0.6077945232391357\n",
            "Epoch: 0/9\n",
            "62\n",
            "Loss: 0.6612212061882019\n",
            "Epoch: 0/9\n",
            "63\n",
            "Loss: 0.6056535840034485\n",
            "Epoch: 0/9\n",
            "64\n",
            "Loss: 0.6042820811271667\n",
            "Epoch: 0/9\n",
            "65\n",
            "Loss: 0.5446507334709167\n",
            "Epoch: 0/9\n",
            "66\n",
            "Loss: 0.5572928786277771\n",
            "Epoch: 0/9\n",
            "67\n",
            "Loss: 0.6605613231658936\n",
            "Epoch: 0/9\n",
            "68\n",
            "Loss: 0.6156597137451172\n",
            "Epoch: 0/9\n",
            "69\n",
            "Loss: 0.6766217350959778\n",
            "Epoch: 0/9\n",
            "70\n",
            "Loss: 0.6837199330329895\n",
            "Epoch: 0/9\n",
            "71\n",
            "Loss: 0.6755406260490417\n",
            "Epoch: 0/9\n",
            "72\n",
            "Loss: 0.7154072523117065\n",
            "Epoch: 0/9\n",
            "73\n",
            "Loss: 0.6909085512161255\n",
            "Epoch: 0/9\n",
            "74\n",
            "Loss: 0.691878080368042\n",
            "Epoch: 0/9\n",
            "75\n",
            "Loss: 0.6289114356040955\n",
            "Epoch: 0/9\n",
            "76\n",
            "Loss: 0.709281325340271\n",
            "Epoch: 0/9\n",
            "77\n",
            "Loss: 0.696412205696106\n",
            "Epoch: 0/9\n",
            "78\n",
            "Loss: 0.7526292204856873\n",
            "Epoch: 0/9\n",
            "79\n",
            "Loss: 0.6615747213363647\n",
            "Epoch: 0/9\n",
            "80\n",
            "Loss: 0.6508331298828125\n",
            "Epoch: 0/9\n",
            "81\n",
            "Loss: 0.6925342679023743\n",
            "Epoch: 0/9\n",
            "82\n",
            "Loss: 0.6435725688934326\n",
            "Epoch: 0/9\n",
            "83\n",
            "Loss: 0.7436016798019409\n",
            "Epoch: 0/9\n",
            "84\n",
            "Loss: 0.6557778716087341\n",
            "Epoch: 0/9\n",
            "85\n",
            "Loss: 0.7595019340515137\n",
            "Epoch: 0/9\n",
            "86\n",
            "Loss: 0.7255517244338989\n",
            "Epoch: 0/9\n",
            "87\n",
            "Loss: 0.7167120575904846\n",
            "Epoch: 0/9\n",
            "88\n",
            "Loss: 0.6078525185585022\n",
            "Epoch: 0/9\n",
            "89\n",
            "Loss: 0.7156942486763\n",
            "Epoch: 0/9\n",
            "90\n",
            "Loss: 0.6862144470214844\n",
            "Epoch: 0/9\n",
            "91\n",
            "Loss: 0.6760730743408203\n",
            "Epoch: 0/9\n",
            "92\n",
            "Loss: 0.6692177057266235\n",
            "Epoch: 0/9\n",
            "93\n",
            "Loss: 0.6151577234268188\n",
            "Epoch: 0/9\n",
            "94\n",
            "Loss: 0.6378338932991028\n",
            "Epoch: 0/9\n",
            "95\n",
            "Loss: 0.671489417552948\n",
            "Epoch: 0/9\n",
            "96\n",
            "Loss: 0.6956120729446411\n",
            "Epoch: 0/9\n",
            "97\n",
            "Loss: 0.6361141800880432\n",
            "Epoch: 0/9\n",
            "98\n",
            "Loss: 0.7128004431724548\n",
            "Epoch: 0/9\n",
            "99\n",
            "Loss: 0.6202234625816345\n",
            "Epoch: 0/9\n",
            "100\n",
            "Loss: 0.6530014276504517\n",
            "Epoch: 0/9\n",
            "101\n",
            "Loss: 0.617493748664856\n",
            "Epoch: 0/9\n",
            "102\n",
            "Loss: 0.5619164705276489\n",
            "Epoch: 0/9\n",
            "103\n",
            "Loss: 0.6289093494415283\n",
            "Epoch: 0/9\n",
            "104\n",
            "Loss: 0.7008189558982849\n",
            "Epoch: 0/9\n",
            "105\n",
            "Loss: 0.6451635956764221\n",
            "Epoch: 0/9\n",
            "106\n",
            "Loss: 0.6974118947982788\n",
            "Epoch: 0/9\n",
            "107\n",
            "Loss: 0.6282929182052612\n",
            "Epoch: 0/9\n",
            "108\n",
            "Loss: 0.5900256633758545\n",
            "Epoch: 0/9\n",
            "109\n",
            "Loss: 0.6002058386802673\n",
            "Epoch: 0/9\n",
            "110\n",
            "Loss: 0.6206562519073486\n",
            "Epoch: 0/9\n",
            "111\n",
            "Loss: 0.6680614948272705\n",
            "Epoch: 0/9\n",
            "112\n",
            "Loss: 0.5765487551689148\n",
            "Epoch: 0/9\n",
            "113\n",
            "Loss: 0.5817258358001709\n",
            "Epoch: 0/9\n",
            "114\n",
            "Loss: 0.5893535017967224\n",
            "Epoch: 0/9\n",
            "115\n",
            "Loss: 0.6265242099761963\n",
            "Epoch: 0/9\n",
            "116\n",
            "Loss: 0.5971380472183228\n",
            "Epoch: 0/9\n",
            "117\n",
            "Loss: 0.611207127571106\n",
            "Epoch: 0/9\n",
            "118\n",
            "Loss: 0.5626459717750549\n",
            "Epoch: 0/9\n",
            "119\n",
            "Loss: 0.6003249287605286\n",
            "Epoch: 0/9\n",
            "120\n",
            "Loss: 0.7279728651046753\n",
            "Epoch: 0/9\n",
            "121\n",
            "Loss: 0.6015868186950684\n",
            "Epoch: 0/9\n",
            "122\n",
            "Loss: 0.5719004273414612\n",
            "Epoch: 0/9\n",
            "123\n",
            "Loss: 0.6259793043136597\n",
            "Epoch: 0/9\n",
            "124\n",
            "Loss: 0.6726320385932922\n",
            "Epoch: 0/9\n",
            "125\n",
            "Loss: 0.7378398776054382\n",
            "Epoch: 0/9\n",
            "126\n",
            "Loss: 0.6630747318267822\n",
            "Epoch: 0/9\n",
            "127\n",
            "Loss: 0.6963368058204651\n",
            "Epoch: 0/9\n",
            "128\n",
            "Loss: 0.6348591446876526\n",
            "Epoch: 0/9\n",
            "129\n",
            "Loss: 0.6281787753105164\n",
            "Epoch: 0/9\n",
            "130\n",
            "Loss: 0.6918662786483765\n",
            "Epoch: 0/9\n",
            "131\n",
            "Loss: 0.8120336532592773\n",
            "Epoch: 0/9\n",
            "132\n",
            "Loss: 0.765224814414978\n",
            "Epoch: 0/9\n",
            "133\n",
            "Loss: 0.5583392381668091\n",
            "Epoch: 0/9\n",
            "134\n",
            "Loss: 0.7721769213676453\n",
            "Epoch: 0/9\n",
            "135\n",
            "Loss: 0.6147221922874451\n",
            "Epoch: 0/9\n",
            "136\n",
            "Loss: 0.7178677320480347\n",
            "Epoch: 0/9\n",
            "137\n",
            "Loss: 0.713573157787323\n",
            "Epoch: 0/9\n",
            "138\n",
            "Loss: 0.6225236654281616\n",
            "Epoch: 0/9\n",
            "139\n",
            "Loss: 0.7126616835594177\n",
            "Epoch: 0/9\n",
            "140\n",
            "Loss: 0.6309443116188049\n",
            "Epoch: 0/9\n",
            "141\n",
            "Loss: 0.7135822772979736\n",
            "Epoch: 0/9\n",
            "142\n",
            "Loss: 0.5792689323425293\n",
            "Epoch: 0/9\n",
            "143\n",
            "Loss: 0.6369040608406067\n",
            "Epoch: 0/9\n",
            "144\n",
            "Loss: 0.5763593912124634\n",
            "Epoch: 0/9\n",
            "145\n",
            "Loss: 0.6682711243629456\n",
            "Epoch: 0/9\n",
            "146\n",
            "Loss: 0.6248397827148438\n",
            "Epoch: 0/9\n",
            "147\n",
            "Loss: 0.5973771810531616\n",
            "Epoch: 0/9\n",
            "148\n",
            "Loss: 0.6398772597312927\n",
            "Epoch: 0/9\n",
            "149\n",
            "Loss: 0.6009169220924377\n",
            "Epoch: 0/9\n",
            "150\n",
            "Loss: 0.5587301850318909\n",
            "Epoch: 0/9\n",
            "151\n",
            "Loss: 0.4654093086719513\n",
            "Epoch: 0/9\n",
            "152\n",
            "Loss: 0.5369318127632141\n",
            "Epoch: 0/9\n",
            "153\n",
            "Loss: 0.594292402267456\n",
            "Epoch: 0/9\n",
            "154\n",
            "Loss: 0.5193023681640625\n",
            "Epoch: 0/9\n",
            "155\n",
            "Loss: 0.5698021650314331\n",
            "Epoch: 0/9\n",
            "156\n",
            "Loss: 0.45873889327049255\n",
            "Epoch: 0/9\n",
            "157\n",
            "Loss: 0.6494454741477966\n",
            "Epoch: 0/9\n",
            "158\n",
            "Loss: 0.5880675911903381\n",
            "Epoch: 0/9\n",
            "159\n",
            "Loss: 0.6055187582969666\n",
            "Epoch: 0/9\n",
            "160\n",
            "Loss: 0.5546649694442749\n",
            "Epoch: 0/9\n",
            "161\n",
            "Loss: 0.5087985396385193\n",
            "Epoch: 0/9\n",
            "162\n",
            "Loss: 0.6153690218925476\n",
            "Epoch: 0/9\n",
            "163\n",
            "Loss: 0.5077953338623047\n",
            "Epoch: 0/9\n",
            "164\n",
            "Loss: 0.6132956743240356\n",
            "Epoch: 0/9\n",
            "165\n",
            "Loss: 0.481426477432251\n",
            "Epoch: 0/9\n",
            "166\n",
            "Loss: 0.4066660404205322\n",
            "Epoch: 0/9\n",
            "167\n",
            "Loss: 0.46562299132347107\n",
            "Epoch: 0/9\n",
            "168\n",
            "Loss: 0.4240066409111023\n",
            "Epoch: 0/9\n",
            "169\n",
            "Loss: 0.4924871027469635\n",
            "Epoch: 0/9\n",
            "170\n",
            "Loss: 0.4637121260166168\n",
            "Epoch: 0/9\n",
            "171\n",
            "Loss: 0.41269683837890625\n",
            "Epoch: 0/9\n",
            "172\n",
            "Loss: 0.47701340913772583\n",
            "Epoch: 0/9\n",
            "173\n",
            "Loss: 0.44760802388191223\n",
            "Epoch: 0/9\n",
            "174\n",
            "Loss: 0.48148074746131897\n",
            "Epoch: 0/9\n",
            "175\n",
            "Loss: 0.37857404351234436\n",
            "Epoch: 0/9\n",
            "176\n",
            "Loss: 0.47931724786758423\n",
            "Epoch: 0/9\n",
            "177\n",
            "Loss: 0.481749951839447\n",
            "Epoch: 0/9\n",
            "178\n",
            "Loss: 0.5451095700263977\n",
            "Epoch: 0/9\n",
            "179\n",
            "Loss: 0.5101683139801025\n",
            "Epoch: 0/9\n",
            "180\n",
            "Loss: 0.535581111907959\n",
            "Epoch: 0/9\n",
            "181\n",
            "Loss: 0.5604428648948669\n",
            "Epoch: 0/9\n",
            "182\n",
            "Loss: 0.4719504415988922\n",
            "Epoch: 0/9\n",
            "183\n",
            "Loss: 0.5278589129447937\n",
            "Epoch: 0/9\n",
            "184\n",
            "Loss: 0.5184388756752014\n",
            "Epoch: 0/9\n",
            "185\n",
            "Loss: 0.45770516991615295\n",
            "Epoch: 0/9\n",
            "186\n",
            "Loss: 0.5346150398254395\n",
            "Epoch: 0/9\n",
            "187\n",
            "Loss: 0.5283482670783997\n",
            "Epoch: 0/9\n",
            "188\n",
            "Loss: 0.4795435070991516\n",
            "Epoch: 0/9\n",
            "189\n",
            "Loss: 0.4051097631454468\n",
            "Epoch: 0/9\n",
            "190\n",
            "Loss: 0.4461731016635895\n",
            "Epoch: 0/9\n",
            "191\n",
            "Loss: 0.41194307804107666\n",
            "Epoch: 0/9\n",
            "192\n",
            "Loss: 0.3724161982536316\n",
            "Epoch: 0/9\n",
            "193\n",
            "Loss: 0.4257220923900604\n",
            "Epoch: 0/9\n",
            "194\n",
            "Loss: 0.32049989700317383\n",
            "Epoch: 0/9\n",
            "195\n",
            "Loss: 0.22708113491535187\n",
            "Epoch: 0/9\n",
            "Epoch: 1\n",
            "0\n",
            "Loss: 0.5328880548477173\n",
            "Epoch: 1/9\n",
            "1\n",
            "Loss: 0.513859748840332\n",
            "Epoch: 1/9\n",
            "2\n",
            "Loss: 0.427610844373703\n",
            "Epoch: 1/9\n",
            "3\n",
            "Loss: 0.5205837488174438\n",
            "Epoch: 1/9\n",
            "4\n",
            "Loss: 0.6713735461235046\n",
            "Epoch: 1/9\n",
            "5\n",
            "Loss: 0.5600711107254028\n",
            "Epoch: 1/9\n",
            "6\n",
            "Loss: 0.5034298896789551\n",
            "Epoch: 1/9\n",
            "7\n",
            "Loss: 0.6486430764198303\n",
            "Epoch: 1/9\n",
            "8\n",
            "Loss: 0.6221628785133362\n",
            "Epoch: 1/9\n",
            "9\n",
            "Loss: 0.5437057614326477\n",
            "Epoch: 1/9\n",
            "10\n",
            "Loss: 0.5653489828109741\n",
            "Epoch: 1/9\n",
            "11\n",
            "Loss: 0.7210260033607483\n",
            "Epoch: 1/9\n",
            "12\n",
            "Loss: 0.6707258224487305\n",
            "Epoch: 1/9\n",
            "13\n",
            "Loss: 0.5968847274780273\n",
            "Epoch: 1/9\n",
            "14\n",
            "Loss: 0.6416319608688354\n",
            "Epoch: 1/9\n",
            "15\n",
            "Loss: 0.680314838886261\n",
            "Epoch: 1/9\n",
            "16\n",
            "Loss: 0.7181958556175232\n",
            "Epoch: 1/9\n",
            "17\n",
            "Loss: 0.7290856838226318\n",
            "Epoch: 1/9\n",
            "18\n",
            "Loss: 0.6296125054359436\n",
            "Epoch: 1/9\n",
            "19\n",
            "Loss: 0.6665917038917542\n",
            "Epoch: 1/9\n",
            "20\n",
            "Loss: 0.6813186407089233\n",
            "Epoch: 1/9\n",
            "21\n",
            "Loss: 0.6967028975486755\n",
            "Epoch: 1/9\n",
            "22\n",
            "Loss: 0.650269091129303\n",
            "Epoch: 1/9\n",
            "23\n",
            "Loss: 0.6148269772529602\n",
            "Epoch: 1/9\n",
            "24\n",
            "Loss: 0.6790052652359009\n",
            "Epoch: 1/9\n",
            "25\n",
            "Loss: 0.7064384818077087\n",
            "Epoch: 1/9\n",
            "26\n",
            "Loss: 0.7135615348815918\n",
            "Epoch: 1/9\n",
            "27\n",
            "Loss: 0.6953385472297668\n",
            "Epoch: 1/9\n",
            "28\n",
            "Loss: 0.6078665852546692\n",
            "Epoch: 1/9\n",
            "29\n",
            "Loss: 0.6994071006774902\n",
            "Epoch: 1/9\n",
            "30\n",
            "Loss: 0.6376963257789612\n",
            "Epoch: 1/9\n",
            "31\n",
            "Loss: 0.6709049940109253\n",
            "Epoch: 1/9\n",
            "32\n",
            "Loss: 0.5728110671043396\n",
            "Epoch: 1/9\n",
            "33\n",
            "Loss: 0.707809329032898\n",
            "Epoch: 1/9\n",
            "34\n",
            "Loss: 0.6599911451339722\n",
            "Epoch: 1/9\n",
            "35\n",
            "Loss: 0.6920284032821655\n",
            "Epoch: 1/9\n",
            "36\n",
            "Loss: 0.774495005607605\n",
            "Epoch: 1/9\n",
            "37\n",
            "Loss: 0.6368538737297058\n",
            "Epoch: 1/9\n",
            "38\n",
            "Loss: 0.6369057893753052\n",
            "Epoch: 1/9\n",
            "39\n",
            "Loss: 0.7507461309432983\n",
            "Epoch: 1/9\n",
            "40\n",
            "Loss: 0.7323906421661377\n",
            "Epoch: 1/9\n",
            "41\n",
            "Loss: 0.6079659461975098\n",
            "Epoch: 1/9\n",
            "42\n",
            "Loss: 0.6846880912780762\n",
            "Epoch: 1/9\n",
            "43\n",
            "Loss: 0.820140540599823\n",
            "Epoch: 1/9\n",
            "44\n",
            "Loss: 0.6472087502479553\n",
            "Epoch: 1/9\n",
            "45\n",
            "Loss: 0.6226342916488647\n",
            "Epoch: 1/9\n",
            "46\n",
            "Loss: 0.647814154624939\n",
            "Epoch: 1/9\n",
            "47\n",
            "Loss: 0.7279214262962341\n",
            "Epoch: 1/9\n",
            "48\n",
            "Loss: 0.738231360912323\n",
            "Epoch: 1/9\n",
            "49\n",
            "Loss: 0.6612671613693237\n",
            "Epoch: 1/9\n",
            "50\n",
            "Loss: 0.6983926296234131\n",
            "Epoch: 1/9\n",
            "51\n",
            "Loss: 0.7571043372154236\n",
            "Epoch: 1/9\n",
            "52\n",
            "Loss: 0.7114708423614502\n",
            "Epoch: 1/9\n",
            "53\n",
            "Loss: 0.7663466334342957\n",
            "Epoch: 1/9\n",
            "54\n",
            "Loss: 0.7133014798164368\n",
            "Epoch: 1/9\n",
            "55\n",
            "Loss: 0.6799853444099426\n",
            "Epoch: 1/9\n",
            "56\n",
            "Loss: 0.7209370732307434\n",
            "Epoch: 1/9\n",
            "57\n",
            "Loss: 0.6483865976333618\n",
            "Epoch: 1/9\n",
            "58\n",
            "Loss: 0.6215924620628357\n",
            "Epoch: 1/9\n",
            "59\n",
            "Loss: 0.6547295451164246\n",
            "Epoch: 1/9\n",
            "60\n",
            "Loss: 0.6423700451850891\n",
            "Epoch: 1/9\n",
            "61\n",
            "Loss: 0.6030864715576172\n",
            "Epoch: 1/9\n",
            "62\n",
            "Loss: 0.657082200050354\n",
            "Epoch: 1/9\n",
            "63\n",
            "Loss: 0.6010518074035645\n",
            "Epoch: 1/9\n",
            "64\n",
            "Loss: 0.6004834175109863\n",
            "Epoch: 1/9\n",
            "65\n",
            "Loss: 0.5390543937683105\n",
            "Epoch: 1/9\n",
            "66\n",
            "Loss: 0.5499286651611328\n",
            "Epoch: 1/9\n",
            "67\n",
            "Loss: 0.6508471965789795\n",
            "Epoch: 1/9\n",
            "68\n",
            "Loss: 0.6104293465614319\n",
            "Epoch: 1/9\n",
            "69\n",
            "Loss: 0.6700089573860168\n",
            "Epoch: 1/9\n",
            "70\n",
            "Loss: 0.6801707148551941\n",
            "Epoch: 1/9\n",
            "71\n",
            "Loss: 0.6650601625442505\n",
            "Epoch: 1/9\n",
            "72\n",
            "Loss: 0.7101057171821594\n",
            "Epoch: 1/9\n",
            "73\n",
            "Loss: 0.6816222667694092\n",
            "Epoch: 1/9\n",
            "74\n",
            "Loss: 0.6885779500007629\n",
            "Epoch: 1/9\n",
            "75\n",
            "Loss: 0.6231375336647034\n",
            "Epoch: 1/9\n",
            "76\n",
            "Loss: 0.7033121585845947\n",
            "Epoch: 1/9\n",
            "77\n",
            "Loss: 0.6889312863349915\n",
            "Epoch: 1/9\n",
            "78\n",
            "Loss: 0.7455815076828003\n",
            "Epoch: 1/9\n",
            "79\n",
            "Loss: 0.6593427062034607\n",
            "Epoch: 1/9\n",
            "80\n",
            "Loss: 0.6418972611427307\n",
            "Epoch: 1/9\n",
            "81\n",
            "Loss: 0.6894290447235107\n",
            "Epoch: 1/9\n",
            "82\n",
            "Loss: 0.6329824924468994\n",
            "Epoch: 1/9\n",
            "83\n",
            "Loss: 0.7416778802871704\n",
            "Epoch: 1/9\n",
            "84\n",
            "Loss: 0.652759313583374\n",
            "Epoch: 1/9\n",
            "85\n",
            "Loss: 0.753205418586731\n",
            "Epoch: 1/9\n",
            "86\n",
            "Loss: 0.7208876609802246\n",
            "Epoch: 1/9\n",
            "87\n",
            "Loss: 0.7108250260353088\n",
            "Epoch: 1/9\n",
            "88\n",
            "Loss: 0.6011767387390137\n",
            "Epoch: 1/9\n",
            "89\n",
            "Loss: 0.7056981325149536\n",
            "Epoch: 1/9\n",
            "90\n",
            "Loss: 0.6777141690254211\n",
            "Epoch: 1/9\n",
            "91\n",
            "Loss: 0.6700425148010254\n",
            "Epoch: 1/9\n",
            "92\n",
            "Loss: 0.6642889976501465\n",
            "Epoch: 1/9\n",
            "93\n",
            "Loss: 0.6113724112510681\n",
            "Epoch: 1/9\n",
            "94\n",
            "Loss: 0.6340368986129761\n",
            "Epoch: 1/9\n",
            "95\n",
            "Loss: 0.6683810949325562\n",
            "Epoch: 1/9\n",
            "96\n",
            "Loss: 0.6868528723716736\n",
            "Epoch: 1/9\n",
            "97\n",
            "Loss: 0.6274238228797913\n",
            "Epoch: 1/9\n",
            "98\n",
            "Loss: 0.7091836333274841\n",
            "Epoch: 1/9\n",
            "99\n",
            "Loss: 0.6122966408729553\n",
            "Epoch: 1/9\n",
            "100\n",
            "Loss: 0.6493974328041077\n",
            "Epoch: 1/9\n",
            "101\n",
            "Loss: 0.612753689289093\n",
            "Epoch: 1/9\n",
            "102\n",
            "Loss: 0.5604780316352844\n",
            "Epoch: 1/9\n",
            "103\n",
            "Loss: 0.6237230896949768\n",
            "Epoch: 1/9\n",
            "104\n",
            "Loss: 0.6900394558906555\n",
            "Epoch: 1/9\n",
            "105\n",
            "Loss: 0.6407790184020996\n",
            "Epoch: 1/9\n",
            "106\n",
            "Loss: 0.6865355968475342\n",
            "Epoch: 1/9\n",
            "107\n",
            "Loss: 0.618958055973053\n",
            "Epoch: 1/9\n",
            "108\n",
            "Loss: 0.5847931504249573\n",
            "Epoch: 1/9\n",
            "109\n",
            "Loss: 0.5970540642738342\n",
            "Epoch: 1/9\n",
            "110\n",
            "Loss: 0.6139748692512512\n",
            "Epoch: 1/9\n",
            "111\n",
            "Loss: 0.6609591841697693\n",
            "Epoch: 1/9\n",
            "112\n",
            "Loss: 0.5653608441352844\n",
            "Epoch: 1/9\n",
            "113\n",
            "Loss: 0.575793981552124\n",
            "Epoch: 1/9\n",
            "114\n",
            "Loss: 0.5835140943527222\n",
            "Epoch: 1/9\n",
            "115\n",
            "Loss: 0.6162785291671753\n",
            "Epoch: 1/9\n",
            "116\n",
            "Loss: 0.5936498641967773\n",
            "Epoch: 1/9\n",
            "117\n",
            "Loss: 0.6035506725311279\n",
            "Epoch: 1/9\n",
            "118\n",
            "Loss: 0.5569919347763062\n",
            "Epoch: 1/9\n",
            "119\n",
            "Loss: 0.5927709937095642\n",
            "Epoch: 1/9\n",
            "120\n",
            "Loss: 0.7206705808639526\n",
            "Epoch: 1/9\n",
            "121\n",
            "Loss: 0.5944069027900696\n",
            "Epoch: 1/9\n",
            "122\n",
            "Loss: 0.5643934607505798\n",
            "Epoch: 1/9\n",
            "123\n",
            "Loss: 0.6184760332107544\n",
            "Epoch: 1/9\n",
            "124\n",
            "Loss: 0.664291501045227\n",
            "Epoch: 1/9\n",
            "125\n",
            "Loss: 0.7307208776473999\n",
            "Epoch: 1/9\n",
            "126\n",
            "Loss: 0.6567788124084473\n",
            "Epoch: 1/9\n",
            "127\n",
            "Loss: 0.6904827952384949\n",
            "Epoch: 1/9\n",
            "128\n",
            "Loss: 0.6276146769523621\n",
            "Epoch: 1/9\n",
            "129\n",
            "Loss: 0.6225704550743103\n",
            "Epoch: 1/9\n",
            "130\n",
            "Loss: 0.6815024018287659\n",
            "Epoch: 1/9\n",
            "131\n",
            "Loss: 0.805587112903595\n",
            "Epoch: 1/9\n",
            "132\n",
            "Loss: 0.7601182460784912\n",
            "Epoch: 1/9\n",
            "133\n",
            "Loss: 0.5501545071601868\n",
            "Epoch: 1/9\n",
            "134\n",
            "Loss: 0.7620629072189331\n",
            "Epoch: 1/9\n",
            "135\n",
            "Loss: 0.6075442433357239\n",
            "Epoch: 1/9\n",
            "136\n",
            "Loss: 0.7060205340385437\n",
            "Epoch: 1/9\n",
            "137\n",
            "Loss: 0.7010695338249207\n",
            "Epoch: 1/9\n",
            "138\n",
            "Loss: 0.6165410280227661\n",
            "Epoch: 1/9\n",
            "139\n",
            "Loss: 0.7037857174873352\n",
            "Epoch: 1/9\n",
            "140\n",
            "Loss: 0.6263255476951599\n",
            "Epoch: 1/9\n",
            "141\n",
            "Loss: 0.7041723132133484\n",
            "Epoch: 1/9\n",
            "142\n",
            "Loss: 0.5720121264457703\n",
            "Epoch: 1/9\n",
            "143\n",
            "Loss: 0.6307774782180786\n",
            "Epoch: 1/9\n",
            "144\n",
            "Loss: 0.5721399188041687\n",
            "Epoch: 1/9\n",
            "145\n",
            "Loss: 0.6602990627288818\n",
            "Epoch: 1/9\n",
            "146\n",
            "Loss: 0.6196283102035522\n",
            "Epoch: 1/9\n",
            "147\n",
            "Loss: 0.5918362736701965\n",
            "Epoch: 1/9\n",
            "148\n",
            "Loss: 0.6331183314323425\n",
            "Epoch: 1/9\n",
            "149\n",
            "Loss: 0.5990745425224304\n",
            "Epoch: 1/9\n",
            "150\n",
            "Loss: 0.5528331995010376\n",
            "Epoch: 1/9\n",
            "151\n",
            "Loss: 0.45904186367988586\n",
            "Epoch: 1/9\n",
            "152\n",
            "Loss: 0.531427800655365\n",
            "Epoch: 1/9\n",
            "153\n",
            "Loss: 0.5861283540725708\n",
            "Epoch: 1/9\n",
            "154\n",
            "Loss: 0.5142545700073242\n",
            "Epoch: 1/9\n",
            "155\n",
            "Loss: 0.5612298250198364\n",
            "Epoch: 1/9\n",
            "156\n",
            "Loss: 0.4531310200691223\n",
            "Epoch: 1/9\n",
            "157\n",
            "Loss: 0.6420230865478516\n",
            "Epoch: 1/9\n",
            "158\n",
            "Loss: 0.5827299356460571\n",
            "Epoch: 1/9\n",
            "159\n",
            "Loss: 0.5974738597869873\n",
            "Epoch: 1/9\n",
            "160\n",
            "Loss: 0.5464522838592529\n",
            "Epoch: 1/9\n",
            "161\n",
            "Loss: 0.49915260076522827\n",
            "Epoch: 1/9\n",
            "162\n",
            "Loss: 0.6073118448257446\n",
            "Epoch: 1/9\n",
            "163\n",
            "Loss: 0.5019890069961548\n",
            "Epoch: 1/9\n",
            "164\n",
            "Loss: 0.6020795106887817\n",
            "Epoch: 1/9\n",
            "165\n",
            "Loss: 0.474517285823822\n",
            "Epoch: 1/9\n",
            "166\n",
            "Loss: 0.39712196588516235\n",
            "Epoch: 1/9\n",
            "167\n",
            "Loss: 0.4599073529243469\n",
            "Epoch: 1/9\n",
            "168\n",
            "Loss: 0.418560266494751\n",
            "Epoch: 1/9\n",
            "169\n",
            "Loss: 0.4860692024230957\n",
            "Epoch: 1/9\n",
            "170\n",
            "Loss: 0.4587973952293396\n",
            "Epoch: 1/9\n",
            "171\n",
            "Loss: 0.4055871367454529\n",
            "Epoch: 1/9\n",
            "172\n",
            "Loss: 0.47331932187080383\n",
            "Epoch: 1/9\n",
            "173\n",
            "Loss: 0.44215822219848633\n",
            "Epoch: 1/9\n",
            "174\n",
            "Loss: 0.4713537096977234\n",
            "Epoch: 1/9\n",
            "175\n",
            "Loss: 0.37253057956695557\n",
            "Epoch: 1/9\n",
            "176\n",
            "Loss: 0.4731140434741974\n",
            "Epoch: 1/9\n",
            "177\n",
            "Loss: 0.47288089990615845\n",
            "Epoch: 1/9\n",
            "178\n",
            "Loss: 0.5405790209770203\n",
            "Epoch: 1/9\n",
            "179\n",
            "Loss: 0.5041854977607727\n",
            "Epoch: 1/9\n",
            "180\n",
            "Loss: 0.5299551486968994\n",
            "Epoch: 1/9\n",
            "181\n",
            "Loss: 0.5536689758300781\n",
            "Epoch: 1/9\n",
            "182\n",
            "Loss: 0.4672366976737976\n",
            "Epoch: 1/9\n",
            "183\n",
            "Loss: 0.5214575529098511\n",
            "Epoch: 1/9\n",
            "184\n",
            "Loss: 0.5131189823150635\n",
            "Epoch: 1/9\n",
            "185\n",
            "Loss: 0.45247384905815125\n",
            "Epoch: 1/9\n",
            "186\n",
            "Loss: 0.5292892456054688\n",
            "Epoch: 1/9\n",
            "187\n",
            "Loss: 0.5214022397994995\n",
            "Epoch: 1/9\n",
            "188\n",
            "Loss: 0.4712448716163635\n",
            "Epoch: 1/9\n",
            "189\n",
            "Loss: 0.3982173502445221\n",
            "Epoch: 1/9\n",
            "190\n",
            "Loss: 0.44003725051879883\n",
            "Epoch: 1/9\n",
            "191\n",
            "Loss: 0.4045206308364868\n",
            "Epoch: 1/9\n",
            "192\n",
            "Loss: 0.365174263715744\n",
            "Epoch: 1/9\n",
            "193\n",
            "Loss: 0.419346421957016\n",
            "Epoch: 1/9\n",
            "194\n",
            "Loss: 0.31460610032081604\n",
            "Epoch: 1/9\n",
            "195\n",
            "Loss: 0.222316712141037\n",
            "Epoch: 1/9\n",
            "Epoch: 2\n",
            "0\n",
            "Loss: 0.5257208347320557\n",
            "Epoch: 2/9\n",
            "1\n",
            "Loss: 0.5088877081871033\n",
            "Epoch: 2/9\n",
            "2\n",
            "Loss: 0.41996362805366516\n",
            "Epoch: 2/9\n",
            "3\n",
            "Loss: 0.5128306150436401\n",
            "Epoch: 2/9\n",
            "4\n",
            "Loss: 0.6656628847122192\n",
            "Epoch: 2/9\n",
            "5\n",
            "Loss: 0.5525075793266296\n",
            "Epoch: 2/9\n",
            "6\n",
            "Loss: 0.4968169033527374\n",
            "Epoch: 2/9\n",
            "7\n",
            "Loss: 0.644193172454834\n",
            "Epoch: 2/9\n",
            "8\n",
            "Loss: 0.6157629489898682\n",
            "Epoch: 2/9\n",
            "9\n",
            "Loss: 0.538743793964386\n",
            "Epoch: 2/9\n",
            "10\n",
            "Loss: 0.5574982166290283\n",
            "Epoch: 2/9\n",
            "11\n",
            "Loss: 0.715892493724823\n",
            "Epoch: 2/9\n",
            "12\n",
            "Loss: 0.6628021001815796\n",
            "Epoch: 2/9\n",
            "13\n",
            "Loss: 0.5931836366653442\n",
            "Epoch: 2/9\n",
            "14\n",
            "Loss: 0.638277530670166\n",
            "Epoch: 2/9\n",
            "15\n",
            "Loss: 0.6735220551490784\n",
            "Epoch: 2/9\n",
            "16\n",
            "Loss: 0.7106791734695435\n",
            "Epoch: 2/9\n",
            "17\n",
            "Loss: 0.7213756442070007\n",
            "Epoch: 2/9\n",
            "18\n",
            "Loss: 0.6260786652565002\n",
            "Epoch: 2/9\n",
            "19\n",
            "Loss: 0.6650877594947815\n",
            "Epoch: 2/9\n",
            "20\n",
            "Loss: 0.6741806864738464\n",
            "Epoch: 2/9\n",
            "21\n",
            "Loss: 0.6876348853111267\n",
            "Epoch: 2/9\n",
            "22\n",
            "Loss: 0.646860659122467\n",
            "Epoch: 2/9\n",
            "23\n",
            "Loss: 0.6097315549850464\n",
            "Epoch: 2/9\n",
            "24\n",
            "Loss: 0.6745806336402893\n",
            "Epoch: 2/9\n",
            "25\n",
            "Loss: 0.6972352862358093\n",
            "Epoch: 2/9\n",
            "26\n",
            "Loss: 0.709322988986969\n",
            "Epoch: 2/9\n",
            "27\n",
            "Loss: 0.6859310269355774\n",
            "Epoch: 2/9\n",
            "28\n",
            "Loss: 0.5997321009635925\n",
            "Epoch: 2/9\n",
            "29\n",
            "Loss: 0.6937788724899292\n",
            "Epoch: 2/9\n",
            "30\n",
            "Loss: 0.6318467259407043\n",
            "Epoch: 2/9\n",
            "31\n",
            "Loss: 0.6647193431854248\n",
            "Epoch: 2/9\n",
            "32\n",
            "Loss: 0.5674687027931213\n",
            "Epoch: 2/9\n",
            "33\n",
            "Loss: 0.7018561363220215\n",
            "Epoch: 2/9\n",
            "34\n",
            "Loss: 0.6528093814849854\n",
            "Epoch: 2/9\n",
            "35\n",
            "Loss: 0.6878595948219299\n",
            "Epoch: 2/9\n",
            "36\n",
            "Loss: 0.7695926427841187\n",
            "Epoch: 2/9\n",
            "37\n",
            "Loss: 0.6311278939247131\n",
            "Epoch: 2/9\n",
            "38\n",
            "Loss: 0.6308092474937439\n",
            "Epoch: 2/9\n",
            "39\n",
            "Loss: 0.7482333779335022\n",
            "Epoch: 2/9\n",
            "40\n",
            "Loss: 0.7293447256088257\n",
            "Epoch: 2/9\n",
            "41\n",
            "Loss: 0.6033083200454712\n",
            "Epoch: 2/9\n",
            "42\n",
            "Loss: 0.6805840730667114\n",
            "Epoch: 2/9\n",
            "43\n",
            "Loss: 0.814899742603302\n",
            "Epoch: 2/9\n",
            "44\n",
            "Loss: 0.6401538848876953\n",
            "Epoch: 2/9\n",
            "45\n",
            "Loss: 0.6203104853630066\n",
            "Epoch: 2/9\n",
            "46\n",
            "Loss: 0.6388062834739685\n",
            "Epoch: 2/9\n",
            "47\n",
            "Loss: 0.7266457080841064\n",
            "Epoch: 2/9\n",
            "48\n",
            "Loss: 0.7325825691223145\n",
            "Epoch: 2/9\n",
            "49\n",
            "Loss: 0.6541151404380798\n",
            "Epoch: 2/9\n",
            "50\n",
            "Loss: 0.6912291049957275\n",
            "Epoch: 2/9\n",
            "51\n",
            "Loss: 0.7524862289428711\n",
            "Epoch: 2/9\n",
            "52\n",
            "Loss: 0.7053555846214294\n",
            "Epoch: 2/9\n",
            "53\n",
            "Loss: 0.7604545950889587\n",
            "Epoch: 2/9\n",
            "54\n",
            "Loss: 0.7078270316123962\n",
            "Epoch: 2/9\n",
            "55\n",
            "Loss: 0.6709111332893372\n",
            "Epoch: 2/9\n",
            "56\n",
            "Loss: 0.7104716897010803\n",
            "Epoch: 2/9\n",
            "57\n",
            "Loss: 0.6434229612350464\n",
            "Epoch: 2/9\n",
            "58\n",
            "Loss: 0.6158298254013062\n",
            "Epoch: 2/9\n",
            "59\n",
            "Loss: 0.6492568254470825\n",
            "Epoch: 2/9\n",
            "60\n",
            "Loss: 0.6342296600341797\n",
            "Epoch: 2/9\n",
            "61\n",
            "Loss: 0.5971375107765198\n",
            "Epoch: 2/9\n",
            "62\n",
            "Loss: 0.6534939408302307\n",
            "Epoch: 2/9\n",
            "63\n",
            "Loss: 0.5974825620651245\n",
            "Epoch: 2/9\n",
            "64\n",
            "Loss: 0.5974507331848145\n",
            "Epoch: 2/9\n",
            "65\n",
            "Loss: 0.5343049764633179\n",
            "Epoch: 2/9\n",
            "66\n",
            "Loss: 0.54435133934021\n",
            "Epoch: 2/9\n",
            "67\n",
            "Loss: 0.6430467963218689\n",
            "Epoch: 2/9\n",
            "68\n",
            "Loss: 0.6052426099777222\n",
            "Epoch: 2/9\n",
            "69\n",
            "Loss: 0.6643852591514587\n",
            "Epoch: 2/9\n",
            "70\n",
            "Loss: 0.6778160333633423\n",
            "Epoch: 2/9\n",
            "71\n",
            "Loss: 0.6582017540931702\n",
            "Epoch: 2/9\n",
            "72\n",
            "Loss: 0.705652117729187\n",
            "Epoch: 2/9\n",
            "73\n",
            "Loss: 0.672883152961731\n",
            "Epoch: 2/9\n",
            "74\n",
            "Loss: 0.6866781711578369\n",
            "Epoch: 2/9\n",
            "75\n",
            "Loss: 0.6170310378074646\n",
            "Epoch: 2/9\n",
            "76\n",
            "Loss: 0.6971445679664612\n",
            "Epoch: 2/9\n",
            "77\n",
            "Loss: 0.684162974357605\n",
            "Epoch: 2/9\n",
            "78\n",
            "Loss: 0.7373349070549011\n",
            "Epoch: 2/9\n",
            "79\n",
            "Loss: 0.6545990705490112\n",
            "Epoch: 2/9\n",
            "80\n",
            "Loss: 0.6330138444900513\n",
            "Epoch: 2/9\n",
            "81\n",
            "Loss: 0.6845037937164307\n",
            "Epoch: 2/9\n",
            "82\n",
            "Loss: 0.6232481598854065\n",
            "Epoch: 2/9\n",
            "83\n",
            "Loss: 0.738659143447876\n",
            "Epoch: 2/9\n",
            "84\n",
            "Loss: 0.6495667099952698\n",
            "Epoch: 2/9\n",
            "85\n",
            "Loss: 0.7485978007316589\n",
            "Epoch: 2/9\n",
            "86\n",
            "Loss: 0.7145787477493286\n",
            "Epoch: 2/9\n",
            "87\n",
            "Loss: 0.7070243954658508\n",
            "Epoch: 2/9\n",
            "88\n",
            "Loss: 0.5965495705604553\n",
            "Epoch: 2/9\n",
            "89\n",
            "Loss: 0.6975871324539185\n",
            "Epoch: 2/9\n",
            "90\n",
            "Loss: 0.670060932636261\n",
            "Epoch: 2/9\n",
            "91\n",
            "Loss: 0.6630687117576599\n",
            "Epoch: 2/9\n",
            "92\n",
            "Loss: 0.660234272480011\n",
            "Epoch: 2/9\n",
            "93\n",
            "Loss: 0.607217013835907\n",
            "Epoch: 2/9\n",
            "94\n",
            "Loss: 0.6312954425811768\n",
            "Epoch: 2/9\n",
            "95\n",
            "Loss: 0.6651900410652161\n",
            "Epoch: 2/9\n",
            "96\n",
            "Loss: 0.6789579391479492\n",
            "Epoch: 2/9\n",
            "97\n",
            "Loss: 0.6194009184837341\n",
            "Epoch: 2/9\n",
            "98\n",
            "Loss: 0.7058371305465698\n",
            "Epoch: 2/9\n",
            "99\n",
            "Loss: 0.6066930294036865\n",
            "Epoch: 2/9\n",
            "100\n",
            "Loss: 0.6461817622184753\n",
            "Epoch: 2/9\n",
            "101\n",
            "Loss: 0.6077105402946472\n",
            "Epoch: 2/9\n",
            "102\n",
            "Loss: 0.5576296448707581\n",
            "Epoch: 2/9\n",
            "103\n",
            "Loss: 0.6193179488182068\n",
            "Epoch: 2/9\n",
            "104\n",
            "Loss: 0.6816724538803101\n",
            "Epoch: 2/9\n",
            "105\n",
            "Loss: 0.6371347904205322\n",
            "Epoch: 2/9\n",
            "106\n",
            "Loss: 0.6768229603767395\n",
            "Epoch: 2/9\n",
            "107\n",
            "Loss: 0.6115028262138367\n",
            "Epoch: 2/9\n",
            "108\n",
            "Loss: 0.5807867050170898\n",
            "Epoch: 2/9\n",
            "109\n",
            "Loss: 0.595080554485321\n",
            "Epoch: 2/9\n",
            "110\n",
            "Loss: 0.6086326241493225\n",
            "Epoch: 2/9\n",
            "111\n",
            "Loss: 0.6542677879333496\n",
            "Epoch: 2/9\n",
            "112\n",
            "Loss: 0.5558854341506958\n",
            "Epoch: 2/9\n",
            "113\n",
            "Loss: 0.5698438882827759\n",
            "Epoch: 2/9\n",
            "114\n",
            "Loss: 0.5785320401191711\n",
            "Epoch: 2/9\n",
            "115\n",
            "Loss: 0.6098374128341675\n",
            "Epoch: 2/9\n",
            "116\n",
            "Loss: 0.590486466884613\n",
            "Epoch: 2/9\n",
            "117\n",
            "Loss: 0.5978405475616455\n",
            "Epoch: 2/9\n",
            "118\n",
            "Loss: 0.5522105693817139\n",
            "Epoch: 2/9\n",
            "119\n",
            "Loss: 0.5852060914039612\n",
            "Epoch: 2/9\n",
            "120\n",
            "Loss: 0.7159954309463501\n",
            "Epoch: 2/9\n",
            "121\n",
            "Loss: 0.5898407101631165\n",
            "Epoch: 2/9\n",
            "122\n",
            "Loss: 0.5583402514457703\n",
            "Epoch: 2/9\n",
            "123\n",
            "Loss: 0.6120803952217102\n",
            "Epoch: 2/9\n",
            "124\n",
            "Loss: 0.6596022844314575\n",
            "Epoch: 2/9\n",
            "125\n",
            "Loss: 0.7260270118713379\n",
            "Epoch: 2/9\n",
            "126\n",
            "Loss: 0.650253176689148\n",
            "Epoch: 2/9\n",
            "127\n",
            "Loss: 0.6846113801002502\n",
            "Epoch: 2/9\n",
            "128\n",
            "Loss: 0.621147096157074\n",
            "Epoch: 2/9\n",
            "129\n",
            "Loss: 0.618682324886322\n",
            "Epoch: 2/9\n",
            "130\n",
            "Loss: 0.6745624542236328\n",
            "Epoch: 2/9\n",
            "131\n",
            "Loss: 0.7991025447845459\n",
            "Epoch: 2/9\n",
            "132\n",
            "Loss: 0.7542422413825989\n",
            "Epoch: 2/9\n",
            "133\n",
            "Loss: 0.544059157371521\n",
            "Epoch: 2/9\n",
            "134\n",
            "Loss: 0.7532960176467896\n",
            "Epoch: 2/9\n",
            "135\n",
            "Loss: 0.6019703149795532\n",
            "Epoch: 2/9\n",
            "136\n",
            "Loss: 0.6968339681625366\n",
            "Epoch: 2/9\n",
            "137\n",
            "Loss: 0.691556990146637\n",
            "Epoch: 2/9\n",
            "138\n",
            "Loss: 0.6125085353851318\n",
            "Epoch: 2/9\n",
            "139\n",
            "Loss: 0.69764643907547\n",
            "Epoch: 2/9\n",
            "140\n",
            "Loss: 0.622481107711792\n",
            "Epoch: 2/9\n",
            "141\n",
            "Loss: 0.6953270435333252\n",
            "Epoch: 2/9\n",
            "142\n",
            "Loss: 0.5654847025871277\n",
            "Epoch: 2/9\n",
            "143\n",
            "Loss: 0.6256676316261292\n",
            "Epoch: 2/9\n",
            "144\n",
            "Loss: 0.5687242150306702\n",
            "Epoch: 2/9\n",
            "145\n",
            "Loss: 0.654060959815979\n",
            "Epoch: 2/9\n",
            "146\n",
            "Loss: 0.6163322925567627\n",
            "Epoch: 2/9\n",
            "147\n",
            "Loss: 0.587191641330719\n",
            "Epoch: 2/9\n",
            "148\n",
            "Loss: 0.6274356245994568\n",
            "Epoch: 2/9\n",
            "149\n",
            "Loss: 0.5974955558776855\n",
            "Epoch: 2/9\n",
            "150\n",
            "Loss: 0.5489053726196289\n",
            "Epoch: 2/9\n",
            "151\n",
            "Loss: 0.45501935482025146\n",
            "Epoch: 2/9\n",
            "152\n",
            "Loss: 0.5279339551925659\n",
            "Epoch: 2/9\n",
            "153\n",
            "Loss: 0.5801360607147217\n",
            "Epoch: 2/9\n",
            "154\n",
            "Loss: 0.5098819732666016\n",
            "Epoch: 2/9\n",
            "155\n",
            "Loss: 0.5537137389183044\n",
            "Epoch: 2/9\n",
            "156\n",
            "Loss: 0.44808533787727356\n",
            "Epoch: 2/9\n",
            "157\n",
            "Loss: 0.6362317204475403\n",
            "Epoch: 2/9\n",
            "158\n",
            "Loss: 0.5776591300964355\n",
            "Epoch: 2/9\n",
            "159\n",
            "Loss: 0.5925177335739136\n",
            "Epoch: 2/9\n",
            "160\n",
            "Loss: 0.5395954251289368\n",
            "Epoch: 2/9\n",
            "161\n",
            "Loss: 0.4919412434101105\n",
            "Epoch: 2/9\n",
            "162\n",
            "Loss: 0.5997284650802612\n",
            "Epoch: 2/9\n",
            "163\n",
            "Loss: 0.4972335398197174\n",
            "Epoch: 2/9\n",
            "164\n",
            "Loss: 0.5929111242294312\n",
            "Epoch: 2/9\n",
            "165\n",
            "Loss: 0.4691256880760193\n",
            "Epoch: 2/9\n",
            "166\n",
            "Loss: 0.3882904648780823\n",
            "Epoch: 2/9\n",
            "167\n",
            "Loss: 0.4546792507171631\n",
            "Epoch: 2/9\n",
            "168\n",
            "Loss: 0.41381600499153137\n",
            "Epoch: 2/9\n",
            "169\n",
            "Loss: 0.48074430227279663\n",
            "Epoch: 2/9\n",
            "170\n",
            "Loss: 0.45535728335380554\n",
            "Epoch: 2/9\n",
            "171\n",
            "Loss: 0.3996979594230652\n",
            "Epoch: 2/9\n",
            "172\n",
            "Loss: 0.4712163507938385\n",
            "Epoch: 2/9\n",
            "173\n",
            "Loss: 0.43657392263412476\n",
            "Epoch: 2/9\n",
            "174\n",
            "Loss: 0.4623609185218811\n",
            "Epoch: 2/9\n",
            "175\n",
            "Loss: 0.3670075237751007\n",
            "Epoch: 2/9\n",
            "176\n",
            "Loss: 0.46859946846961975\n",
            "Epoch: 2/9\n",
            "177\n",
            "Loss: 0.46673399209976196\n",
            "Epoch: 2/9\n",
            "178\n",
            "Loss: 0.5374011397361755\n",
            "Epoch: 2/9\n",
            "179\n",
            "Loss: 0.4988108277320862\n",
            "Epoch: 2/9\n",
            "180\n",
            "Loss: 0.5234736204147339\n",
            "Epoch: 2/9\n",
            "181\n",
            "Loss: 0.5475659966468811\n",
            "Epoch: 2/9\n",
            "182\n",
            "Loss: 0.4636543095111847\n",
            "Epoch: 2/9\n",
            "183\n",
            "Loss: 0.5164034366607666\n",
            "Epoch: 2/9\n",
            "184\n",
            "Loss: 0.5087523460388184\n",
            "Epoch: 2/9\n",
            "185\n",
            "Loss: 0.4473828375339508\n",
            "Epoch: 2/9\n",
            "186\n",
            "Loss: 0.5244296789169312\n",
            "Epoch: 2/9\n",
            "187\n",
            "Loss: 0.5155923366546631\n",
            "Epoch: 2/9\n",
            "188\n",
            "Loss: 0.46387824416160583\n",
            "Epoch: 2/9\n",
            "189\n",
            "Loss: 0.392544686794281\n",
            "Epoch: 2/9\n",
            "190\n",
            "Loss: 0.43489742279052734\n",
            "Epoch: 2/9\n",
            "191\n",
            "Loss: 0.3976876437664032\n",
            "Epoch: 2/9\n",
            "192\n",
            "Loss: 0.3590642213821411\n",
            "Epoch: 2/9\n",
            "193\n",
            "Loss: 0.4130396544933319\n",
            "Epoch: 2/9\n",
            "194\n",
            "Loss: 0.3101583421230316\n",
            "Epoch: 2/9\n",
            "195\n",
            "Loss: 0.2186860740184784\n",
            "Epoch: 2/9\n",
            "Epoch: 3\n",
            "0\n",
            "Loss: 0.5194082260131836\n",
            "Epoch: 3/9\n",
            "1\n",
            "Loss: 0.505616307258606\n",
            "Epoch: 3/9\n",
            "2\n",
            "Loss: 0.412763386964798\n",
            "Epoch: 3/9\n",
            "3\n",
            "Loss: 0.5061458945274353\n",
            "Epoch: 3/9\n",
            "4\n",
            "Loss: 0.660615086555481\n",
            "Epoch: 3/9\n",
            "5\n",
            "Loss: 0.5469945073127747\n",
            "Epoch: 3/9\n",
            "6\n",
            "Loss: 0.4907490909099579\n",
            "Epoch: 3/9\n",
            "7\n",
            "Loss: 0.6404165029525757\n",
            "Epoch: 3/9\n",
            "8\n",
            "Loss: 0.6105067729949951\n",
            "Epoch: 3/9\n",
            "9\n",
            "Loss: 0.5358874797821045\n",
            "Epoch: 3/9\n",
            "10\n",
            "Loss: 0.5506891012191772\n",
            "Epoch: 3/9\n",
            "11\n",
            "Loss: 0.7108624577522278\n",
            "Epoch: 3/9\n",
            "12\n",
            "Loss: 0.6568189263343811\n",
            "Epoch: 3/9\n",
            "13\n",
            "Loss: 0.5895909667015076\n",
            "Epoch: 3/9\n",
            "14\n",
            "Loss: 0.6347415447235107\n",
            "Epoch: 3/9\n",
            "15\n",
            "Loss: 0.6684942245483398\n",
            "Epoch: 3/9\n",
            "16\n",
            "Loss: 0.7037463784217834\n",
            "Epoch: 3/9\n",
            "17\n",
            "Loss: 0.7158346772193909\n",
            "Epoch: 3/9\n",
            "18\n",
            "Loss: 0.6229476928710938\n",
            "Epoch: 3/9\n",
            "19\n",
            "Loss: 0.6640493869781494\n",
            "Epoch: 3/9\n",
            "20\n",
            "Loss: 0.6690681576728821\n",
            "Epoch: 3/9\n",
            "21\n",
            "Loss: 0.6792312264442444\n",
            "Epoch: 3/9\n",
            "22\n",
            "Loss: 0.6439872980117798\n",
            "Epoch: 3/9\n",
            "23\n",
            "Loss: 0.6046357750892639\n",
            "Epoch: 3/9\n",
            "24\n",
            "Loss: 0.6708081960678101\n",
            "Epoch: 3/9\n",
            "25\n",
            "Loss: 0.6893609166145325\n",
            "Epoch: 3/9\n",
            "26\n",
            "Loss: 0.7059336304664612\n",
            "Epoch: 3/9\n",
            "27\n",
            "Loss: 0.6776085495948792\n",
            "Epoch: 3/9\n",
            "28\n",
            "Loss: 0.592859148979187\n",
            "Epoch: 3/9\n",
            "29\n",
            "Loss: 0.6893632411956787\n",
            "Epoch: 3/9\n",
            "30\n",
            "Loss: 0.6259615421295166\n",
            "Epoch: 3/9\n",
            "31\n",
            "Loss: 0.6596431136131287\n",
            "Epoch: 3/9\n",
            "32\n",
            "Loss: 0.5627582669258118\n",
            "Epoch: 3/9\n",
            "33\n",
            "Loss: 0.6977747678756714\n",
            "Epoch: 3/9\n",
            "34\n",
            "Loss: 0.6459315419197083\n",
            "Epoch: 3/9\n",
            "35\n",
            "Loss: 0.6836042404174805\n",
            "Epoch: 3/9\n",
            "36\n",
            "Loss: 0.7645179033279419\n",
            "Epoch: 3/9\n",
            "37\n",
            "Loss: 0.6261817216873169\n",
            "Epoch: 3/9\n",
            "38\n",
            "Loss: 0.6248414516448975\n",
            "Epoch: 3/9\n",
            "39\n",
            "Loss: 0.7464102506637573\n",
            "Epoch: 3/9\n",
            "40\n",
            "Loss: 0.7267463803291321\n",
            "Epoch: 3/9\n",
            "41\n",
            "Loss: 0.5987167954444885\n",
            "Epoch: 3/9\n",
            "42\n",
            "Loss: 0.6760557293891907\n",
            "Epoch: 3/9\n",
            "43\n",
            "Loss: 0.8087972402572632\n",
            "Epoch: 3/9\n",
            "44\n",
            "Loss: 0.6333563923835754\n",
            "Epoch: 3/9\n",
            "45\n",
            "Loss: 0.6176934242248535\n",
            "Epoch: 3/9\n",
            "46\n",
            "Loss: 0.6306194067001343\n",
            "Epoch: 3/9\n",
            "47\n",
            "Loss: 0.7252675890922546\n",
            "Epoch: 3/9\n",
            "48\n",
            "Loss: 0.7276586890220642\n",
            "Epoch: 3/9\n",
            "49\n",
            "Loss: 0.648270308971405\n",
            "Epoch: 3/9\n",
            "50\n",
            "Loss: 0.6851693987846375\n",
            "Epoch: 3/9\n",
            "51\n",
            "Loss: 0.7474265098571777\n",
            "Epoch: 3/9\n",
            "52\n",
            "Loss: 0.6992741227149963\n",
            "Epoch: 3/9\n",
            "53\n",
            "Loss: 0.75433748960495\n",
            "Epoch: 3/9\n",
            "54\n",
            "Loss: 0.704096257686615\n",
            "Epoch: 3/9\n",
            "55\n",
            "Loss: 0.6632640361785889\n",
            "Epoch: 3/9\n",
            "56\n",
            "Loss: 0.7015362977981567\n",
            "Epoch: 3/9\n",
            "57\n",
            "Loss: 0.6380447745323181\n",
            "Epoch: 3/9\n",
            "58\n",
            "Loss: 0.6107853651046753\n",
            "Epoch: 3/9\n",
            "59\n",
            "Loss: 0.6455868482589722\n",
            "Epoch: 3/9\n",
            "60\n",
            "Loss: 0.6265659332275391\n",
            "Epoch: 3/9\n",
            "61\n",
            "Loss: 0.5936642289161682\n",
            "Epoch: 3/9\n",
            "62\n",
            "Loss: 0.6503601670265198\n",
            "Epoch: 3/9\n",
            "63\n",
            "Loss: 0.5941023826599121\n",
            "Epoch: 3/9\n",
            "64\n",
            "Loss: 0.5948695540428162\n",
            "Epoch: 3/9\n",
            "65\n",
            "Loss: 0.5307890176773071\n",
            "Epoch: 3/9\n",
            "66\n",
            "Loss: 0.5387104749679565\n",
            "Epoch: 3/9\n",
            "67\n",
            "Loss: 0.6362164616584778\n",
            "Epoch: 3/9\n",
            "68\n",
            "Loss: 0.6010528802871704\n",
            "Epoch: 3/9\n",
            "69\n",
            "Loss: 0.6612580418586731\n",
            "Epoch: 3/9\n",
            "70\n",
            "Loss: 0.675349235534668\n",
            "Epoch: 3/9\n",
            "71\n",
            "Loss: 0.6521678566932678\n",
            "Epoch: 3/9\n",
            "72\n",
            "Loss: 0.7006694674491882\n",
            "Epoch: 3/9\n",
            "73\n",
            "Loss: 0.6647018790245056\n",
            "Epoch: 3/9\n",
            "74\n",
            "Loss: 0.6845898032188416\n",
            "Epoch: 3/9\n",
            "75\n",
            "Loss: 0.6127680540084839\n",
            "Epoch: 3/9\n",
            "76\n",
            "Loss: 0.6910683512687683\n",
            "Epoch: 3/9\n",
            "77\n",
            "Loss: 0.679121732711792\n",
            "Epoch: 3/9\n",
            "78\n",
            "Loss: 0.7300866842269897\n",
            "Epoch: 3/9\n",
            "79\n",
            "Loss: 0.6503543257713318\n",
            "Epoch: 3/9\n",
            "80\n",
            "Loss: 0.6244943141937256\n",
            "Epoch: 3/9\n",
            "81\n",
            "Loss: 0.6800451874732971\n",
            "Epoch: 3/9\n",
            "82\n",
            "Loss: 0.6156491041183472\n",
            "Epoch: 3/9\n",
            "83\n",
            "Loss: 0.7364985346794128\n",
            "Epoch: 3/9\n",
            "84\n",
            "Loss: 0.6466067433357239\n",
            "Epoch: 3/9\n",
            "85\n",
            "Loss: 0.74424809217453\n",
            "Epoch: 3/9\n",
            "86\n",
            "Loss: 0.7085351943969727\n",
            "Epoch: 3/9\n",
            "87\n",
            "Loss: 0.7036455273628235\n",
            "Epoch: 3/9\n",
            "88\n",
            "Loss: 0.5924521684646606\n",
            "Epoch: 3/9\n",
            "89\n",
            "Loss: 0.6905180215835571\n",
            "Epoch: 3/9\n",
            "90\n",
            "Loss: 0.6640658974647522\n",
            "Epoch: 3/9\n",
            "91\n",
            "Loss: 0.656480610370636\n",
            "Epoch: 3/9\n",
            "92\n",
            "Loss: 0.6557185053825378\n",
            "Epoch: 3/9\n",
            "93\n",
            "Loss: 0.6031489968299866\n",
            "Epoch: 3/9\n",
            "94\n",
            "Loss: 0.6286658048629761\n",
            "Epoch: 3/9\n",
            "95\n",
            "Loss: 0.6625177264213562\n",
            "Epoch: 3/9\n",
            "96\n",
            "Loss: 0.6716232895851135\n",
            "Epoch: 3/9\n",
            "97\n",
            "Loss: 0.6119932532310486\n",
            "Epoch: 3/9\n",
            "98\n",
            "Loss: 0.7031112909317017\n",
            "Epoch: 3/9\n",
            "99\n",
            "Loss: 0.6021982431411743\n",
            "Epoch: 3/9\n",
            "100\n",
            "Loss: 0.6427803039550781\n",
            "Epoch: 3/9\n",
            "101\n",
            "Loss: 0.6029888987541199\n",
            "Epoch: 3/9\n",
            "102\n",
            "Loss: 0.5547593832015991\n",
            "Epoch: 3/9\n",
            "103\n",
            "Loss: 0.6158888936042786\n",
            "Epoch: 3/9\n",
            "104\n",
            "Loss: 0.6742939949035645\n",
            "Epoch: 3/9\n",
            "105\n",
            "Loss: 0.634690523147583\n",
            "Epoch: 3/9\n",
            "106\n",
            "Loss: 0.6681950092315674\n",
            "Epoch: 3/9\n",
            "107\n",
            "Loss: 0.6048301458358765\n",
            "Epoch: 3/9\n",
            "108\n",
            "Loss: 0.5773158073425293\n",
            "Epoch: 3/9\n",
            "109\n",
            "Loss: 0.5926519632339478\n",
            "Epoch: 3/9\n",
            "110\n",
            "Loss: 0.6041895151138306\n",
            "Epoch: 3/9\n",
            "111\n",
            "Loss: 0.6480018496513367\n",
            "Epoch: 3/9\n",
            "112\n",
            "Loss: 0.5476865172386169\n",
            "Epoch: 3/9\n",
            "113\n",
            "Loss: 0.5642291903495789\n",
            "Epoch: 3/9\n",
            "114\n",
            "Loss: 0.5736188888549805\n",
            "Epoch: 3/9\n",
            "115\n",
            "Loss: 0.6046581268310547\n",
            "Epoch: 3/9\n",
            "116\n",
            "Loss: 0.5876116156578064\n",
            "Epoch: 3/9\n",
            "117\n",
            "Loss: 0.5914303064346313\n",
            "Epoch: 3/9\n",
            "118\n",
            "Loss: 0.5493837594985962\n",
            "Epoch: 3/9\n",
            "119\n",
            "Loss: 0.5796307325363159\n",
            "Epoch: 3/9\n",
            "120\n",
            "Loss: 0.7117983102798462\n",
            "Epoch: 3/9\n",
            "121\n",
            "Loss: 0.5853971838951111\n",
            "Epoch: 3/9\n",
            "122\n",
            "Loss: 0.5543726086616516\n",
            "Epoch: 3/9\n",
            "123\n",
            "Loss: 0.6063874363899231\n",
            "Epoch: 3/9\n",
            "124\n",
            "Loss: 0.6549447178840637\n",
            "Epoch: 3/9\n",
            "125\n",
            "Loss: 0.7207854390144348\n",
            "Epoch: 3/9\n",
            "126\n",
            "Loss: 0.6431125998497009\n",
            "Epoch: 3/9\n",
            "127\n",
            "Loss: 0.679964542388916\n",
            "Epoch: 3/9\n",
            "128\n",
            "Loss: 0.61412113904953\n",
            "Epoch: 3/9\n",
            "129\n",
            "Loss: 0.6149937510490417\n",
            "Epoch: 3/9\n",
            "130\n",
            "Loss: 0.668920636177063\n",
            "Epoch: 3/9\n",
            "131\n",
            "Loss: 0.7934231758117676\n",
            "Epoch: 3/9\n",
            "132\n",
            "Loss: 0.7490121126174927\n",
            "Epoch: 3/9\n",
            "133\n",
            "Loss: 0.5388408303260803\n",
            "Epoch: 3/9\n",
            "134\n",
            "Loss: 0.7454929947853088\n",
            "Epoch: 3/9\n",
            "135\n",
            "Loss: 0.5966373682022095\n",
            "Epoch: 3/9\n",
            "136\n",
            "Loss: 0.689501166343689\n",
            "Epoch: 3/9\n",
            "137\n",
            "Loss: 0.6836891770362854\n",
            "Epoch: 3/9\n",
            "138\n",
            "Loss: 0.6082900166511536\n",
            "Epoch: 3/9\n",
            "139\n",
            "Loss: 0.6919955611228943\n",
            "Epoch: 3/9\n",
            "140\n",
            "Loss: 0.6179959177970886\n",
            "Epoch: 3/9\n",
            "141\n",
            "Loss: 0.6876431107521057\n",
            "Epoch: 3/9\n",
            "142\n",
            "Loss: 0.5602884292602539\n",
            "Epoch: 3/9\n",
            "143\n",
            "Loss: 0.6211004853248596\n",
            "Epoch: 3/9\n",
            "144\n",
            "Loss: 0.5659319758415222\n",
            "Epoch: 3/9\n",
            "145\n",
            "Loss: 0.6492322087287903\n",
            "Epoch: 3/9\n",
            "146\n",
            "Loss: 0.6122606992721558\n",
            "Epoch: 3/9\n",
            "147\n",
            "Loss: 0.5831679701805115\n",
            "Epoch: 3/9\n",
            "148\n",
            "Loss: 0.6214853525161743\n",
            "Epoch: 3/9\n",
            "149\n",
            "Loss: 0.5952531695365906\n",
            "Epoch: 3/9\n",
            "150\n",
            "Loss: 0.5452360510826111\n",
            "Epoch: 3/9\n",
            "151\n",
            "Loss: 0.4516231417655945\n",
            "Epoch: 3/9\n",
            "152\n",
            "Loss: 0.5244413614273071\n",
            "Epoch: 3/9\n",
            "153\n",
            "Loss: 0.5753411650657654\n",
            "Epoch: 3/9\n",
            "154\n",
            "Loss: 0.5067625641822815\n",
            "Epoch: 3/9\n",
            "155\n",
            "Loss: 0.5468186140060425\n",
            "Epoch: 3/9\n",
            "156\n",
            "Loss: 0.44497251510620117\n",
            "Epoch: 3/9\n",
            "157\n",
            "Loss: 0.6313312649726868\n",
            "Epoch: 3/9\n",
            "158\n",
            "Loss: 0.5745506882667542\n",
            "Epoch: 3/9\n",
            "159\n",
            "Loss: 0.5874652862548828\n",
            "Epoch: 3/9\n",
            "160\n",
            "Loss: 0.5336064696311951\n",
            "Epoch: 3/9\n",
            "161\n",
            "Loss: 0.48616331815719604\n",
            "Epoch: 3/9\n",
            "162\n",
            "Loss: 0.5926716923713684\n",
            "Epoch: 3/9\n",
            "163\n",
            "Loss: 0.4929060637950897\n",
            "Epoch: 3/9\n",
            "164\n",
            "Loss: 0.5844011902809143\n",
            "Epoch: 3/9\n",
            "165\n",
            "Loss: 0.4642769396305084\n",
            "Epoch: 3/9\n",
            "166\n",
            "Loss: 0.3817170262336731\n",
            "Epoch: 3/9\n",
            "167\n",
            "Loss: 0.45032384991645813\n",
            "Epoch: 3/9\n",
            "168\n",
            "Loss: 0.41004064679145813\n",
            "Epoch: 3/9\n",
            "169\n",
            "Loss: 0.4765477776527405\n",
            "Epoch: 3/9\n",
            "170\n",
            "Loss: 0.4527241587638855\n",
            "Epoch: 3/9\n",
            "171\n",
            "Loss: 0.3953513205051422\n",
            "Epoch: 3/9\n",
            "172\n",
            "Loss: 0.4690987467765808\n",
            "Epoch: 3/9\n",
            "173\n",
            "Loss: 0.43203362822532654\n",
            "Epoch: 3/9\n",
            "174\n",
            "Loss: 0.4552015960216522\n",
            "Epoch: 3/9\n",
            "175\n",
            "Loss: 0.36172765493392944\n",
            "Epoch: 3/9\n",
            "176\n",
            "Loss: 0.46392491459846497\n",
            "Epoch: 3/9\n",
            "177\n",
            "Loss: 0.46100062131881714\n",
            "Epoch: 3/9\n",
            "178\n",
            "Loss: 0.5351401567459106\n",
            "Epoch: 3/9\n",
            "179\n",
            "Loss: 0.49488741159439087\n",
            "Epoch: 3/9\n",
            "180\n",
            "Loss: 0.5183647871017456\n",
            "Epoch: 3/9\n",
            "181\n",
            "Loss: 0.5424074530601501\n",
            "Epoch: 3/9\n",
            "182\n",
            "Loss: 0.4610540270805359\n",
            "Epoch: 3/9\n",
            "183\n",
            "Loss: 0.5115273594856262\n",
            "Epoch: 3/9\n",
            "184\n",
            "Loss: 0.5050190687179565\n",
            "Epoch: 3/9\n",
            "185\n",
            "Loss: 0.44287461042404175\n",
            "Epoch: 3/9\n",
            "186\n",
            "Loss: 0.5196835994720459\n",
            "Epoch: 3/9\n",
            "187\n",
            "Loss: 0.510250449180603\n",
            "Epoch: 3/9\n",
            "188\n",
            "Loss: 0.4578801691532135\n",
            "Epoch: 3/9\n",
            "189\n",
            "Loss: 0.38687869906425476\n",
            "Epoch: 3/9\n",
            "190\n",
            "Loss: 0.42965012788772583\n",
            "Epoch: 3/9\n",
            "191\n",
            "Loss: 0.392011821269989\n",
            "Epoch: 3/9\n",
            "192\n",
            "Loss: 0.3544809818267822\n",
            "Epoch: 3/9\n",
            "193\n",
            "Loss: 0.40705978870391846\n",
            "Epoch: 3/9\n",
            "194\n",
            "Loss: 0.3067012429237366\n",
            "Epoch: 3/9\n",
            "195\n",
            "Loss: 0.2153441160917282\n",
            "Epoch: 3/9\n",
            "Epoch: 4\n",
            "0\n",
            "Loss: 0.5128872394561768\n",
            "Epoch: 4/9\n",
            "1\n",
            "Loss: 0.5026837587356567\n",
            "Epoch: 4/9\n",
            "2\n",
            "Loss: 0.40649840235710144\n",
            "Epoch: 4/9\n",
            "3\n",
            "Loss: 0.5004811882972717\n",
            "Epoch: 4/9\n",
            "4\n",
            "Loss: 0.6563631296157837\n",
            "Epoch: 4/9\n",
            "5\n",
            "Loss: 0.5416241884231567\n",
            "Epoch: 4/9\n",
            "6\n",
            "Loss: 0.4863639771938324\n",
            "Epoch: 4/9\n",
            "7\n",
            "Loss: 0.6366767287254333\n",
            "Epoch: 4/9\n",
            "8\n",
            "Loss: 0.6052750945091248\n",
            "Epoch: 4/9\n",
            "9\n",
            "Loss: 0.5329091548919678\n",
            "Epoch: 4/9\n",
            "10\n",
            "Loss: 0.544801652431488\n",
            "Epoch: 4/9\n",
            "11\n",
            "Loss: 0.7066500782966614\n",
            "Epoch: 4/9\n",
            "12\n",
            "Loss: 0.6504896283149719\n",
            "Epoch: 4/9\n",
            "13\n",
            "Loss: 0.5875450968742371\n",
            "Epoch: 4/9\n",
            "14\n",
            "Loss: 0.6307981014251709\n",
            "Epoch: 4/9\n",
            "15\n",
            "Loss: 0.6648106575012207\n",
            "Epoch: 4/9\n",
            "16\n",
            "Loss: 0.6977280974388123\n",
            "Epoch: 4/9\n",
            "17\n",
            "Loss: 0.7113010287284851\n",
            "Epoch: 4/9\n",
            "18\n",
            "Loss: 0.6202755570411682\n",
            "Epoch: 4/9\n",
            "19\n",
            "Loss: 0.6625474095344543\n",
            "Epoch: 4/9\n",
            "20\n",
            "Loss: 0.6632193922996521\n",
            "Epoch: 4/9\n",
            "21\n",
            "Loss: 0.6720861792564392\n",
            "Epoch: 4/9\n",
            "22\n",
            "Loss: 0.6405983567237854\n",
            "Epoch: 4/9\n",
            "23\n",
            "Loss: 0.5998304486274719\n",
            "Epoch: 4/9\n",
            "24\n",
            "Loss: 0.6667572259902954\n",
            "Epoch: 4/9\n",
            "25\n",
            "Loss: 0.6833159923553467\n",
            "Epoch: 4/9\n",
            "26\n",
            "Loss: 0.7019527554512024\n",
            "Epoch: 4/9\n",
            "27\n",
            "Loss: 0.6699633598327637\n",
            "Epoch: 4/9\n",
            "28\n",
            "Loss: 0.586664617061615\n",
            "Epoch: 4/9\n",
            "29\n",
            "Loss: 0.6849619150161743\n",
            "Epoch: 4/9\n",
            "30\n",
            "Loss: 0.6207089424133301\n",
            "Epoch: 4/9\n",
            "31\n",
            "Loss: 0.6552541255950928\n",
            "Epoch: 4/9\n",
            "32\n",
            "Loss: 0.5588367581367493\n",
            "Epoch: 4/9\n",
            "33\n",
            "Loss: 0.692577600479126\n",
            "Epoch: 4/9\n",
            "34\n",
            "Loss: 0.6397578120231628\n",
            "Epoch: 4/9\n",
            "35\n",
            "Loss: 0.6796778440475464\n",
            "Epoch: 4/9\n",
            "36\n",
            "Loss: 0.7588815689086914\n",
            "Epoch: 4/9\n",
            "37\n",
            "Loss: 0.6208850741386414\n",
            "Epoch: 4/9\n",
            "38\n",
            "Loss: 0.6195955276489258\n",
            "Epoch: 4/9\n",
            "39\n",
            "Loss: 0.743938684463501\n",
            "Epoch: 4/9\n",
            "40\n",
            "Loss: 0.7245739102363586\n",
            "Epoch: 4/9\n",
            "41\n",
            "Loss: 0.5949300527572632\n",
            "Epoch: 4/9\n",
            "42\n",
            "Loss: 0.6721088886260986\n",
            "Epoch: 4/9\n",
            "43\n",
            "Loss: 0.8027744889259338\n",
            "Epoch: 4/9\n",
            "44\n",
            "Loss: 0.6274115443229675\n",
            "Epoch: 4/9\n",
            "45\n",
            "Loss: 0.6158727407455444\n",
            "Epoch: 4/9\n",
            "46\n",
            "Loss: 0.6231541633605957\n",
            "Epoch: 4/9\n",
            "47\n",
            "Loss: 0.7244720458984375\n",
            "Epoch: 4/9\n",
            "48\n",
            "Loss: 0.7232656478881836\n",
            "Epoch: 4/9\n",
            "49\n",
            "Loss: 0.6424020528793335\n",
            "Epoch: 4/9\n",
            "50\n",
            "Loss: 0.6800113916397095\n",
            "Epoch: 4/9\n",
            "51\n",
            "Loss: 0.7441291213035583\n",
            "Epoch: 4/9\n",
            "52\n",
            "Loss: 0.693986177444458\n",
            "Epoch: 4/9\n",
            "53\n",
            "Loss: 0.7491379380226135\n",
            "Epoch: 4/9\n",
            "54\n",
            "Loss: 0.7005748748779297\n",
            "Epoch: 4/9\n",
            "55\n",
            "Loss: 0.6578665375709534\n",
            "Epoch: 4/9\n",
            "56\n",
            "Loss: 0.693606436252594\n",
            "Epoch: 4/9\n",
            "57\n",
            "Loss: 0.6334750056266785\n",
            "Epoch: 4/9\n",
            "58\n",
            "Loss: 0.6059099435806274\n",
            "Epoch: 4/9\n",
            "59\n",
            "Loss: 0.6425006985664368\n",
            "Epoch: 4/9\n",
            "60\n",
            "Loss: 0.6196109056472778\n",
            "Epoch: 4/9\n",
            "61\n",
            "Loss: 0.5910722017288208\n",
            "Epoch: 4/9\n",
            "62\n",
            "Loss: 0.6484201550483704\n",
            "Epoch: 4/9\n",
            "63\n",
            "Loss: 0.5912627577781677\n",
            "Epoch: 4/9\n",
            "64\n",
            "Loss: 0.5940616726875305\n",
            "Epoch: 4/9\n",
            "65\n",
            "Loss: 0.5280803442001343\n",
            "Epoch: 4/9\n",
            "66\n",
            "Loss: 0.5336170196533203\n",
            "Epoch: 4/9\n",
            "67\n",
            "Loss: 0.6310954689979553\n",
            "Epoch: 4/9\n",
            "68\n",
            "Loss: 0.5960655212402344\n",
            "Epoch: 4/9\n",
            "69\n",
            "Loss: 0.657739520072937\n",
            "Epoch: 4/9\n",
            "70\n",
            "Loss: 0.6730229258537292\n",
            "Epoch: 4/9\n",
            "71\n",
            "Loss: 0.6467161178588867\n",
            "Epoch: 4/9\n",
            "72\n",
            "Loss: 0.6978928446769714\n",
            "Epoch: 4/9\n",
            "73\n",
            "Loss: 0.65799480676651\n",
            "Epoch: 4/9\n",
            "74\n",
            "Loss: 0.6821882724761963\n",
            "Epoch: 4/9\n",
            "75\n",
            "Loss: 0.6077024936676025\n",
            "Epoch: 4/9\n",
            "76\n",
            "Loss: 0.6859955787658691\n",
            "Epoch: 4/9\n",
            "77\n",
            "Loss: 0.674443244934082\n",
            "Epoch: 4/9\n",
            "78\n",
            "Loss: 0.7238572239875793\n",
            "Epoch: 4/9\n",
            "79\n",
            "Loss: 0.646411657333374\n",
            "Epoch: 4/9\n",
            "80\n",
            "Loss: 0.617596447467804\n",
            "Epoch: 4/9\n",
            "81\n",
            "Loss: 0.6762024164199829\n",
            "Epoch: 4/9\n",
            "82\n",
            "Loss: 0.6083419919013977\n",
            "Epoch: 4/9\n",
            "83\n",
            "Loss: 0.7332115173339844\n",
            "Epoch: 4/9\n",
            "84\n",
            "Loss: 0.6447307467460632\n",
            "Epoch: 4/9\n",
            "85\n",
            "Loss: 0.7386265993118286\n",
            "Epoch: 4/9\n",
            "86\n",
            "Loss: 0.7039582133293152\n",
            "Epoch: 4/9\n",
            "87\n",
            "Loss: 0.7009601593017578\n",
            "Epoch: 4/9\n",
            "88\n",
            "Loss: 0.5881280899047852\n",
            "Epoch: 4/9\n",
            "89\n",
            "Loss: 0.6856160163879395\n",
            "Epoch: 4/9\n",
            "90\n",
            "Loss: 0.6591816544532776\n",
            "Epoch: 4/9\n",
            "91\n",
            "Loss: 0.6503697037696838\n",
            "Epoch: 4/9\n",
            "92\n",
            "Loss: 0.6513325572013855\n",
            "Epoch: 4/9\n",
            "93\n",
            "Loss: 0.5990362763404846\n",
            "Epoch: 4/9\n",
            "94\n",
            "Loss: 0.625697672367096\n",
            "Epoch: 4/9\n",
            "95\n",
            "Loss: 0.6596470475196838\n",
            "Epoch: 4/9\n",
            "96\n",
            "Loss: 0.6652823686599731\n",
            "Epoch: 4/9\n",
            "97\n",
            "Loss: 0.6055889129638672\n",
            "Epoch: 4/9\n",
            "98\n",
            "Loss: 0.700748085975647\n",
            "Epoch: 4/9\n",
            "99\n",
            "Loss: 0.5984575748443604\n",
            "Epoch: 4/9\n",
            "100\n",
            "Loss: 0.6392995715141296\n",
            "Epoch: 4/9\n",
            "101\n",
            "Loss: 0.5994528532028198\n",
            "Epoch: 4/9\n",
            "102\n",
            "Loss: 0.551788866519928\n",
            "Epoch: 4/9\n",
            "103\n",
            "Loss: 0.6128911375999451\n",
            "Epoch: 4/9\n",
            "104\n",
            "Loss: 0.6681144833564758\n",
            "Epoch: 4/9\n",
            "105\n",
            "Loss: 0.6327111124992371\n",
            "Epoch: 4/9\n",
            "106\n",
            "Loss: 0.6611552834510803\n",
            "Epoch: 4/9\n",
            "107\n",
            "Loss: 0.598828911781311\n",
            "Epoch: 4/9\n",
            "108\n",
            "Loss: 0.5757158994674683\n",
            "Epoch: 4/9\n",
            "109\n",
            "Loss: 0.590336263179779\n",
            "Epoch: 4/9\n",
            "110\n",
            "Loss: 0.6013603210449219\n",
            "Epoch: 4/9\n",
            "111\n",
            "Loss: 0.6421582102775574\n",
            "Epoch: 4/9\n",
            "112\n",
            "Loss: 0.5396193861961365\n",
            "Epoch: 4/9\n",
            "113\n",
            "Loss: 0.558788001537323\n",
            "Epoch: 4/9\n",
            "114\n",
            "Loss: 0.5699399709701538\n",
            "Epoch: 4/9\n",
            "115\n",
            "Loss: 0.6016016602516174\n",
            "Epoch: 4/9\n",
            "116\n",
            "Loss: 0.5852676630020142\n",
            "Epoch: 4/9\n",
            "117\n",
            "Loss: 0.5856154561042786\n",
            "Epoch: 4/9\n",
            "118\n",
            "Loss: 0.5456850528717041\n",
            "Epoch: 4/9\n",
            "119\n",
            "Loss: 0.5752752423286438\n",
            "Epoch: 4/9\n",
            "120\n",
            "Loss: 0.7074273824691772\n",
            "Epoch: 4/9\n",
            "121\n",
            "Loss: 0.5830560922622681\n",
            "Epoch: 4/9\n",
            "122\n",
            "Loss: 0.5510861277580261\n",
            "Epoch: 4/9\n",
            "123\n",
            "Loss: 0.6009039878845215\n",
            "Epoch: 4/9\n",
            "124\n",
            "Loss: 0.6509626507759094\n",
            "Epoch: 4/9\n",
            "125\n",
            "Loss: 0.7173537015914917\n",
            "Epoch: 4/9\n",
            "126\n",
            "Loss: 0.6381669640541077\n",
            "Epoch: 4/9\n",
            "127\n",
            "Loss: 0.6754238605499268\n",
            "Epoch: 4/9\n",
            "128\n",
            "Loss: 0.6085184812545776\n",
            "Epoch: 4/9\n",
            "129\n",
            "Loss: 0.6120154857635498\n",
            "Epoch: 4/9\n",
            "130\n",
            "Loss: 0.664842963218689\n",
            "Epoch: 4/9\n",
            "131\n",
            "Loss: 0.7882797122001648\n",
            "Epoch: 4/9\n",
            "132\n",
            "Loss: 0.744256317615509\n",
            "Epoch: 4/9\n",
            "133\n",
            "Loss: 0.535161554813385\n",
            "Epoch: 4/9\n",
            "134\n",
            "Loss: 0.7387065887451172\n",
            "Epoch: 4/9\n",
            "135\n",
            "Loss: 0.5924482345581055\n",
            "Epoch: 4/9\n",
            "136\n",
            "Loss: 0.6819679141044617\n",
            "Epoch: 4/9\n",
            "137\n",
            "Loss: 0.6780494451522827\n",
            "Epoch: 4/9\n",
            "138\n",
            "Loss: 0.6033607721328735\n",
            "Epoch: 4/9\n",
            "139\n",
            "Loss: 0.688369870185852\n",
            "Epoch: 4/9\n",
            "140\n",
            "Loss: 0.614304780960083\n",
            "Epoch: 4/9\n",
            "141\n",
            "Loss: 0.680311918258667\n",
            "Epoch: 4/9\n",
            "142\n",
            "Loss: 0.5545262098312378\n",
            "Epoch: 4/9\n",
            "143\n",
            "Loss: 0.617993175983429\n",
            "Epoch: 4/9\n",
            "144\n",
            "Loss: 0.5634613037109375\n",
            "Epoch: 4/9\n",
            "145\n",
            "Loss: 0.6455110907554626\n",
            "Epoch: 4/9\n",
            "146\n",
            "Loss: 0.6085586547851562\n",
            "Epoch: 4/9\n",
            "147\n",
            "Loss: 0.5795813798904419\n",
            "Epoch: 4/9\n",
            "148\n",
            "Loss: 0.6168620586395264\n",
            "Epoch: 4/9\n",
            "149\n",
            "Loss: 0.5934105515480042\n",
            "Epoch: 4/9\n",
            "150\n",
            "Loss: 0.5430326461791992\n",
            "Epoch: 4/9\n",
            "151\n",
            "Loss: 0.44806867837905884\n",
            "Epoch: 4/9\n",
            "152\n",
            "Loss: 0.5207161903381348\n",
            "Epoch: 4/9\n",
            "153\n",
            "Loss: 0.5706990361213684\n",
            "Epoch: 4/9\n",
            "154\n",
            "Loss: 0.5038352012634277\n",
            "Epoch: 4/9\n",
            "155\n",
            "Loss: 0.5402286648750305\n",
            "Epoch: 4/9\n",
            "156\n",
            "Loss: 0.44119104743003845\n",
            "Epoch: 4/9\n",
            "157\n",
            "Loss: 0.6270366907119751\n",
            "Epoch: 4/9\n",
            "158\n",
            "Loss: 0.5713264346122742\n",
            "Epoch: 4/9\n",
            "159\n",
            "Loss: 0.5828382968902588\n",
            "Epoch: 4/9\n",
            "160\n",
            "Loss: 0.5273842215538025\n",
            "Epoch: 4/9\n",
            "161\n",
            "Loss: 0.48084965348243713\n",
            "Epoch: 4/9\n",
            "162\n",
            "Loss: 0.5862053632736206\n",
            "Epoch: 4/9\n",
            "163\n",
            "Loss: 0.48923635482788086\n",
            "Epoch: 4/9\n",
            "164\n",
            "Loss: 0.5769136548042297\n",
            "Epoch: 4/9\n",
            "165\n",
            "Loss: 0.4594934582710266\n",
            "Epoch: 4/9\n",
            "166\n",
            "Loss: 0.37576234340667725\n",
            "Epoch: 4/9\n",
            "167\n",
            "Loss: 0.4459422528743744\n",
            "Epoch: 4/9\n",
            "168\n",
            "Loss: 0.4070329964160919\n",
            "Epoch: 4/9\n",
            "169\n",
            "Loss: 0.47289371490478516\n",
            "Epoch: 4/9\n",
            "170\n",
            "Loss: 0.45034822821617126\n",
            "Epoch: 4/9\n",
            "171\n",
            "Loss: 0.3907097280025482\n",
            "Epoch: 4/9\n",
            "172\n",
            "Loss: 0.466673344373703\n",
            "Epoch: 4/9\n",
            "173\n",
            "Loss: 0.4274521470069885\n",
            "Epoch: 4/9\n",
            "174\n",
            "Loss: 0.44865331053733826\n",
            "Epoch: 4/9\n",
            "175\n",
            "Loss: 0.35676801204681396\n",
            "Epoch: 4/9\n",
            "176\n",
            "Loss: 0.45885416865348816\n",
            "Epoch: 4/9\n",
            "177\n",
            "Loss: 0.4555836617946625\n",
            "Epoch: 4/9\n",
            "178\n",
            "Loss: 0.5332856774330139\n",
            "Epoch: 4/9\n",
            "179\n",
            "Loss: 0.49035024642944336\n",
            "Epoch: 4/9\n",
            "180\n",
            "Loss: 0.5137978792190552\n",
            "Epoch: 4/9\n",
            "181\n",
            "Loss: 0.5383380055427551\n",
            "Epoch: 4/9\n",
            "182\n",
            "Loss: 0.4578503668308258\n",
            "Epoch: 4/9\n",
            "183\n",
            "Loss: 0.5079432725906372\n",
            "Epoch: 4/9\n",
            "184\n",
            "Loss: 0.5020634531974792\n",
            "Epoch: 4/9\n",
            "185\n",
            "Loss: 0.4384695589542389\n",
            "Epoch: 4/9\n",
            "186\n",
            "Loss: 0.513373613357544\n",
            "Epoch: 4/9\n",
            "187\n",
            "Loss: 0.505874752998352\n",
            "Epoch: 4/9\n",
            "188\n",
            "Loss: 0.45286285877227783\n",
            "Epoch: 4/9\n",
            "189\n",
            "Loss: 0.3818231523036957\n",
            "Epoch: 4/9\n",
            "190\n",
            "Loss: 0.4262484908103943\n",
            "Epoch: 4/9\n",
            "191\n",
            "Loss: 0.3876481056213379\n",
            "Epoch: 4/9\n",
            "192\n",
            "Loss: 0.35059455037117004\n",
            "Epoch: 4/9\n",
            "193\n",
            "Loss: 0.4025074243545532\n",
            "Epoch: 4/9\n",
            "194\n",
            "Loss: 0.3038296699523926\n",
            "Epoch: 4/9\n",
            "195\n",
            "Loss: 0.21215298771858215\n",
            "Epoch: 4/9\n",
            "Epoch: 5\n",
            "0\n",
            "Loss: 0.5071155428886414\n",
            "Epoch: 5/9\n",
            "1\n",
            "Loss: 0.4996950626373291\n",
            "Epoch: 5/9\n",
            "2\n",
            "Loss: 0.4015657305717468\n",
            "Epoch: 5/9\n",
            "3\n",
            "Loss: 0.4949338436126709\n",
            "Epoch: 5/9\n",
            "4\n",
            "Loss: 0.6513644456863403\n",
            "Epoch: 5/9\n",
            "5\n",
            "Loss: 0.5354368686676025\n",
            "Epoch: 5/9\n",
            "6\n",
            "Loss: 0.4824427366256714\n",
            "Epoch: 5/9\n",
            "7\n",
            "Loss: 0.6327158212661743\n",
            "Epoch: 5/9\n",
            "8\n",
            "Loss: 0.6005001068115234\n",
            "Epoch: 5/9\n",
            "9\n",
            "Loss: 0.529408872127533\n",
            "Epoch: 5/9\n",
            "10\n",
            "Loss: 0.5399602055549622\n",
            "Epoch: 5/9\n",
            "11\n",
            "Loss: 0.7020103931427002\n",
            "Epoch: 5/9\n",
            "12\n",
            "Loss: 0.6453364491462708\n",
            "Epoch: 5/9\n",
            "13\n",
            "Loss: 0.585559070110321\n",
            "Epoch: 5/9\n",
            "14\n",
            "Loss: 0.6263526082038879\n",
            "Epoch: 5/9\n",
            "15\n",
            "Loss: 0.6604834198951721\n",
            "Epoch: 5/9\n",
            "16\n",
            "Loss: 0.6927940845489502\n",
            "Epoch: 5/9\n",
            "17\n",
            "Loss: 0.7063444256782532\n",
            "Epoch: 5/9\n",
            "18\n",
            "Loss: 0.6177601218223572\n",
            "Epoch: 5/9\n",
            "19\n",
            "Loss: 0.6615774035453796\n",
            "Epoch: 5/9\n",
            "20\n",
            "Loss: 0.6566453576087952\n",
            "Epoch: 5/9\n",
            "21\n",
            "Loss: 0.6649353504180908\n",
            "Epoch: 5/9\n",
            "22\n",
            "Loss: 0.6378761529922485\n",
            "Epoch: 5/9\n",
            "23\n",
            "Loss: 0.5956470370292664\n",
            "Epoch: 5/9\n",
            "24\n",
            "Loss: 0.6634519696235657\n",
            "Epoch: 5/9\n",
            "25\n",
            "Loss: 0.678658127784729\n",
            "Epoch: 5/9\n",
            "26\n",
            "Loss: 0.6987430453300476\n",
            "Epoch: 5/9\n",
            "27\n",
            "Loss: 0.6640214920043945\n",
            "Epoch: 5/9\n",
            "28\n",
            "Loss: 0.5824645757675171\n",
            "Epoch: 5/9\n",
            "29\n",
            "Loss: 0.6804824471473694\n",
            "Epoch: 5/9\n",
            "30\n",
            "Loss: 0.6162989139556885\n",
            "Epoch: 5/9\n",
            "31\n",
            "Loss: 0.6511560082435608\n",
            "Epoch: 5/9\n",
            "32\n",
            "Loss: 0.5553381443023682\n",
            "Epoch: 5/9\n",
            "33\n",
            "Loss: 0.687990665435791\n",
            "Epoch: 5/9\n",
            "34\n",
            "Loss: 0.634330689907074\n",
            "Epoch: 5/9\n",
            "35\n",
            "Loss: 0.6752856969833374\n",
            "Epoch: 5/9\n",
            "36\n",
            "Loss: 0.7550617456436157\n",
            "Epoch: 5/9\n",
            "37\n",
            "Loss: 0.6165581345558167\n",
            "Epoch: 5/9\n",
            "38\n",
            "Loss: 0.6150526404380798\n",
            "Epoch: 5/9\n",
            "39\n",
            "Loss: 0.74198317527771\n",
            "Epoch: 5/9\n",
            "40\n",
            "Loss: 0.7227374911308289\n",
            "Epoch: 5/9\n",
            "41\n",
            "Loss: 0.5928072929382324\n",
            "Epoch: 5/9\n",
            "42\n",
            "Loss: 0.6684619784355164\n",
            "Epoch: 5/9\n",
            "43\n",
            "Loss: 0.7985885143280029\n",
            "Epoch: 5/9\n",
            "44\n",
            "Loss: 0.6215794086456299\n",
            "Epoch: 5/9\n",
            "45\n",
            "Loss: 0.6129550933837891\n",
            "Epoch: 5/9\n",
            "46\n",
            "Loss: 0.6175193786621094\n",
            "Epoch: 5/9\n",
            "47\n",
            "Loss: 0.7241305112838745\n",
            "Epoch: 5/9\n",
            "48\n",
            "Loss: 0.7197680473327637\n",
            "Epoch: 5/9\n",
            "49\n",
            "Loss: 0.6384878754615784\n",
            "Epoch: 5/9\n",
            "50\n",
            "Loss: 0.6755865812301636\n",
            "Epoch: 5/9\n",
            "51\n",
            "Loss: 0.7400881052017212\n",
            "Epoch: 5/9\n",
            "52\n",
            "Loss: 0.6898587346076965\n",
            "Epoch: 5/9\n",
            "53\n",
            "Loss: 0.7444721460342407\n",
            "Epoch: 5/9\n",
            "54\n",
            "Loss: 0.6974334716796875\n",
            "Epoch: 5/9\n",
            "55\n",
            "Loss: 0.6526975631713867\n",
            "Epoch: 5/9\n",
            "56\n",
            "Loss: 0.6857618093490601\n",
            "Epoch: 5/9\n",
            "57\n",
            "Loss: 0.6303163170814514\n",
            "Epoch: 5/9\n",
            "58\n",
            "Loss: 0.6016660332679749\n",
            "Epoch: 5/9\n",
            "59\n",
            "Loss: 0.6398470997810364\n",
            "Epoch: 5/9\n",
            "60\n",
            "Loss: 0.6138660311698914\n",
            "Epoch: 5/9\n",
            "61\n",
            "Loss: 0.5880059599876404\n",
            "Epoch: 5/9\n",
            "62\n",
            "Loss: 0.6447720527648926\n",
            "Epoch: 5/9\n",
            "63\n",
            "Loss: 0.5867301225662231\n",
            "Epoch: 5/9\n",
            "64\n",
            "Loss: 0.593064546585083\n",
            "Epoch: 5/9\n",
            "65\n",
            "Loss: 0.5247320532798767\n",
            "Epoch: 5/9\n",
            "66\n",
            "Loss: 0.5282177329063416\n",
            "Epoch: 5/9\n",
            "67\n",
            "Loss: 0.6268519759178162\n",
            "Epoch: 5/9\n",
            "68\n",
            "Loss: 0.5912212133407593\n",
            "Epoch: 5/9\n",
            "69\n",
            "Loss: 0.654809296131134\n",
            "Epoch: 5/9\n",
            "70\n",
            "Loss: 0.6714474558830261\n",
            "Epoch: 5/9\n",
            "71\n",
            "Loss: 0.6422326564788818\n",
            "Epoch: 5/9\n",
            "72\n",
            "Loss: 0.6943914294242859\n",
            "Epoch: 5/9\n",
            "73\n",
            "Loss: 0.6516282558441162\n",
            "Epoch: 5/9\n",
            "74\n",
            "Loss: 0.6806801557540894\n",
            "Epoch: 5/9\n",
            "75\n",
            "Loss: 0.6038264632225037\n",
            "Epoch: 5/9\n",
            "76\n",
            "Loss: 0.6819333434104919\n",
            "Epoch: 5/9\n",
            "77\n",
            "Loss: 0.6707631349563599\n",
            "Epoch: 5/9\n",
            "78\n",
            "Loss: 0.7182072997093201\n",
            "Epoch: 5/9\n",
            "79\n",
            "Loss: 0.6426699757575989\n",
            "Epoch: 5/9\n",
            "80\n",
            "Loss: 0.6119177341461182\n",
            "Epoch: 5/9\n",
            "81\n",
            "Loss: 0.6733096241950989\n",
            "Epoch: 5/9\n",
            "82\n",
            "Loss: 0.6029768586158752\n",
            "Epoch: 5/9\n",
            "83\n",
            "Loss: 0.7312114238739014\n",
            "Epoch: 5/9\n",
            "84\n",
            "Loss: 0.6426164507865906\n",
            "Epoch: 5/9\n",
            "85\n",
            "Loss: 0.7349376082420349\n",
            "Epoch: 5/9\n",
            "86\n",
            "Loss: 0.700136661529541\n",
            "Epoch: 5/9\n",
            "87\n",
            "Loss: 0.6994616389274597\n",
            "Epoch: 5/9\n",
            "88\n",
            "Loss: 0.5838944911956787\n",
            "Epoch: 5/9\n",
            "89\n",
            "Loss: 0.6812512874603271\n",
            "Epoch: 5/9\n",
            "90\n",
            "Loss: 0.6542606353759766\n",
            "Epoch: 5/9\n",
            "91\n",
            "Loss: 0.644698977470398\n",
            "Epoch: 5/9\n",
            "92\n",
            "Loss: 0.6467131972312927\n",
            "Epoch: 5/9\n",
            "93\n",
            "Loss: 0.5948042869567871\n",
            "Epoch: 5/9\n",
            "94\n",
            "Loss: 0.6223208904266357\n",
            "Epoch: 5/9\n",
            "95\n",
            "Loss: 0.6570268869400024\n",
            "Epoch: 5/9\n",
            "96\n",
            "Loss: 0.660057008266449\n",
            "Epoch: 5/9\n",
            "97\n",
            "Loss: 0.5997433662414551\n",
            "Epoch: 5/9\n",
            "98\n",
            "Loss: 0.6985405087471008\n",
            "Epoch: 5/9\n",
            "99\n",
            "Loss: 0.5955561995506287\n",
            "Epoch: 5/9\n",
            "100\n",
            "Loss: 0.6359459161758423\n",
            "Epoch: 5/9\n",
            "101\n",
            "Loss: 0.5958870053291321\n",
            "Epoch: 5/9\n",
            "102\n",
            "Loss: 0.5501523613929749\n",
            "Epoch: 5/9\n",
            "103\n",
            "Loss: 0.6102675795555115\n",
            "Epoch: 5/9\n",
            "104\n",
            "Loss: 0.6623604893684387\n",
            "Epoch: 5/9\n",
            "105\n",
            "Loss: 0.6318666934967041\n",
            "Epoch: 5/9\n",
            "106\n",
            "Loss: 0.654050886631012\n",
            "Epoch: 5/9\n",
            "107\n",
            "Loss: 0.5947866439819336\n",
            "Epoch: 5/9\n",
            "108\n",
            "Loss: 0.5736913681030273\n",
            "Epoch: 5/9\n",
            "109\n",
            "Loss: 0.5879905819892883\n",
            "Epoch: 5/9\n",
            "110\n",
            "Loss: 0.5972636342048645\n",
            "Epoch: 5/9\n",
            "111\n",
            "Loss: 0.6367642283439636\n",
            "Epoch: 5/9\n",
            "112\n",
            "Loss: 0.5335191488265991\n",
            "Epoch: 5/9\n",
            "113\n",
            "Loss: 0.5545117855072021\n",
            "Epoch: 5/9\n",
            "114\n",
            "Loss: 0.5666990876197815\n",
            "Epoch: 5/9\n",
            "115\n",
            "Loss: 0.598090648651123\n",
            "Epoch: 5/9\n",
            "116\n",
            "Loss: 0.5827805995941162\n",
            "Epoch: 5/9\n",
            "117\n",
            "Loss: 0.580372154712677\n",
            "Epoch: 5/9\n",
            "118\n",
            "Loss: 0.5419053435325623\n",
            "Epoch: 5/9\n",
            "119\n",
            "Loss: 0.5711151361465454\n",
            "Epoch: 5/9\n",
            "120\n",
            "Loss: 0.7028740048408508\n",
            "Epoch: 5/9\n",
            "121\n",
            "Loss: 0.5807119011878967\n",
            "Epoch: 5/9\n",
            "122\n",
            "Loss: 0.5486604571342468\n",
            "Epoch: 5/9\n",
            "123\n",
            "Loss: 0.5956448912620544\n",
            "Epoch: 5/9\n",
            "124\n",
            "Loss: 0.6454460620880127\n",
            "Epoch: 5/9\n",
            "125\n",
            "Loss: 0.7148674726486206\n",
            "Epoch: 5/9\n",
            "126\n",
            "Loss: 0.6334303617477417\n",
            "Epoch: 5/9\n",
            "127\n",
            "Loss: 0.670415461063385\n",
            "Epoch: 5/9\n",
            "128\n",
            "Loss: 0.6040278077125549\n",
            "Epoch: 5/9\n",
            "129\n",
            "Loss: 0.6101365685462952\n",
            "Epoch: 5/9\n",
            "130\n",
            "Loss: 0.6609221696853638\n",
            "Epoch: 5/9\n",
            "131\n",
            "Loss: 0.7842768430709839\n",
            "Epoch: 5/9\n",
            "132\n",
            "Loss: 0.740671694278717\n",
            "Epoch: 5/9\n",
            "133\n",
            "Loss: 0.5310662984848022\n",
            "Epoch: 5/9\n",
            "134\n",
            "Loss: 0.7322040796279907\n",
            "Epoch: 5/9\n",
            "135\n",
            "Loss: 0.589056134223938\n",
            "Epoch: 5/9\n",
            "136\n",
            "Loss: 0.6751189231872559\n",
            "Epoch: 5/9\n",
            "137\n",
            "Loss: 0.6726662516593933\n",
            "Epoch: 5/9\n",
            "138\n",
            "Loss: 0.599894642829895\n",
            "Epoch: 5/9\n",
            "139\n",
            "Loss: 0.6840127110481262\n",
            "Epoch: 5/9\n",
            "140\n",
            "Loss: 0.611138105392456\n",
            "Epoch: 5/9\n",
            "141\n",
            "Loss: 0.6744242310523987\n",
            "Epoch: 5/9\n",
            "142\n",
            "Loss: 0.5492079257965088\n",
            "Epoch: 5/9\n",
            "143\n",
            "Loss: 0.6157231330871582\n",
            "Epoch: 5/9\n",
            "144\n",
            "Loss: 0.5614237785339355\n",
            "Epoch: 5/9\n",
            "145\n",
            "Loss: 0.6398986577987671\n",
            "Epoch: 5/9\n",
            "146\n",
            "Loss: 0.60560142993927\n",
            "Epoch: 5/9\n",
            "147\n",
            "Loss: 0.5765008926391602\n",
            "Epoch: 5/9\n",
            "148\n",
            "Loss: 0.6117687821388245\n",
            "Epoch: 5/9\n",
            "149\n",
            "Loss: 0.5905662775039673\n",
            "Epoch: 5/9\n",
            "150\n",
            "Loss: 0.5408110618591309\n",
            "Epoch: 5/9\n",
            "151\n",
            "Loss: 0.4448337256908417\n",
            "Epoch: 5/9\n",
            "152\n",
            "Loss: 0.5162480473518372\n",
            "Epoch: 5/9\n",
            "153\n",
            "Loss: 0.5668774843215942\n",
            "Epoch: 5/9\n",
            "154\n",
            "Loss: 0.5009812712669373\n",
            "Epoch: 5/9\n",
            "155\n",
            "Loss: 0.5346746444702148\n",
            "Epoch: 5/9\n",
            "156\n",
            "Loss: 0.43854302167892456\n",
            "Epoch: 5/9\n",
            "157\n",
            "Loss: 0.6225163340568542\n",
            "Epoch: 5/9\n",
            "158\n",
            "Loss: 0.5678948163986206\n",
            "Epoch: 5/9\n",
            "159\n",
            "Loss: 0.5789449214935303\n",
            "Epoch: 5/9\n",
            "160\n",
            "Loss: 0.5229954123497009\n",
            "Epoch: 5/9\n",
            "161\n",
            "Loss: 0.47642290592193604\n",
            "Epoch: 5/9\n",
            "162\n",
            "Loss: 0.5801399946212769\n",
            "Epoch: 5/9\n",
            "163\n",
            "Loss: 0.4854481816291809\n",
            "Epoch: 5/9\n",
            "164\n",
            "Loss: 0.5706237554550171\n",
            "Epoch: 5/9\n",
            "165\n",
            "Loss: 0.4556467831134796\n",
            "Epoch: 5/9\n",
            "166\n",
            "Loss: 0.3709864020347595\n",
            "Epoch: 5/9\n",
            "167\n",
            "Loss: 0.44234922528266907\n",
            "Epoch: 5/9\n",
            "168\n",
            "Loss: 0.40382927656173706\n",
            "Epoch: 5/9\n",
            "169\n",
            "Loss: 0.4690823256969452\n",
            "Epoch: 5/9\n",
            "170\n",
            "Loss: 0.4480028748512268\n",
            "Epoch: 5/9\n",
            "171\n",
            "Loss: 0.3862631916999817\n",
            "Epoch: 5/9\n",
            "172\n",
            "Loss: 0.4643027186393738\n",
            "Epoch: 5/9\n",
            "173\n",
            "Loss: 0.42331865429878235\n",
            "Epoch: 5/9\n",
            "174\n",
            "Loss: 0.4431140422821045\n",
            "Epoch: 5/9\n",
            "175\n",
            "Loss: 0.3522578775882721\n",
            "Epoch: 5/9\n",
            "176\n",
            "Loss: 0.4539138376712799\n",
            "Epoch: 5/9\n",
            "177\n",
            "Loss: 0.45065516233444214\n",
            "Epoch: 5/9\n",
            "178\n",
            "Loss: 0.530728280544281\n",
            "Epoch: 5/9\n",
            "179\n",
            "Loss: 0.4858103096485138\n",
            "Epoch: 5/9\n",
            "180\n",
            "Loss: 0.5092317461967468\n",
            "Epoch: 5/9\n",
            "181\n",
            "Loss: 0.5346935391426086\n",
            "Epoch: 5/9\n",
            "182\n",
            "Loss: 0.4556677043437958\n",
            "Epoch: 5/9\n",
            "183\n",
            "Loss: 0.5046148896217346\n",
            "Epoch: 5/9\n",
            "184\n",
            "Loss: 0.4993968904018402\n",
            "Epoch: 5/9\n",
            "185\n",
            "Loss: 0.43414896726608276\n",
            "Epoch: 5/9\n",
            "186\n",
            "Loss: 0.5088652968406677\n",
            "Epoch: 5/9\n",
            "187\n",
            "Loss: 0.5010741949081421\n",
            "Epoch: 5/9\n",
            "188\n",
            "Loss: 0.44872525334358215\n",
            "Epoch: 5/9\n",
            "189\n",
            "Loss: 0.37751567363739014\n",
            "Epoch: 5/9\n",
            "190\n",
            "Loss: 0.4231705069541931\n",
            "Epoch: 5/9\n",
            "191\n",
            "Loss: 0.3827378749847412\n",
            "Epoch: 5/9\n",
            "192\n",
            "Loss: 0.34642907977104187\n",
            "Epoch: 5/9\n",
            "193\n",
            "Loss: 0.3978897035121918\n",
            "Epoch: 5/9\n",
            "194\n",
            "Loss: 0.3012068271636963\n",
            "Epoch: 5/9\n",
            "195\n",
            "Loss: 0.20827455818653107\n",
            "Epoch: 5/9\n",
            "Epoch: 6\n",
            "0\n",
            "Loss: 0.5021920800209045\n",
            "Epoch: 6/9\n",
            "1\n",
            "Loss: 0.4978683590888977\n",
            "Epoch: 6/9\n",
            "2\n",
            "Loss: 0.3966624140739441\n",
            "Epoch: 6/9\n",
            "3\n",
            "Loss: 0.4904676377773285\n",
            "Epoch: 6/9\n",
            "4\n",
            "Loss: 0.6478936672210693\n",
            "Epoch: 6/9\n",
            "5\n",
            "Loss: 0.5291616320610046\n",
            "Epoch: 6/9\n",
            "6\n",
            "Loss: 0.47822070121765137\n",
            "Epoch: 6/9\n",
            "7\n",
            "Loss: 0.6295506954193115\n",
            "Epoch: 6/9\n",
            "8\n",
            "Loss: 0.5961288809776306\n",
            "Epoch: 6/9\n",
            "9\n",
            "Loss: 0.5260442495346069\n",
            "Epoch: 6/9\n",
            "10\n",
            "Loss: 0.5356234908103943\n",
            "Epoch: 6/9\n",
            "11\n",
            "Loss: 0.6987109184265137\n",
            "Epoch: 6/9\n",
            "12\n",
            "Loss: 0.6409479379653931\n",
            "Epoch: 6/9\n",
            "13\n",
            "Loss: 0.5856285095214844\n",
            "Epoch: 6/9\n",
            "14\n",
            "Loss: 0.6215506792068481\n",
            "Epoch: 6/9\n",
            "15\n",
            "Loss: 0.6586556434631348\n",
            "Epoch: 6/9\n",
            "16\n",
            "Loss: 0.6883769035339355\n",
            "Epoch: 6/9\n",
            "17\n",
            "Loss: 0.702664852142334\n",
            "Epoch: 6/9\n",
            "18\n",
            "Loss: 0.6160925626754761\n",
            "Epoch: 6/9\n",
            "19\n",
            "Loss: 0.6601865291595459\n",
            "Epoch: 6/9\n",
            "20\n",
            "Loss: 0.6518732309341431\n",
            "Epoch: 6/9\n",
            "21\n",
            "Loss: 0.6582654118537903\n",
            "Epoch: 6/9\n",
            "22\n",
            "Loss: 0.6348973512649536\n",
            "Epoch: 6/9\n",
            "23\n",
            "Loss: 0.5926715135574341\n",
            "Epoch: 6/9\n",
            "24\n",
            "Loss: 0.6599766612052917\n",
            "Epoch: 6/9\n",
            "25\n",
            "Loss: 0.6734508275985718\n",
            "Epoch: 6/9\n",
            "26\n",
            "Loss: 0.6967945694923401\n",
            "Epoch: 6/9\n",
            "27\n",
            "Loss: 0.6588713526725769\n",
            "Epoch: 6/9\n",
            "28\n",
            "Loss: 0.5785609483718872\n",
            "Epoch: 6/9\n",
            "29\n",
            "Loss: 0.6759204268455505\n",
            "Epoch: 6/9\n",
            "30\n",
            "Loss: 0.6123490333557129\n",
            "Epoch: 6/9\n",
            "31\n",
            "Loss: 0.6466458439826965\n",
            "Epoch: 6/9\n",
            "32\n",
            "Loss: 0.5527440309524536\n",
            "Epoch: 6/9\n",
            "33\n",
            "Loss: 0.6838271617889404\n",
            "Epoch: 6/9\n",
            "34\n",
            "Loss: 0.6284715533256531\n",
            "Epoch: 6/9\n",
            "35\n",
            "Loss: 0.6718839406967163\n",
            "Epoch: 6/9\n",
            "36\n",
            "Loss: 0.7519056797027588\n",
            "Epoch: 6/9\n",
            "37\n",
            "Loss: 0.6131578683853149\n",
            "Epoch: 6/9\n",
            "38\n",
            "Loss: 0.6102038621902466\n",
            "Epoch: 6/9\n",
            "39\n",
            "Loss: 0.7405592799186707\n",
            "Epoch: 6/9\n",
            "40\n",
            "Loss: 0.7209780812263489\n",
            "Epoch: 6/9\n",
            "41\n",
            "Loss: 0.5899285078048706\n",
            "Epoch: 6/9\n",
            "42\n",
            "Loss: 0.6651536226272583\n",
            "Epoch: 6/9\n",
            "43\n",
            "Loss: 0.7932973504066467\n",
            "Epoch: 6/9\n",
            "44\n",
            "Loss: 0.6167306900024414\n",
            "Epoch: 6/9\n",
            "45\n",
            "Loss: 0.611014723777771\n",
            "Epoch: 6/9\n",
            "46\n",
            "Loss: 0.6127328276634216\n",
            "Epoch: 6/9\n",
            "47\n",
            "Loss: 0.7233032584190369\n",
            "Epoch: 6/9\n",
            "48\n",
            "Loss: 0.7168624401092529\n",
            "Epoch: 6/9\n",
            "49\n",
            "Loss: 0.6356995701789856\n",
            "Epoch: 6/9\n",
            "50\n",
            "Loss: 0.6726155281066895\n",
            "Epoch: 6/9\n",
            "51\n",
            "Loss: 0.7366389036178589\n",
            "Epoch: 6/9\n",
            "52\n",
            "Loss: 0.6856943964958191\n",
            "Epoch: 6/9\n",
            "53\n",
            "Loss: 0.7405188083648682\n",
            "Epoch: 6/9\n",
            "54\n",
            "Loss: 0.6934943199157715\n",
            "Epoch: 6/9\n",
            "55\n",
            "Loss: 0.6477636098861694\n",
            "Epoch: 6/9\n",
            "56\n",
            "Loss: 0.6798357367515564\n",
            "Epoch: 6/9\n",
            "57\n",
            "Loss: 0.6261873841285706\n",
            "Epoch: 6/9\n",
            "58\n",
            "Loss: 0.5977891087532043\n",
            "Epoch: 6/9\n",
            "59\n",
            "Loss: 0.6371616125106812\n",
            "Epoch: 6/9\n",
            "60\n",
            "Loss: 0.6090553402900696\n",
            "Epoch: 6/9\n",
            "61\n",
            "Loss: 0.5856890678405762\n",
            "Epoch: 6/9\n",
            "62\n",
            "Loss: 0.6423208117485046\n",
            "Epoch: 6/9\n",
            "63\n",
            "Loss: 0.5830946564674377\n",
            "Epoch: 6/9\n",
            "64\n",
            "Loss: 0.5925848484039307\n",
            "Epoch: 6/9\n",
            "65\n",
            "Loss: 0.5222775340080261\n",
            "Epoch: 6/9\n",
            "66\n",
            "Loss: 0.5235703587532043\n",
            "Epoch: 6/9\n",
            "67\n",
            "Loss: 0.6229174733161926\n",
            "Epoch: 6/9\n",
            "68\n",
            "Loss: 0.5865583419799805\n",
            "Epoch: 6/9\n",
            "69\n",
            "Loss: 0.6523414254188538\n",
            "Epoch: 6/9\n",
            "70\n",
            "Loss: 0.6696476936340332\n",
            "Epoch: 6/9\n",
            "71\n",
            "Loss: 0.6382696628570557\n",
            "Epoch: 6/9\n",
            "72\n",
            "Loss: 0.6916877627372742\n",
            "Epoch: 6/9\n",
            "73\n",
            "Loss: 0.6459526419639587\n",
            "Epoch: 6/9\n",
            "74\n",
            "Loss: 0.679793119430542\n",
            "Epoch: 6/9\n",
            "75\n",
            "Loss: 0.5994079113006592\n",
            "Epoch: 6/9\n",
            "76\n",
            "Loss: 0.6769847273826599\n",
            "Epoch: 6/9\n",
            "77\n",
            "Loss: 0.667064368724823\n",
            "Epoch: 6/9\n",
            "78\n",
            "Loss: 0.7141493558883667\n",
            "Epoch: 6/9\n",
            "79\n",
            "Loss: 0.63907390832901\n",
            "Epoch: 6/9\n",
            "80\n",
            "Loss: 0.6063816547393799\n",
            "Epoch: 6/9\n",
            "81\n",
            "Loss: 0.670848548412323\n",
            "Epoch: 6/9\n",
            "82\n",
            "Loss: 0.5978347659111023\n",
            "Epoch: 6/9\n",
            "83\n",
            "Loss: 0.7295839190483093\n",
            "Epoch: 6/9\n",
            "84\n",
            "Loss: 0.6407772898674011\n",
            "Epoch: 6/9\n",
            "85\n",
            "Loss: 0.7319873571395874\n",
            "Epoch: 6/9\n",
            "86\n",
            "Loss: 0.6963228583335876\n",
            "Epoch: 6/9\n",
            "87\n",
            "Loss: 0.6981096863746643\n",
            "Epoch: 6/9\n",
            "88\n",
            "Loss: 0.5817668437957764\n",
            "Epoch: 6/9\n",
            "89\n",
            "Loss: 0.6770497560501099\n",
            "Epoch: 6/9\n",
            "90\n",
            "Loss: 0.6484764218330383\n",
            "Epoch: 6/9\n",
            "91\n",
            "Loss: 0.639564573764801\n",
            "Epoch: 6/9\n",
            "92\n",
            "Loss: 0.642594575881958\n",
            "Epoch: 6/9\n",
            "93\n",
            "Loss: 0.590661883354187\n",
            "Epoch: 6/9\n",
            "94\n",
            "Loss: 0.619818925857544\n",
            "Epoch: 6/9\n",
            "95\n",
            "Loss: 0.6546536087989807\n",
            "Epoch: 6/9\n",
            "96\n",
            "Loss: 0.6544498801231384\n",
            "Epoch: 6/9\n",
            "97\n",
            "Loss: 0.5947306156158447\n",
            "Epoch: 6/9\n",
            "98\n",
            "Loss: 0.6965723633766174\n",
            "Epoch: 6/9\n",
            "99\n",
            "Loss: 0.5926779508590698\n",
            "Epoch: 6/9\n",
            "100\n",
            "Loss: 0.6323198676109314\n",
            "Epoch: 6/9\n",
            "101\n",
            "Loss: 0.5920121073722839\n",
            "Epoch: 6/9\n",
            "102\n",
            "Loss: 0.5483474135398865\n",
            "Epoch: 6/9\n",
            "103\n",
            "Loss: 0.6084809899330139\n",
            "Epoch: 6/9\n",
            "104\n",
            "Loss: 0.6584815382957458\n",
            "Epoch: 6/9\n",
            "105\n",
            "Loss: 0.6298983097076416\n",
            "Epoch: 6/9\n",
            "106\n",
            "Loss: 0.6485596299171448\n",
            "Epoch: 6/9\n",
            "107\n",
            "Loss: 0.5904608964920044\n",
            "Epoch: 6/9\n",
            "108\n",
            "Loss: 0.5710622072219849\n",
            "Epoch: 6/9\n",
            "109\n",
            "Loss: 0.5857771635055542\n",
            "Epoch: 6/9\n",
            "110\n",
            "Loss: 0.5927374958992004\n",
            "Epoch: 6/9\n",
            "111\n",
            "Loss: 0.6320089101791382\n",
            "Epoch: 6/9\n",
            "112\n",
            "Loss: 0.529184103012085\n",
            "Epoch: 6/9\n",
            "113\n",
            "Loss: 0.5512951612472534\n",
            "Epoch: 6/9\n",
            "114\n",
            "Loss: 0.5626308917999268\n",
            "Epoch: 6/9\n",
            "115\n",
            "Loss: 0.5947901010513306\n",
            "Epoch: 6/9\n",
            "116\n",
            "Loss: 0.58016437292099\n",
            "Epoch: 6/9\n",
            "117\n",
            "Loss: 0.5762856602668762\n",
            "Epoch: 6/9\n",
            "118\n",
            "Loss: 0.538612425327301\n",
            "Epoch: 6/9\n",
            "119\n",
            "Loss: 0.5677711963653564\n",
            "Epoch: 6/9\n",
            "120\n",
            "Loss: 0.6997638940811157\n",
            "Epoch: 6/9\n",
            "121\n",
            "Loss: 0.5777074694633484\n",
            "Epoch: 6/9\n",
            "122\n",
            "Loss: 0.5463845133781433\n",
            "Epoch: 6/9\n",
            "123\n",
            "Loss: 0.5912285447120667\n",
            "Epoch: 6/9\n",
            "124\n",
            "Loss: 0.641316831111908\n",
            "Epoch: 6/9\n",
            "125\n",
            "Loss: 0.7111021280288696\n",
            "Epoch: 6/9\n",
            "126\n",
            "Loss: 0.6296781897544861\n",
            "Epoch: 6/9\n",
            "127\n",
            "Loss: 0.666720449924469\n",
            "Epoch: 6/9\n",
            "128\n",
            "Loss: 0.5986247658729553\n",
            "Epoch: 6/9\n",
            "129\n",
            "Loss: 0.6080182790756226\n",
            "Epoch: 6/9\n",
            "130\n",
            "Loss: 0.6567760705947876\n",
            "Epoch: 6/9\n",
            "131\n",
            "Loss: 0.7788869142532349\n",
            "Epoch: 6/9\n",
            "132\n",
            "Loss: 0.7377992868423462\n",
            "Epoch: 6/9\n",
            "133\n",
            "Loss: 0.5272985696792603\n",
            "Epoch: 6/9\n",
            "134\n",
            "Loss: 0.7257769107818604\n",
            "Epoch: 6/9\n",
            "135\n",
            "Loss: 0.5860437154769897\n",
            "Epoch: 6/9\n",
            "136\n",
            "Loss: 0.6694333553314209\n",
            "Epoch: 6/9\n",
            "137\n",
            "Loss: 0.6686944961547852\n",
            "Epoch: 6/9\n",
            "138\n",
            "Loss: 0.5964372158050537\n",
            "Epoch: 6/9\n",
            "139\n",
            "Loss: 0.6791602373123169\n",
            "Epoch: 6/9\n",
            "140\n",
            "Loss: 0.6079875826835632\n",
            "Epoch: 6/9\n",
            "141\n",
            "Loss: 0.6681541204452515\n",
            "Epoch: 6/9\n",
            "142\n",
            "Loss: 0.544488787651062\n",
            "Epoch: 6/9\n",
            "143\n",
            "Loss: 0.6134469509124756\n",
            "Epoch: 6/9\n",
            "144\n",
            "Loss: 0.5609031915664673\n",
            "Epoch: 6/9\n",
            "145\n",
            "Loss: 0.6360955238342285\n",
            "Epoch: 6/9\n",
            "146\n",
            "Loss: 0.6028060913085938\n",
            "Epoch: 6/9\n",
            "147\n",
            "Loss: 0.5741151571273804\n",
            "Epoch: 6/9\n",
            "148\n",
            "Loss: 0.6066851019859314\n",
            "Epoch: 6/9\n",
            "149\n",
            "Loss: 0.5883899927139282\n",
            "Epoch: 6/9\n",
            "150\n",
            "Loss: 0.5381180047988892\n",
            "Epoch: 6/9\n",
            "151\n",
            "Loss: 0.4414786696434021\n",
            "Epoch: 6/9\n",
            "152\n",
            "Loss: 0.5116898417472839\n",
            "Epoch: 6/9\n",
            "153\n",
            "Loss: 0.564094603061676\n",
            "Epoch: 6/9\n",
            "154\n",
            "Loss: 0.4990236461162567\n",
            "Epoch: 6/9\n",
            "155\n",
            "Loss: 0.528458833694458\n",
            "Epoch: 6/9\n",
            "156\n",
            "Loss: 0.4362572431564331\n",
            "Epoch: 6/9\n",
            "157\n",
            "Loss: 0.6185729503631592\n",
            "Epoch: 6/9\n",
            "158\n",
            "Loss: 0.5651183128356934\n",
            "Epoch: 6/9\n",
            "159\n",
            "Loss: 0.5753018260002136\n",
            "Epoch: 6/9\n",
            "160\n",
            "Loss: 0.519238293170929\n",
            "Epoch: 6/9\n",
            "161\n",
            "Loss: 0.4727138876914978\n",
            "Epoch: 6/9\n",
            "162\n",
            "Loss: 0.5752741694450378\n",
            "Epoch: 6/9\n",
            "163\n",
            "Loss: 0.481410413980484\n",
            "Epoch: 6/9\n",
            "164\n",
            "Loss: 0.565833568572998\n",
            "Epoch: 6/9\n",
            "165\n",
            "Loss: 0.4519531726837158\n",
            "Epoch: 6/9\n",
            "166\n",
            "Loss: 0.3665136396884918\n",
            "Epoch: 6/9\n",
            "167\n",
            "Loss: 0.4382243752479553\n",
            "Epoch: 6/9\n",
            "168\n",
            "Loss: 0.4014256000518799\n",
            "Epoch: 6/9\n",
            "169\n",
            "Loss: 0.46654069423675537\n",
            "Epoch: 6/9\n",
            "170\n",
            "Loss: 0.4455111026763916\n",
            "Epoch: 6/9\n",
            "171\n",
            "Loss: 0.3829226791858673\n",
            "Epoch: 6/9\n",
            "172\n",
            "Loss: 0.4619337022304535\n",
            "Epoch: 6/9\n",
            "173\n",
            "Loss: 0.41907793283462524\n",
            "Epoch: 6/9\n",
            "174\n",
            "Loss: 0.43815797567367554\n",
            "Epoch: 6/9\n",
            "175\n",
            "Loss: 0.3478977680206299\n",
            "Epoch: 6/9\n",
            "176\n",
            "Loss: 0.4508139491081238\n",
            "Epoch: 6/9\n",
            "177\n",
            "Loss: 0.4468673765659332\n",
            "Epoch: 6/9\n",
            "178\n",
            "Loss: 0.5284404158592224\n",
            "Epoch: 6/9\n",
            "179\n",
            "Loss: 0.4817366600036621\n",
            "Epoch: 6/9\n",
            "180\n",
            "Loss: 0.5053055882453918\n",
            "Epoch: 6/9\n",
            "181\n",
            "Loss: 0.5312330722808838\n",
            "Epoch: 6/9\n",
            "182\n",
            "Loss: 0.4531753361225128\n",
            "Epoch: 6/9\n",
            "183\n",
            "Loss: 0.5011758208274841\n",
            "Epoch: 6/9\n",
            "184\n",
            "Loss: 0.49715325236320496\n",
            "Epoch: 6/9\n",
            "185\n",
            "Loss: 0.43043944239616394\n",
            "Epoch: 6/9\n",
            "186\n",
            "Loss: 0.5050079822540283\n",
            "Epoch: 6/9\n",
            "187\n",
            "Loss: 0.4973686635494232\n",
            "Epoch: 6/9\n",
            "188\n",
            "Loss: 0.44536107778549194\n",
            "Epoch: 6/9\n",
            "189\n",
            "Loss: 0.3737918734550476\n",
            "Epoch: 6/9\n",
            "190\n",
            "Loss: 0.42029643058776855\n",
            "Epoch: 6/9\n",
            "191\n",
            "Loss: 0.3791997730731964\n",
            "Epoch: 6/9\n",
            "192\n",
            "Loss: 0.3430367708206177\n",
            "Epoch: 6/9\n",
            "193\n",
            "Loss: 0.3944413959980011\n",
            "Epoch: 6/9\n",
            "194\n",
            "Loss: 0.2985800504684448\n",
            "Epoch: 6/9\n",
            "195\n",
            "Loss: 0.20493340492248535\n",
            "Epoch: 6/9\n",
            "Epoch: 7\n",
            "0\n",
            "Loss: 0.4971911311149597\n",
            "Epoch: 7/9\n",
            "1\n",
            "Loss: 0.49495449662208557\n",
            "Epoch: 7/9\n",
            "2\n",
            "Loss: 0.39336249232292175\n",
            "Epoch: 7/9\n",
            "3\n",
            "Loss: 0.48692604899406433\n",
            "Epoch: 7/9\n",
            "4\n",
            "Loss: 0.6449785232543945\n",
            "Epoch: 7/9\n",
            "5\n",
            "Loss: 0.525468647480011\n",
            "Epoch: 7/9\n",
            "6\n",
            "Loss: 0.47520872950553894\n",
            "Epoch: 7/9\n",
            "7\n",
            "Loss: 0.6260338425636292\n",
            "Epoch: 7/9\n",
            "8\n",
            "Loss: 0.590649425983429\n",
            "Epoch: 7/9\n",
            "9\n",
            "Loss: 0.522598922252655\n",
            "Epoch: 7/9\n",
            "10\n",
            "Loss: 0.5327959060668945\n",
            "Epoch: 7/9\n",
            "11\n",
            "Loss: 0.6943968534469604\n",
            "Epoch: 7/9\n",
            "12\n",
            "Loss: 0.6368682980537415\n",
            "Epoch: 7/9\n",
            "13\n",
            "Loss: 0.5846514701843262\n",
            "Epoch: 7/9\n",
            "14\n",
            "Loss: 0.61781907081604\n",
            "Epoch: 7/9\n",
            "15\n",
            "Loss: 0.6566877365112305\n",
            "Epoch: 7/9\n",
            "16\n",
            "Loss: 0.6832451224327087\n",
            "Epoch: 7/9\n",
            "17\n",
            "Loss: 0.7003723978996277\n",
            "Epoch: 7/9\n",
            "18\n",
            "Loss: 0.6151570081710815\n",
            "Epoch: 7/9\n",
            "19\n",
            "Loss: 0.6593496203422546\n",
            "Epoch: 7/9\n",
            "20\n",
            "Loss: 0.6475722193717957\n",
            "Epoch: 7/9\n",
            "21\n",
            "Loss: 0.6534932255744934\n",
            "Epoch: 7/9\n",
            "22\n",
            "Loss: 0.6306931376457214\n",
            "Epoch: 7/9\n",
            "23\n",
            "Loss: 0.5886914730072021\n",
            "Epoch: 7/9\n",
            "24\n",
            "Loss: 0.657024621963501\n",
            "Epoch: 7/9\n",
            "25\n",
            "Loss: 0.669378399848938\n",
            "Epoch: 7/9\n",
            "26\n",
            "Loss: 0.6940315365791321\n",
            "Epoch: 7/9\n",
            "27\n",
            "Loss: 0.654291570186615\n",
            "Epoch: 7/9\n",
            "28\n",
            "Loss: 0.5747195482254028\n",
            "Epoch: 7/9\n",
            "29\n",
            "Loss: 0.6717599034309387\n",
            "Epoch: 7/9\n",
            "30\n",
            "Loss: 0.6092149019241333\n",
            "Epoch: 7/9\n",
            "31\n",
            "Loss: 0.6427931189537048\n",
            "Epoch: 7/9\n",
            "32\n",
            "Loss: 0.5502094626426697\n",
            "Epoch: 7/9\n",
            "33\n",
            "Loss: 0.6806149482727051\n",
            "Epoch: 7/9\n",
            "34\n",
            "Loss: 0.623879075050354\n",
            "Epoch: 7/9\n",
            "35\n",
            "Loss: 0.6683839559555054\n",
            "Epoch: 7/9\n",
            "36\n",
            "Loss: 0.7493639588356018\n",
            "Epoch: 7/9\n",
            "37\n",
            "Loss: 0.6097097396850586\n",
            "Epoch: 7/9\n",
            "38\n",
            "Loss: 0.6050680875778198\n",
            "Epoch: 7/9\n",
            "39\n",
            "Loss: 0.7388210892677307\n",
            "Epoch: 7/9\n",
            "40\n",
            "Loss: 0.7193082571029663\n",
            "Epoch: 7/9\n",
            "41\n",
            "Loss: 0.587319016456604\n",
            "Epoch: 7/9\n",
            "42\n",
            "Loss: 0.6602749824523926\n",
            "Epoch: 7/9\n",
            "43\n",
            "Loss: 0.7893242239952087\n",
            "Epoch: 7/9\n",
            "44\n",
            "Loss: 0.6127508878707886\n",
            "Epoch: 7/9\n",
            "45\n",
            "Loss: 0.6085380911827087\n",
            "Epoch: 7/9\n",
            "46\n",
            "Loss: 0.607958972454071\n",
            "Epoch: 7/9\n",
            "47\n",
            "Loss: 0.7223544120788574\n",
            "Epoch: 7/9\n",
            "48\n",
            "Loss: 0.7141513824462891\n",
            "Epoch: 7/9\n",
            "49\n",
            "Loss: 0.6335166692733765\n",
            "Epoch: 7/9\n",
            "50\n",
            "Loss: 0.668796956539154\n",
            "Epoch: 7/9\n",
            "51\n",
            "Loss: 0.7339661121368408\n",
            "Epoch: 7/9\n",
            "52\n",
            "Loss: 0.6816219091415405\n",
            "Epoch: 7/9\n",
            "53\n",
            "Loss: 0.7362386584281921\n",
            "Epoch: 7/9\n",
            "54\n",
            "Loss: 0.6900705099105835\n",
            "Epoch: 7/9\n",
            "55\n",
            "Loss: 0.6440895199775696\n",
            "Epoch: 7/9\n",
            "56\n",
            "Loss: 0.6744154095649719\n",
            "Epoch: 7/9\n",
            "57\n",
            "Loss: 0.6230245232582092\n",
            "Epoch: 7/9\n",
            "58\n",
            "Loss: 0.5943407416343689\n",
            "Epoch: 7/9\n",
            "59\n",
            "Loss: 0.6353247761726379\n",
            "Epoch: 7/9\n",
            "60\n",
            "Loss: 0.6039291024208069\n",
            "Epoch: 7/9\n",
            "61\n",
            "Loss: 0.5836197733879089\n",
            "Epoch: 7/9\n",
            "62\n",
            "Loss: 0.6381075978279114\n",
            "Epoch: 7/9\n",
            "63\n",
            "Loss: 0.580352246761322\n",
            "Epoch: 7/9\n",
            "64\n",
            "Loss: 0.592006266117096\n",
            "Epoch: 7/9\n",
            "65\n",
            "Loss: 0.5201452374458313\n",
            "Epoch: 7/9\n",
            "66\n",
            "Loss: 0.5200026631355286\n",
            "Epoch: 7/9\n",
            "67\n",
            "Loss: 0.6184846758842468\n",
            "Epoch: 7/9\n",
            "68\n",
            "Loss: 0.5828620791435242\n",
            "Epoch: 7/9\n",
            "69\n",
            "Loss: 0.6489885449409485\n",
            "Epoch: 7/9\n",
            "70\n",
            "Loss: 0.6680746078491211\n",
            "Epoch: 7/9\n",
            "71\n",
            "Loss: 0.6348938941955566\n",
            "Epoch: 7/9\n",
            "72\n",
            "Loss: 0.6888032555580139\n",
            "Epoch: 7/9\n",
            "73\n",
            "Loss: 0.641765832901001\n",
            "Epoch: 7/9\n",
            "74\n",
            "Loss: 0.678615391254425\n",
            "Epoch: 7/9\n",
            "75\n",
            "Loss: 0.5954530835151672\n",
            "Epoch: 7/9\n",
            "76\n",
            "Loss: 0.673178493976593\n",
            "Epoch: 7/9\n",
            "77\n",
            "Loss: 0.6648858785629272\n",
            "Epoch: 7/9\n",
            "78\n",
            "Loss: 0.7098990082740784\n",
            "Epoch: 7/9\n",
            "79\n",
            "Loss: 0.6364169120788574\n",
            "Epoch: 7/9\n",
            "80\n",
            "Loss: 0.6008701920509338\n",
            "Epoch: 7/9\n",
            "81\n",
            "Loss: 0.6671598553657532\n",
            "Epoch: 7/9\n",
            "82\n",
            "Loss: 0.5932533144950867\n",
            "Epoch: 7/9\n",
            "83\n",
            "Loss: 0.729224681854248\n",
            "Epoch: 7/9\n",
            "84\n",
            "Loss: 0.6398174166679382\n",
            "Epoch: 7/9\n",
            "85\n",
            "Loss: 0.729152262210846\n",
            "Epoch: 7/9\n",
            "86\n",
            "Loss: 0.6930103898048401\n",
            "Epoch: 7/9\n",
            "87\n",
            "Loss: 0.697073221206665\n",
            "Epoch: 7/9\n",
            "88\n",
            "Loss: 0.5787557363510132\n",
            "Epoch: 7/9\n",
            "89\n",
            "Loss: 0.6725946664810181\n",
            "Epoch: 7/9\n",
            "90\n",
            "Loss: 0.6434023976325989\n",
            "Epoch: 7/9\n",
            "91\n",
            "Loss: 0.6352459192276001\n",
            "Epoch: 7/9\n",
            "92\n",
            "Loss: 0.6387142539024353\n",
            "Epoch: 7/9\n",
            "93\n",
            "Loss: 0.5873719453811646\n",
            "Epoch: 7/9\n",
            "94\n",
            "Loss: 0.6176033020019531\n",
            "Epoch: 7/9\n",
            "95\n",
            "Loss: 0.6527060270309448\n",
            "Epoch: 7/9\n",
            "96\n",
            "Loss: 0.6490885019302368\n",
            "Epoch: 7/9\n",
            "97\n",
            "Loss: 0.590056836605072\n",
            "Epoch: 7/9\n",
            "98\n",
            "Loss: 0.6953191161155701\n",
            "Epoch: 7/9\n",
            "99\n",
            "Loss: 0.589981198310852\n",
            "Epoch: 7/9\n",
            "100\n",
            "Loss: 0.6289090514183044\n",
            "Epoch: 7/9\n",
            "101\n",
            "Loss: 0.5885816216468811\n",
            "Epoch: 7/9\n",
            "102\n",
            "Loss: 0.5465571880340576\n",
            "Epoch: 7/9\n",
            "103\n",
            "Loss: 0.606903076171875\n",
            "Epoch: 7/9\n",
            "104\n",
            "Loss: 0.6546810269355774\n",
            "Epoch: 7/9\n",
            "105\n",
            "Loss: 0.628206729888916\n",
            "Epoch: 7/9\n",
            "106\n",
            "Loss: 0.6428788900375366\n",
            "Epoch: 7/9\n",
            "107\n",
            "Loss: 0.5871772766113281\n",
            "Epoch: 7/9\n",
            "108\n",
            "Loss: 0.569794774055481\n",
            "Epoch: 7/9\n",
            "109\n",
            "Loss: 0.5821531414985657\n",
            "Epoch: 7/9\n",
            "110\n",
            "Loss: 0.5889518857002258\n",
            "Epoch: 7/9\n",
            "111\n",
            "Loss: 0.6270111799240112\n",
            "Epoch: 7/9\n",
            "112\n",
            "Loss: 0.5251634120941162\n",
            "Epoch: 7/9\n",
            "113\n",
            "Loss: 0.5480527877807617\n",
            "Epoch: 7/9\n",
            "114\n",
            "Loss: 0.5585893392562866\n",
            "Epoch: 7/9\n",
            "115\n",
            "Loss: 0.5925906300544739\n",
            "Epoch: 7/9\n",
            "116\n",
            "Loss: 0.5777137279510498\n",
            "Epoch: 7/9\n",
            "117\n",
            "Loss: 0.5734153985977173\n",
            "Epoch: 7/9\n",
            "118\n",
            "Loss: 0.535859227180481\n",
            "Epoch: 7/9\n",
            "119\n",
            "Loss: 0.5648229122161865\n",
            "Epoch: 7/9\n",
            "120\n",
            "Loss: 0.6978411078453064\n",
            "Epoch: 7/9\n",
            "121\n",
            "Loss: 0.5751720070838928\n",
            "Epoch: 7/9\n",
            "122\n",
            "Loss: 0.5440154075622559\n",
            "Epoch: 7/9\n",
            "123\n",
            "Loss: 0.5883392691612244\n",
            "Epoch: 7/9\n",
            "124\n",
            "Loss: 0.6389776468276978\n",
            "Epoch: 7/9\n",
            "125\n",
            "Loss: 0.708892285823822\n",
            "Epoch: 7/9\n",
            "126\n",
            "Loss: 0.6261646747589111\n",
            "Epoch: 7/9\n",
            "127\n",
            "Loss: 0.6641599535942078\n",
            "Epoch: 7/9\n",
            "128\n",
            "Loss: 0.5937120914459229\n",
            "Epoch: 7/9\n",
            "129\n",
            "Loss: 0.6071596741676331\n",
            "Epoch: 7/9\n",
            "130\n",
            "Loss: 0.6533958315849304\n",
            "Epoch: 7/9\n",
            "131\n",
            "Loss: 0.7759911417961121\n",
            "Epoch: 7/9\n",
            "132\n",
            "Loss: 0.7343746423721313\n",
            "Epoch: 7/9\n",
            "133\n",
            "Loss: 0.5238201022148132\n",
            "Epoch: 7/9\n",
            "134\n",
            "Loss: 0.7208184599876404\n",
            "Epoch: 7/9\n",
            "135\n",
            "Loss: 0.5822387933731079\n",
            "Epoch: 7/9\n",
            "136\n",
            "Loss: 0.6646725535392761\n",
            "Epoch: 7/9\n",
            "137\n",
            "Loss: 0.6643006801605225\n",
            "Epoch: 7/9\n",
            "138\n",
            "Loss: 0.5928897261619568\n",
            "Epoch: 7/9\n",
            "139\n",
            "Loss: 0.6755036115646362\n",
            "Epoch: 7/9\n",
            "140\n",
            "Loss: 0.6049044728279114\n",
            "Epoch: 7/9\n",
            "141\n",
            "Loss: 0.6626021862030029\n",
            "Epoch: 7/9\n",
            "142\n",
            "Loss: 0.5401082038879395\n",
            "Epoch: 7/9\n",
            "143\n",
            "Loss: 0.6111304759979248\n",
            "Epoch: 7/9\n",
            "144\n",
            "Loss: 0.5594873428344727\n",
            "Epoch: 7/9\n",
            "145\n",
            "Loss: 0.6323456764221191\n",
            "Epoch: 7/9\n",
            "146\n",
            "Loss: 0.599955677986145\n",
            "Epoch: 7/9\n",
            "147\n",
            "Loss: 0.5720414519309998\n",
            "Epoch: 7/9\n",
            "148\n",
            "Loss: 0.6018868684768677\n",
            "Epoch: 7/9\n",
            "149\n",
            "Loss: 0.5862827897071838\n",
            "Epoch: 7/9\n",
            "150\n",
            "Loss: 0.5353737473487854\n",
            "Epoch: 7/9\n",
            "151\n",
            "Loss: 0.43869027495384216\n",
            "Epoch: 7/9\n",
            "152\n",
            "Loss: 0.5075562000274658\n",
            "Epoch: 7/9\n",
            "153\n",
            "Loss: 0.5615234971046448\n",
            "Epoch: 7/9\n",
            "154\n",
            "Loss: 0.49701565504074097\n",
            "Epoch: 7/9\n",
            "155\n",
            "Loss: 0.523304283618927\n",
            "Epoch: 7/9\n",
            "156\n",
            "Loss: 0.4331691563129425\n",
            "Epoch: 7/9\n",
            "157\n",
            "Loss: 0.6156828999519348\n",
            "Epoch: 7/9\n",
            "158\n",
            "Loss: 0.5620336532592773\n",
            "Epoch: 7/9\n",
            "159\n",
            "Loss: 0.5715420246124268\n",
            "Epoch: 7/9\n",
            "160\n",
            "Loss: 0.5156509280204773\n",
            "Epoch: 7/9\n",
            "161\n",
            "Loss: 0.469717413187027\n",
            "Epoch: 7/9\n",
            "162\n",
            "Loss: 0.5706722140312195\n",
            "Epoch: 7/9\n",
            "163\n",
            "Loss: 0.47811707854270935\n",
            "Epoch: 7/9\n",
            "164\n",
            "Loss: 0.5617257952690125\n",
            "Epoch: 7/9\n",
            "165\n",
            "Loss: 0.44870492815971375\n",
            "Epoch: 7/9\n",
            "166\n",
            "Loss: 0.3621756434440613\n",
            "Epoch: 7/9\n",
            "167\n",
            "Loss: 0.43450528383255005\n",
            "Epoch: 7/9\n",
            "168\n",
            "Loss: 0.39923831820487976\n",
            "Epoch: 7/9\n",
            "169\n",
            "Loss: 0.46423038840293884\n",
            "Epoch: 7/9\n",
            "170\n",
            "Loss: 0.4432135224342346\n",
            "Epoch: 7/9\n",
            "171\n",
            "Loss: 0.3795522451400757\n",
            "Epoch: 7/9\n",
            "172\n",
            "Loss: 0.45985689759254456\n",
            "Epoch: 7/9\n",
            "173\n",
            "Loss: 0.4153585135936737\n",
            "Epoch: 7/9\n",
            "174\n",
            "Loss: 0.4338107407093048\n",
            "Epoch: 7/9\n",
            "175\n",
            "Loss: 0.34453484416007996\n",
            "Epoch: 7/9\n",
            "176\n",
            "Loss: 0.447317898273468\n",
            "Epoch: 7/9\n",
            "177\n",
            "Loss: 0.44364801049232483\n",
            "Epoch: 7/9\n",
            "178\n",
            "Loss: 0.5260171294212341\n",
            "Epoch: 7/9\n",
            "179\n",
            "Loss: 0.47759559750556946\n",
            "Epoch: 7/9\n",
            "180\n",
            "Loss: 0.5016868114471436\n",
            "Epoch: 7/9\n",
            "181\n",
            "Loss: 0.5275206565856934\n",
            "Epoch: 7/9\n",
            "182\n",
            "Loss: 0.450533926486969\n",
            "Epoch: 7/9\n",
            "183\n",
            "Loss: 0.4978364109992981\n",
            "Epoch: 7/9\n",
            "184\n",
            "Loss: 0.49526944756507874\n",
            "Epoch: 7/9\n",
            "185\n",
            "Loss: 0.42758655548095703\n",
            "Epoch: 7/9\n",
            "186\n",
            "Loss: 0.5014588236808777\n",
            "Epoch: 7/9\n",
            "187\n",
            "Loss: 0.49344247579574585\n",
            "Epoch: 7/9\n",
            "188\n",
            "Loss: 0.4420914351940155\n",
            "Epoch: 7/9\n",
            "189\n",
            "Loss: 0.37087422609329224\n",
            "Epoch: 7/9\n",
            "190\n",
            "Loss: 0.417153000831604\n",
            "Epoch: 7/9\n",
            "191\n",
            "Loss: 0.37582701444625854\n",
            "Epoch: 7/9\n",
            "192\n",
            "Loss: 0.3407299220561981\n",
            "Epoch: 7/9\n",
            "193\n",
            "Loss: 0.39064133167266846\n",
            "Epoch: 7/9\n",
            "194\n",
            "Loss: 0.2954427897930145\n",
            "Epoch: 7/9\n",
            "195\n",
            "Loss: 0.20185573399066925\n",
            "Epoch: 7/9\n",
            "Epoch: 8\n",
            "0\n",
            "Loss: 0.4929655194282532\n",
            "Epoch: 8/9\n",
            "1\n",
            "Loss: 0.49264878034591675\n",
            "Epoch: 8/9\n",
            "2\n",
            "Loss: 0.3906818628311157\n",
            "Epoch: 8/9\n",
            "3\n",
            "Loss: 0.4829943776130676\n",
            "Epoch: 8/9\n",
            "4\n",
            "Loss: 0.6421458125114441\n",
            "Epoch: 8/9\n",
            "5\n",
            "Loss: 0.5204108953475952\n",
            "Epoch: 8/9\n",
            "6\n",
            "Loss: 0.4727014899253845\n",
            "Epoch: 8/9\n",
            "7\n",
            "Loss: 0.6222946047782898\n",
            "Epoch: 8/9\n",
            "8\n",
            "Loss: 0.5865017771720886\n",
            "Epoch: 8/9\n",
            "9\n",
            "Loss: 0.5196038484573364\n",
            "Epoch: 8/9\n",
            "10\n",
            "Loss: 0.5286650061607361\n",
            "Epoch: 8/9\n",
            "11\n",
            "Loss: 0.690684974193573\n",
            "Epoch: 8/9\n",
            "12\n",
            "Loss: 0.6334891319274902\n",
            "Epoch: 8/9\n",
            "13\n",
            "Loss: 0.5839359164237976\n",
            "Epoch: 8/9\n",
            "14\n",
            "Loss: 0.6130416393280029\n",
            "Epoch: 8/9\n",
            "15\n",
            "Loss: 0.65552818775177\n",
            "Epoch: 8/9\n",
            "16\n",
            "Loss: 0.6779999136924744\n",
            "Epoch: 8/9\n",
            "17\n",
            "Loss: 0.6973249912261963\n",
            "Epoch: 8/9\n",
            "18\n",
            "Loss: 0.6132600903511047\n",
            "Epoch: 8/9\n",
            "19\n",
            "Loss: 0.6572141051292419\n",
            "Epoch: 8/9\n",
            "20\n",
            "Loss: 0.6441158056259155\n",
            "Epoch: 8/9\n",
            "21\n",
            "Loss: 0.6488132476806641\n",
            "Epoch: 8/9\n",
            "22\n",
            "Loss: 0.6274094581604004\n",
            "Epoch: 8/9\n",
            "23\n",
            "Loss: 0.5852806568145752\n",
            "Epoch: 8/9\n",
            "24\n",
            "Loss: 0.6532238721847534\n",
            "Epoch: 8/9\n",
            "25\n",
            "Loss: 0.666134774684906\n",
            "Epoch: 8/9\n",
            "26\n",
            "Loss: 0.6914446353912354\n",
            "Epoch: 8/9\n",
            "27\n",
            "Loss: 0.6496978998184204\n",
            "Epoch: 8/9\n",
            "28\n",
            "Loss: 0.5713493824005127\n",
            "Epoch: 8/9\n",
            "29\n",
            "Loss: 0.6681922674179077\n",
            "Epoch: 8/9\n",
            "30\n",
            "Loss: 0.6060249209403992\n",
            "Epoch: 8/9\n",
            "31\n",
            "Loss: 0.639665424823761\n",
            "Epoch: 8/9\n",
            "32\n",
            "Loss: 0.548844039440155\n",
            "Epoch: 8/9\n",
            "33\n",
            "Loss: 0.6783260107040405\n",
            "Epoch: 8/9\n",
            "34\n",
            "Loss: 0.6196372509002686\n",
            "Epoch: 8/9\n",
            "35\n",
            "Loss: 0.6655855178833008\n",
            "Epoch: 8/9\n",
            "36\n",
            "Loss: 0.745680570602417\n",
            "Epoch: 8/9\n",
            "37\n",
            "Loss: 0.6062872409820557\n",
            "Epoch: 8/9\n",
            "38\n",
            "Loss: 0.6008098125457764\n",
            "Epoch: 8/9\n",
            "39\n",
            "Loss: 0.7370345592498779\n",
            "Epoch: 8/9\n",
            "40\n",
            "Loss: 0.7173875570297241\n",
            "Epoch: 8/9\n",
            "41\n",
            "Loss: 0.5861077308654785\n",
            "Epoch: 8/9\n",
            "42\n",
            "Loss: 0.6556864976882935\n",
            "Epoch: 8/9\n",
            "43\n",
            "Loss: 0.7850896120071411\n",
            "Epoch: 8/9\n",
            "44\n",
            "Loss: 0.6091701984405518\n",
            "Epoch: 8/9\n",
            "45\n",
            "Loss: 0.6058055758476257\n",
            "Epoch: 8/9\n",
            "46\n",
            "Loss: 0.6035492420196533\n",
            "Epoch: 8/9\n",
            "47\n",
            "Loss: 0.7212632298469543\n",
            "Epoch: 8/9\n",
            "48\n",
            "Loss: 0.711222767829895\n",
            "Epoch: 8/9\n",
            "49\n",
            "Loss: 0.6309599280357361\n",
            "Epoch: 8/9\n",
            "50\n",
            "Loss: 0.6672510504722595\n",
            "Epoch: 8/9\n",
            "51\n",
            "Loss: 0.7316452264785767\n",
            "Epoch: 8/9\n",
            "52\n",
            "Loss: 0.6777101755142212\n",
            "Epoch: 8/9\n",
            "53\n",
            "Loss: 0.7323693037033081\n",
            "Epoch: 8/9\n",
            "54\n",
            "Loss: 0.6866034269332886\n",
            "Epoch: 8/9\n",
            "55\n",
            "Loss: 0.6403653621673584\n",
            "Epoch: 8/9\n",
            "56\n",
            "Loss: 0.6699941158294678\n",
            "Epoch: 8/9\n",
            "57\n",
            "Loss: 0.6201257705688477\n",
            "Epoch: 8/9\n",
            "58\n",
            "Loss: 0.5918945670127869\n",
            "Epoch: 8/9\n",
            "59\n",
            "Loss: 0.6345300674438477\n",
            "Epoch: 8/9\n",
            "60\n",
            "Loss: 0.5988123416900635\n",
            "Epoch: 8/9\n",
            "61\n",
            "Loss: 0.5811089277267456\n",
            "Epoch: 8/9\n",
            "62\n",
            "Loss: 0.6338237524032593\n",
            "Epoch: 8/9\n",
            "63\n",
            "Loss: 0.5771511793136597\n",
            "Epoch: 8/9\n",
            "64\n",
            "Loss: 0.5913691520690918\n",
            "Epoch: 8/9\n",
            "65\n",
            "Loss: 0.5176459550857544\n",
            "Epoch: 8/9\n",
            "66\n",
            "Loss: 0.5168530344963074\n",
            "Epoch: 8/9\n",
            "67\n",
            "Loss: 0.6146416068077087\n",
            "Epoch: 8/9\n",
            "68\n",
            "Loss: 0.5795179009437561\n",
            "Epoch: 8/9\n",
            "69\n",
            "Loss: 0.6452273726463318\n",
            "Epoch: 8/9\n",
            "70\n",
            "Loss: 0.6664271950721741\n",
            "Epoch: 8/9\n",
            "71\n",
            "Loss: 0.6319292783737183\n",
            "Epoch: 8/9\n",
            "72\n",
            "Loss: 0.6858224868774414\n",
            "Epoch: 8/9\n",
            "73\n",
            "Loss: 0.6380404829978943\n",
            "Epoch: 8/9\n",
            "74\n",
            "Loss: 0.676450252532959\n",
            "Epoch: 8/9\n",
            "75\n",
            "Loss: 0.5916322469711304\n",
            "Epoch: 8/9\n",
            "76\n",
            "Loss: 0.6701350212097168\n",
            "Epoch: 8/9\n",
            "77\n",
            "Loss: 0.6623098850250244\n",
            "Epoch: 8/9\n",
            "78\n",
            "Loss: 0.7053412199020386\n",
            "Epoch: 8/9\n",
            "79\n",
            "Loss: 0.6340757012367249\n",
            "Epoch: 8/9\n",
            "80\n",
            "Loss: 0.5951072573661804\n",
            "Epoch: 8/9\n",
            "81\n",
            "Loss: 0.6644287705421448\n",
            "Epoch: 8/9\n",
            "82\n",
            "Loss: 0.5896204710006714\n",
            "Epoch: 8/9\n",
            "83\n",
            "Loss: 0.7284806966781616\n",
            "Epoch: 8/9\n",
            "84\n",
            "Loss: 0.6380261778831482\n",
            "Epoch: 8/9\n",
            "85\n",
            "Loss: 0.7262020707130432\n",
            "Epoch: 8/9\n",
            "86\n",
            "Loss: 0.6894034743309021\n",
            "Epoch: 8/9\n",
            "87\n",
            "Loss: 0.6955235004425049\n",
            "Epoch: 8/9\n",
            "88\n",
            "Loss: 0.5767583250999451\n",
            "Epoch: 8/9\n",
            "89\n",
            "Loss: 0.6692225337028503\n",
            "Epoch: 8/9\n",
            "90\n",
            "Loss: 0.638995349407196\n",
            "Epoch: 8/9\n",
            "91\n",
            "Loss: 0.6303222179412842\n",
            "Epoch: 8/9\n",
            "92\n",
            "Loss: 0.6347149610519409\n",
            "Epoch: 8/9\n",
            "93\n",
            "Loss: 0.5846498012542725\n",
            "Epoch: 8/9\n",
            "94\n",
            "Loss: 0.6143142580986023\n",
            "Epoch: 8/9\n",
            "95\n",
            "Loss: 0.6512844562530518\n",
            "Epoch: 8/9\n",
            "96\n",
            "Loss: 0.6442866921424866\n",
            "Epoch: 8/9\n",
            "97\n",
            "Loss: 0.5853874683380127\n",
            "Epoch: 8/9\n",
            "98\n",
            "Loss: 0.6947848796844482\n",
            "Epoch: 8/9\n",
            "99\n",
            "Loss: 0.5882216691970825\n",
            "Epoch: 8/9\n",
            "100\n",
            "Loss: 0.625278890132904\n",
            "Epoch: 8/9\n",
            "101\n",
            "Loss: 0.5854358673095703\n",
            "Epoch: 8/9\n",
            "102\n",
            "Loss: 0.5446562170982361\n",
            "Epoch: 8/9\n",
            "103\n",
            "Loss: 0.6055112481117249\n",
            "Epoch: 8/9\n",
            "104\n",
            "Loss: 0.6508405804634094\n",
            "Epoch: 8/9\n",
            "105\n",
            "Loss: 0.626640796661377\n",
            "Epoch: 8/9\n",
            "106\n",
            "Loss: 0.6385128498077393\n",
            "Epoch: 8/9\n",
            "107\n",
            "Loss: 0.5848729610443115\n",
            "Epoch: 8/9\n",
            "108\n",
            "Loss: 0.5691990256309509\n",
            "Epoch: 8/9\n",
            "109\n",
            "Loss: 0.5781363844871521\n",
            "Epoch: 8/9\n",
            "110\n",
            "Loss: 0.5859192609786987\n",
            "Epoch: 8/9\n",
            "111\n",
            "Loss: 0.6229804754257202\n",
            "Epoch: 8/9\n",
            "112\n",
            "Loss: 0.5205352902412415\n",
            "Epoch: 8/9\n",
            "113\n",
            "Loss: 0.5441716313362122\n",
            "Epoch: 8/9\n",
            "114\n",
            "Loss: 0.5553960204124451\n",
            "Epoch: 8/9\n",
            "115\n",
            "Loss: 0.5892834663391113\n",
            "Epoch: 8/9\n",
            "116\n",
            "Loss: 0.5754856467247009\n",
            "Epoch: 8/9\n",
            "117\n",
            "Loss: 0.5704907178878784\n",
            "Epoch: 8/9\n",
            "118\n",
            "Loss: 0.5329161882400513\n",
            "Epoch: 8/9\n",
            "119\n",
            "Loss: 0.5615370273590088\n",
            "Epoch: 8/9\n",
            "120\n",
            "Loss: 0.6953962445259094\n",
            "Epoch: 8/9\n",
            "121\n",
            "Loss: 0.5721268653869629\n",
            "Epoch: 8/9\n",
            "122\n",
            "Loss: 0.5423200726509094\n",
            "Epoch: 8/9\n",
            "123\n",
            "Loss: 0.5858520269393921\n",
            "Epoch: 8/9\n",
            "124\n",
            "Loss: 0.6360527276992798\n",
            "Epoch: 8/9\n",
            "125\n",
            "Loss: 0.7058069109916687\n",
            "Epoch: 8/9\n",
            "126\n",
            "Loss: 0.623204231262207\n",
            "Epoch: 8/9\n",
            "127\n",
            "Loss: 0.6614032983779907\n",
            "Epoch: 8/9\n",
            "128\n",
            "Loss: 0.5892390012741089\n",
            "Epoch: 8/9\n",
            "129\n",
            "Loss: 0.6052402257919312\n",
            "Epoch: 8/9\n",
            "130\n",
            "Loss: 0.6499693989753723\n",
            "Epoch: 8/9\n",
            "131\n",
            "Loss: 0.7725512981414795\n",
            "Epoch: 8/9\n",
            "132\n",
            "Loss: 0.7317056655883789\n",
            "Epoch: 8/9\n",
            "133\n",
            "Loss: 0.5207757353782654\n",
            "Epoch: 8/9\n",
            "134\n",
            "Loss: 0.716139018535614\n",
            "Epoch: 8/9\n",
            "135\n",
            "Loss: 0.5793676376342773\n",
            "Epoch: 8/9\n",
            "136\n",
            "Loss: 0.6608894467353821\n",
            "Epoch: 8/9\n",
            "137\n",
            "Loss: 0.660971462726593\n",
            "Epoch: 8/9\n",
            "138\n",
            "Loss: 0.5900323390960693\n",
            "Epoch: 8/9\n",
            "139\n",
            "Loss: 0.6719566583633423\n",
            "Epoch: 8/9\n",
            "140\n",
            "Loss: 0.6025896668434143\n",
            "Epoch: 8/9\n",
            "141\n",
            "Loss: 0.6590600609779358\n",
            "Epoch: 8/9\n",
            "142\n",
            "Loss: 0.5362001061439514\n",
            "Epoch: 8/9\n",
            "143\n",
            "Loss: 0.6091023683547974\n",
            "Epoch: 8/9\n",
            "144\n",
            "Loss: 0.5582114458084106\n",
            "Epoch: 8/9\n",
            "145\n",
            "Loss: 0.6295669674873352\n",
            "Epoch: 8/9\n",
            "146\n",
            "Loss: 0.5970712304115295\n",
            "Epoch: 8/9\n",
            "147\n",
            "Loss: 0.5709452629089355\n",
            "Epoch: 8/9\n",
            "148\n",
            "Loss: 0.5976906418800354\n",
            "Epoch: 8/9\n",
            "149\n",
            "Loss: 0.5849056839942932\n",
            "Epoch: 8/9\n",
            "150\n",
            "Loss: 0.5336158871650696\n",
            "Epoch: 8/9\n",
            "151\n",
            "Loss: 0.43624600768089294\n",
            "Epoch: 8/9\n",
            "152\n",
            "Loss: 0.5036324858665466\n",
            "Epoch: 8/9\n",
            "153\n",
            "Loss: 0.5590406060218811\n",
            "Epoch: 8/9\n",
            "154\n",
            "Loss: 0.4952910244464874\n",
            "Epoch: 8/9\n",
            "155\n",
            "Loss: 0.5190244317054749\n",
            "Epoch: 8/9\n",
            "156\n",
            "Loss: 0.4310890734195709\n",
            "Epoch: 8/9\n",
            "157\n",
            "Loss: 0.6129418611526489\n",
            "Epoch: 8/9\n",
            "158\n",
            "Loss: 0.5592053532600403\n",
            "Epoch: 8/9\n",
            "159\n",
            "Loss: 0.5677131414413452\n",
            "Epoch: 8/9\n",
            "160\n",
            "Loss: 0.5126197934150696\n",
            "Epoch: 8/9\n",
            "161\n",
            "Loss: 0.46661004424095154\n",
            "Epoch: 8/9\n",
            "162\n",
            "Loss: 0.5657936334609985\n",
            "Epoch: 8/9\n",
            "163\n",
            "Loss: 0.4747481942176819\n",
            "Epoch: 8/9\n",
            "164\n",
            "Loss: 0.5586878061294556\n",
            "Epoch: 8/9\n",
            "165\n",
            "Loss: 0.4450773596763611\n",
            "Epoch: 8/9\n",
            "166\n",
            "Loss: 0.35828453302383423\n",
            "Epoch: 8/9\n",
            "167\n",
            "Loss: 0.43142664432525635\n",
            "Epoch: 8/9\n",
            "168\n",
            "Loss: 0.3968016803264618\n",
            "Epoch: 8/9\n",
            "169\n",
            "Loss: 0.4619910717010498\n",
            "Epoch: 8/9\n",
            "170\n",
            "Loss: 0.4407009482383728\n",
            "Epoch: 8/9\n",
            "171\n",
            "Loss: 0.3762449622154236\n",
            "Epoch: 8/9\n",
            "172\n",
            "Loss: 0.45786556601524353\n",
            "Epoch: 8/9\n",
            "173\n",
            "Loss: 0.41230782866477966\n",
            "Epoch: 8/9\n",
            "174\n",
            "Loss: 0.4296235740184784\n",
            "Epoch: 8/9\n",
            "175\n",
            "Loss: 0.3412836194038391\n",
            "Epoch: 8/9\n",
            "176\n",
            "Loss: 0.44350019097328186\n",
            "Epoch: 8/9\n",
            "177\n",
            "Loss: 0.44090506434440613\n",
            "Epoch: 8/9\n",
            "178\n",
            "Loss: 0.5238449573516846\n",
            "Epoch: 8/9\n",
            "179\n",
            "Loss: 0.47410982847213745\n",
            "Epoch: 8/9\n",
            "180\n",
            "Loss: 0.4992004334926605\n",
            "Epoch: 8/9\n",
            "181\n",
            "Loss: 0.525438129901886\n",
            "Epoch: 8/9\n",
            "182\n",
            "Loss: 0.44936272501945496\n",
            "Epoch: 8/9\n",
            "183\n",
            "Loss: 0.49381691217422485\n",
            "Epoch: 8/9\n",
            "184\n",
            "Loss: 0.49314749240875244\n",
            "Epoch: 8/9\n",
            "185\n",
            "Loss: 0.4253248870372772\n",
            "Epoch: 8/9\n",
            "186\n",
            "Loss: 0.4980875849723816\n",
            "Epoch: 8/9\n",
            "187\n",
            "Loss: 0.4896746873855591\n",
            "Epoch: 8/9\n",
            "188\n",
            "Loss: 0.43974569439888\n",
            "Epoch: 8/9\n",
            "189\n",
            "Loss: 0.36824917793273926\n",
            "Epoch: 8/9\n",
            "190\n",
            "Loss: 0.4151044189929962\n",
            "Epoch: 8/9\n",
            "191\n",
            "Loss: 0.3726137578487396\n",
            "Epoch: 8/9\n",
            "192\n",
            "Loss: 0.338693767786026\n",
            "Epoch: 8/9\n",
            "193\n",
            "Loss: 0.38676977157592773\n",
            "Epoch: 8/9\n",
            "194\n",
            "Loss: 0.29212382435798645\n",
            "Epoch: 8/9\n",
            "195\n",
            "Loss: 0.2001047432422638\n",
            "Epoch: 8/9\n",
            "Epoch: 9\n",
            "0\n",
            "Loss: 0.48884332180023193\n",
            "Epoch: 9/9\n",
            "1\n",
            "Loss: 0.49079906940460205\n",
            "Epoch: 9/9\n",
            "2\n",
            "Loss: 0.38724496960639954\n",
            "Epoch: 9/9\n",
            "3\n",
            "Loss: 0.4785177707672119\n",
            "Epoch: 9/9\n",
            "4\n",
            "Loss: 0.639342188835144\n",
            "Epoch: 9/9\n",
            "5\n",
            "Loss: 0.5163725018501282\n",
            "Epoch: 9/9\n",
            "6\n",
            "Loss: 0.4701492488384247\n",
            "Epoch: 9/9\n",
            "7\n",
            "Loss: 0.6196611523628235\n",
            "Epoch: 9/9\n",
            "8\n",
            "Loss: 0.5830506086349487\n",
            "Epoch: 9/9\n",
            "9\n",
            "Loss: 0.5161433815956116\n",
            "Epoch: 9/9\n",
            "10\n",
            "Loss: 0.5259300470352173\n",
            "Epoch: 9/9\n",
            "11\n",
            "Loss: 0.6876780390739441\n",
            "Epoch: 9/9\n",
            "12\n",
            "Loss: 0.6302570104598999\n",
            "Epoch: 9/9\n",
            "13\n",
            "Loss: 0.5828813314437866\n",
            "Epoch: 9/9\n",
            "14\n",
            "Loss: 0.6079708337783813\n",
            "Epoch: 9/9\n",
            "15\n",
            "Loss: 0.6538459062576294\n",
            "Epoch: 9/9\n",
            "16\n",
            "Loss: 0.6738100647926331\n",
            "Epoch: 9/9\n",
            "17\n",
            "Loss: 0.694186270236969\n",
            "Epoch: 9/9\n",
            "18\n",
            "Loss: 0.6111470460891724\n",
            "Epoch: 9/9\n",
            "19\n",
            "Loss: 0.6563031077384949\n",
            "Epoch: 9/9\n",
            "20\n",
            "Loss: 0.6409848928451538\n",
            "Epoch: 9/9\n",
            "21\n",
            "Loss: 0.6446844339370728\n",
            "Epoch: 9/9\n",
            "22\n",
            "Loss: 0.624907374382019\n",
            "Epoch: 9/9\n",
            "23\n",
            "Loss: 0.582190215587616\n",
            "Epoch: 9/9\n",
            "24\n",
            "Loss: 0.6508976817131042\n",
            "Epoch: 9/9\n",
            "25\n",
            "Loss: 0.6624554395675659\n",
            "Epoch: 9/9\n",
            "26\n",
            "Loss: 0.6877476572990417\n",
            "Epoch: 9/9\n",
            "27\n",
            "Loss: 0.6465374231338501\n",
            "Epoch: 9/9\n",
            "28\n",
            "Loss: 0.5677132606506348\n",
            "Epoch: 9/9\n",
            "29\n",
            "Loss: 0.6648915410041809\n",
            "Epoch: 9/9\n",
            "30\n",
            "Loss: 0.6034147143363953\n",
            "Epoch: 9/9\n",
            "31\n",
            "Loss: 0.6369943022727966\n",
            "Epoch: 9/9\n",
            "32\n",
            "Loss: 0.5486056208610535\n",
            "Epoch: 9/9\n",
            "33\n",
            "Loss: 0.6757099032402039\n",
            "Epoch: 9/9\n",
            "34\n",
            "Loss: 0.6153011918067932\n",
            "Epoch: 9/9\n",
            "35\n",
            "Loss: 0.6628432273864746\n",
            "Epoch: 9/9\n",
            "36\n",
            "Loss: 0.7424187660217285\n",
            "Epoch: 9/9\n",
            "37\n",
            "Loss: 0.6037460565567017\n",
            "Epoch: 9/9\n",
            "38\n",
            "Loss: 0.5974311828613281\n",
            "Epoch: 9/9\n",
            "39\n",
            "Loss: 0.7351890802383423\n",
            "Epoch: 9/9\n",
            "40\n",
            "Loss: 0.7157627940177917\n",
            "Epoch: 9/9\n",
            "41\n",
            "Loss: 0.5850266218185425\n",
            "Epoch: 9/9\n",
            "42\n",
            "Loss: 0.651719868183136\n",
            "Epoch: 9/9\n",
            "43\n",
            "Loss: 0.7806904911994934\n",
            "Epoch: 9/9\n",
            "44\n",
            "Loss: 0.6063421368598938\n",
            "Epoch: 9/9\n",
            "45\n",
            "Loss: 0.6034162044525146\n",
            "Epoch: 9/9\n",
            "46\n",
            "Loss: 0.5987628102302551\n",
            "Epoch: 9/9\n",
            "47\n",
            "Loss: 0.7203109860420227\n",
            "Epoch: 9/9\n",
            "48\n",
            "Loss: 0.7086494565010071\n",
            "Epoch: 9/9\n",
            "49\n",
            "Loss: 0.6287214756011963\n",
            "Epoch: 9/9\n",
            "50\n",
            "Loss: 0.6656394004821777\n",
            "Epoch: 9/9\n",
            "51\n",
            "Loss: 0.7285992503166199\n",
            "Epoch: 9/9\n",
            "52\n",
            "Loss: 0.6738991737365723\n",
            "Epoch: 9/9\n",
            "53\n",
            "Loss: 0.7292832732200623\n",
            "Epoch: 9/9\n",
            "54\n",
            "Loss: 0.6843624114990234\n",
            "Epoch: 9/9\n",
            "55\n",
            "Loss: 0.6373683214187622\n",
            "Epoch: 9/9\n",
            "56\n",
            "Loss: 0.6654508113861084\n",
            "Epoch: 9/9\n",
            "57\n",
            "Loss: 0.6174296140670776\n",
            "Epoch: 9/9\n",
            "58\n",
            "Loss: 0.5893555283546448\n",
            "Epoch: 9/9\n",
            "59\n",
            "Loss: 0.6331942677497864\n",
            "Epoch: 9/9\n",
            "60\n",
            "Loss: 0.5949692130088806\n",
            "Epoch: 9/9\n",
            "61\n",
            "Loss: 0.577673614025116\n",
            "Epoch: 9/9\n",
            "62\n",
            "Loss: 0.6307792067527771\n",
            "Epoch: 9/9\n",
            "63\n",
            "Loss: 0.5750621557235718\n",
            "Epoch: 9/9\n",
            "64\n",
            "Loss: 0.5898945331573486\n",
            "Epoch: 9/9\n",
            "65\n",
            "Loss: 0.5146446824073792\n",
            "Epoch: 9/9\n",
            "66\n",
            "Loss: 0.5140500068664551\n",
            "Epoch: 9/9\n",
            "67\n",
            "Loss: 0.6116726398468018\n",
            "Epoch: 9/9\n",
            "68\n",
            "Loss: 0.5764826536178589\n",
            "Epoch: 9/9\n",
            "69\n",
            "Loss: 0.6434910297393799\n",
            "Epoch: 9/9\n",
            "70\n",
            "Loss: 0.6649043560028076\n",
            "Epoch: 9/9\n",
            "71\n",
            "Loss: 0.6298338174819946\n",
            "Epoch: 9/9\n",
            "72\n",
            "Loss: 0.68312007188797\n",
            "Epoch: 9/9\n",
            "73\n",
            "Loss: 0.6353151798248291\n",
            "Epoch: 9/9\n",
            "74\n",
            "Loss: 0.6737685799598694\n",
            "Epoch: 9/9\n",
            "75\n",
            "Loss: 0.5877915620803833\n",
            "Epoch: 9/9\n",
            "76\n",
            "Loss: 0.6675657629966736\n",
            "Epoch: 9/9\n",
            "77\n",
            "Loss: 0.660409688949585\n",
            "Epoch: 9/9\n",
            "78\n",
            "Loss: 0.7005865573883057\n",
            "Epoch: 9/9\n",
            "79\n",
            "Loss: 0.6318051218986511\n",
            "Epoch: 9/9\n",
            "80\n",
            "Loss: 0.591003954410553\n",
            "Epoch: 9/9\n",
            "81\n",
            "Loss: 0.6619628667831421\n",
            "Epoch: 9/9\n",
            "82\n",
            "Loss: 0.5862835645675659\n",
            "Epoch: 9/9\n",
            "83\n",
            "Loss: 0.7267407178878784\n",
            "Epoch: 9/9\n",
            "84\n",
            "Loss: 0.6356906294822693\n",
            "Epoch: 9/9\n",
            "85\n",
            "Loss: 0.7245126366615295\n",
            "Epoch: 9/9\n",
            "86\n",
            "Loss: 0.686327338218689\n",
            "Epoch: 9/9\n",
            "87\n",
            "Loss: 0.6935832500457764\n",
            "Epoch: 9/9\n",
            "88\n",
            "Loss: 0.5750499367713928\n",
            "Epoch: 9/9\n",
            "89\n",
            "Loss: 0.6662617921829224\n",
            "Epoch: 9/9\n",
            "90\n",
            "Loss: 0.6353567838668823\n",
            "Epoch: 9/9\n",
            "91\n",
            "Loss: 0.627048909664154\n",
            "Epoch: 9/9\n",
            "92\n",
            "Loss: 0.6315388083457947\n",
            "Epoch: 9/9\n",
            "93\n",
            "Loss: 0.5825853943824768\n",
            "Epoch: 9/9\n",
            "94\n",
            "Loss: 0.6115202903747559\n",
            "Epoch: 9/9\n",
            "95\n",
            "Loss: 0.6501287817955017\n",
            "Epoch: 9/9\n",
            "96\n",
            "Loss: 0.6404427886009216\n",
            "Epoch: 9/9\n",
            "97\n",
            "Loss: 0.5803312063217163\n",
            "Epoch: 9/9\n",
            "98\n",
            "Loss: 0.6940262317657471\n",
            "Epoch: 9/9\n",
            "99\n",
            "Loss: 0.5870121717453003\n",
            "Epoch: 9/9\n",
            "100\n",
            "Loss: 0.622940719127655\n",
            "Epoch: 9/9\n",
            "101\n",
            "Loss: 0.5823131203651428\n",
            "Epoch: 9/9\n",
            "102\n",
            "Loss: 0.5422540903091431\n",
            "Epoch: 9/9\n",
            "103\n",
            "Loss: 0.6027177572250366\n",
            "Epoch: 9/9\n",
            "104\n",
            "Loss: 0.6475196480751038\n",
            "Epoch: 9/9\n",
            "105\n",
            "Loss: 0.6248486042022705\n",
            "Epoch: 9/9\n",
            "106\n",
            "Loss: 0.6338660717010498\n",
            "Epoch: 9/9\n",
            "107\n",
            "Loss: 0.5824677348136902\n",
            "Epoch: 9/9\n",
            "108\n",
            "Loss: 0.568072497844696\n",
            "Epoch: 9/9\n",
            "109\n",
            "Loss: 0.5742371082305908\n",
            "Epoch: 9/9\n",
            "110\n",
            "Loss: 0.5833706855773926\n",
            "Epoch: 9/9\n",
            "111\n",
            "Loss: 0.6196698546409607\n",
            "Epoch: 9/9\n",
            "112\n",
            "Loss: 0.5169870257377625\n",
            "Epoch: 9/9\n",
            "113\n",
            "Loss: 0.540806233882904\n",
            "Epoch: 9/9\n",
            "114\n",
            "Loss: 0.552262544631958\n",
            "Epoch: 9/9\n",
            "115\n",
            "Loss: 0.5865075588226318\n",
            "Epoch: 9/9\n",
            "116\n",
            "Loss: 0.5719921588897705\n",
            "Epoch: 9/9\n",
            "117\n",
            "Loss: 0.5675116181373596\n",
            "Epoch: 9/9\n",
            "118\n",
            "Loss: 0.5303307175636292\n",
            "Epoch: 9/9\n",
            "119\n",
            "Loss: 0.5586749911308289\n",
            "Epoch: 9/9\n",
            "120\n",
            "Loss: 0.693101704120636\n",
            "Epoch: 9/9\n",
            "121\n",
            "Loss: 0.5695765614509583\n",
            "Epoch: 9/9\n",
            "122\n",
            "Loss: 0.5408715605735779\n",
            "Epoch: 9/9\n",
            "123\n",
            "Loss: 0.5831835865974426\n",
            "Epoch: 9/9\n",
            "124\n",
            "Loss: 0.6320996284484863\n",
            "Epoch: 9/9\n",
            "125\n",
            "Loss: 0.7032266855239868\n",
            "Epoch: 9/9\n",
            "126\n",
            "Loss: 0.6200243830680847\n",
            "Epoch: 9/9\n",
            "127\n",
            "Loss: 0.6578586101531982\n",
            "Epoch: 9/9\n",
            "128\n",
            "Loss: 0.585261881351471\n",
            "Epoch: 9/9\n",
            "129\n",
            "Loss: 0.6043601632118225\n",
            "Epoch: 9/9\n",
            "130\n",
            "Loss: 0.6467578411102295\n",
            "Epoch: 9/9\n",
            "131\n",
            "Loss: 0.7682324647903442\n",
            "Epoch: 9/9\n",
            "132\n",
            "Loss: 0.7282997965812683\n",
            "Epoch: 9/9\n",
            "133\n",
            "Loss: 0.5187491178512573\n",
            "Epoch: 9/9\n",
            "134\n",
            "Loss: 0.71187424659729\n",
            "Epoch: 9/9\n",
            "135\n",
            "Loss: 0.5766403675079346\n",
            "Epoch: 9/9\n",
            "136\n",
            "Loss: 0.6582725048065186\n",
            "Epoch: 9/9\n",
            "137\n",
            "Loss: 0.6574283838272095\n",
            "Epoch: 9/9\n",
            "138\n",
            "Loss: 0.586431086063385\n",
            "Epoch: 9/9\n",
            "139\n",
            "Loss: 0.6686163544654846\n",
            "Epoch: 9/9\n",
            "140\n",
            "Loss: 0.5998594760894775\n",
            "Epoch: 9/9\n",
            "141\n",
            "Loss: 0.6550500988960266\n",
            "Epoch: 9/9\n",
            "142\n",
            "Loss: 0.5325697064399719\n",
            "Epoch: 9/9\n",
            "143\n",
            "Loss: 0.6078065037727356\n",
            "Epoch: 9/9\n",
            "144\n",
            "Loss: 0.5579623579978943\n",
            "Epoch: 9/9\n",
            "145\n",
            "Loss: 0.6266381740570068\n",
            "Epoch: 9/9\n",
            "146\n",
            "Loss: 0.5951258540153503\n",
            "Epoch: 9/9\n",
            "147\n",
            "Loss: 0.5691884160041809\n",
            "Epoch: 9/9\n",
            "148\n",
            "Loss: 0.5942860841751099\n",
            "Epoch: 9/9\n",
            "149\n",
            "Loss: 0.5836775302886963\n",
            "Epoch: 9/9\n",
            "150\n",
            "Loss: 0.5321181416511536\n",
            "Epoch: 9/9\n",
            "151\n",
            "Loss: 0.4338999390602112\n",
            "Epoch: 9/9\n",
            "152\n",
            "Loss: 0.5004821419715881\n",
            "Epoch: 9/9\n",
            "153\n",
            "Loss: 0.5567000508308411\n",
            "Epoch: 9/9\n",
            "154\n",
            "Loss: 0.4928019642829895\n",
            "Epoch: 9/9\n",
            "155\n",
            "Loss: 0.5153651833534241\n",
            "Epoch: 9/9\n",
            "156\n",
            "Loss: 0.42965129017829895\n",
            "Epoch: 9/9\n",
            "157\n",
            "Loss: 0.6105118989944458\n",
            "Epoch: 9/9\n",
            "158\n",
            "Loss: 0.5569756031036377\n",
            "Epoch: 9/9\n",
            "159\n",
            "Loss: 0.5651980638504028\n",
            "Epoch: 9/9\n",
            "160\n",
            "Loss: 0.5104489922523499\n",
            "Epoch: 9/9\n",
            "161\n",
            "Loss: 0.4632222056388855\n",
            "Epoch: 9/9\n",
            "162\n",
            "Loss: 0.5613242983818054\n",
            "Epoch: 9/9\n",
            "163\n",
            "Loss: 0.4725022614002228\n",
            "Epoch: 9/9\n",
            "164\n",
            "Loss: 0.5554892420768738\n",
            "Epoch: 9/9\n",
            "165\n",
            "Loss: 0.44182726740837097\n",
            "Epoch: 9/9\n",
            "166\n",
            "Loss: 0.3548496663570404\n",
            "Epoch: 9/9\n",
            "167\n",
            "Loss: 0.42791658639907837\n",
            "Epoch: 9/9\n",
            "168\n",
            "Loss: 0.3945401906967163\n",
            "Epoch: 9/9\n",
            "169\n",
            "Loss: 0.46005335450172424\n",
            "Epoch: 9/9\n",
            "170\n",
            "Loss: 0.43839263916015625\n",
            "Epoch: 9/9\n",
            "171\n",
            "Loss: 0.37332040071487427\n",
            "Epoch: 9/9\n",
            "172\n",
            "Loss: 0.4563033878803253\n",
            "Epoch: 9/9\n",
            "173\n",
            "Loss: 0.4098847806453705\n",
            "Epoch: 9/9\n",
            "174\n",
            "Loss: 0.42609044909477234\n",
            "Epoch: 9/9\n",
            "175\n",
            "Loss: 0.3384159207344055\n",
            "Epoch: 9/9\n",
            "176\n",
            "Loss: 0.441195011138916\n",
            "Epoch: 9/9\n",
            "177\n",
            "Loss: 0.43846452236175537\n",
            "Epoch: 9/9\n",
            "178\n",
            "Loss: 0.5210078358650208\n",
            "Epoch: 9/9\n",
            "179\n",
            "Loss: 0.4706081748008728\n",
            "Epoch: 9/9\n",
            "180\n",
            "Loss: 0.4962783753871918\n",
            "Epoch: 9/9\n",
            "181\n",
            "Loss: 0.522617518901825\n",
            "Epoch: 9/9\n",
            "182\n",
            "Loss: 0.4483864903450012\n",
            "Epoch: 9/9\n",
            "183\n",
            "Loss: 0.4907175600528717\n",
            "Epoch: 9/9\n",
            "184\n",
            "Loss: 0.4908602237701416\n",
            "Epoch: 9/9\n",
            "185\n",
            "Loss: 0.4220742881298065\n",
            "Epoch: 9/9\n",
            "186\n",
            "Loss: 0.4948921203613281\n",
            "Epoch: 9/9\n",
            "187\n",
            "Loss: 0.48694777488708496\n",
            "Epoch: 9/9\n",
            "188\n",
            "Loss: 0.4365449845790863\n",
            "Epoch: 9/9\n",
            "189\n",
            "Loss: 0.365845263004303\n",
            "Epoch: 9/9\n",
            "190\n",
            "Loss: 0.4128684401512146\n",
            "Epoch: 9/9\n",
            "191\n",
            "Loss: 0.3697134256362915\n",
            "Epoch: 9/9\n",
            "192\n",
            "Loss: 0.3369032144546509\n",
            "Epoch: 9/9\n",
            "193\n",
            "Loss: 0.3834991753101349\n",
            "Epoch: 9/9\n",
            "194\n",
            "Loss: 0.2902023494243622\n",
            "Epoch: 9/9\n",
            "195\n",
            "Loss: 0.19812729954719543\n",
            "Epoch: 9/9\n"
          ]
        }
      ],
      "source": [
        "retrain_epochs = 10\n",
        "#train the classification layer\n",
        "for epoch in range(retrain_epochs):\n",
        "    print(\"Epoch: {}\".format(epoch))\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        print(i)\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = joined_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        #loss\n",
        "        print(\"Loss: {}\".format(loss.item()))\n",
        "        print(\"Epoch: {}/{}\".format(epoch, retrain_epochs - 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the model on the 10000 test images: 62.760000000000005 %\n"
          ]
        }
      ],
      "source": [
        "# evaluate the joined model\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = joined_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * (correct / total)))\n",
        "    # save the model\n",
        "    torch.save(joined_model.state_dict(), './joined_model_simCLR_Classif.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#save the joined_model for resnet supervised encoder\n",
        "torch.save(joined_model.state_dict(), './saved_models/joined_model_SimCLR_LinearClass.pth')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "Copy of mini-batch-logistic-regression-evaluator.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "149b9ce8fb68473a837a77431c12281a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a88c31d74f5c40a2b24bcff5a35d216c",
              "IPY_MODEL_60c6150177694717a622936b830427b5"
            ],
            "layout": "IPY_MODEL_88cd3db2831e4c13a4a634709700d6b2"
          }
        },
        "5901c2829a554c8ebbd5926610088041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c6150177694717a622936b830427b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f82234388e4701a02a9f68a177193a",
            "placeholder": "",
            "style": "IPY_MODEL_957362a11d174407979cf17012bf9208",
            "value": " 2640404480/? [00:51&lt;00:00, 32685718.58it/s]"
          }
        },
        "88cd3db2831e4c13a4a634709700d6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "957362a11d174407979cf17012bf9208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4f82234388e4701a02a9f68a177193a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a88c31d74f5c40a2b24bcff5a35d216c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5901c2829a554c8ebbd5926610088041",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dba019efadee4fdc8c799f309b9a7e70",
            "value": 1
          }
        },
        "dba019efadee4fdc8c799f309b9a7e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
